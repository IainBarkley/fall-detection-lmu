{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorganize_and_explore.py\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "base_dir = Path(\"~/repos/summerschool2023/projects/fall-detection/fall_detection_data\").expanduser()\n",
    "processed_dir = base_dir / \"processed\"  # Where your preprocessed data is\n",
    "models_dir = base_dir / \"models\"        # Where to save trained models\n",
    "models_dir.mkdir(exist_ok=True)\n",
    "output_dir = models_dir  # Use this for saving mode\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"CURRENT DIRECTORY STRUCTURE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Show current structure\n",
    "for item in sorted(base_dir.iterdir()):\n",
    "    if item.is_dir():\n",
    "        print(f\"\\nüìÅ {item.name}/\")\n",
    "        # Show what's inside each directory\n",
    "        sub_items = list(item.iterdir())[:5]\n",
    "        for sub in sub_items:\n",
    "            if sub.is_dir():\n",
    "                file_count = len(list(sub.glob(\"*\")))\n",
    "                print(f\"   üìÅ {sub.name}/ ({file_count} files)\")\n",
    "            else:\n",
    "                print(f\"   üìÑ {sub.name}\")\n",
    "        if len(list(item.iterdir())) > 5:\n",
    "            print(f\"   ... and {len(list(item.iterdir())) - 5} more\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PROPOSED REORGANIZATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "proposed_structure = \"\"\"\n",
    "fall_detection_data/\n",
    "‚îú‚îÄ‚îÄ KFall/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ sensor_data/\n",
    "‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ SA06/\n",
    "‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ S06T01R01.csv  (KFall format: S##T##R##.csv)\n",
    "‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ S06T02R01.csv\n",
    "‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...\n",
    "‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ SA07/ ...\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ labels/\n",
    "‚îÇ       ‚îú‚îÄ‚îÄ SA06_label.xlsx\n",
    "‚îÇ       ‚îî‚îÄ‚îÄ SA07_label.xlsx ...\n",
    "‚îÇ\n",
    "‚îú‚îÄ‚îÄ SisFall/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ SA01/\n",
    "‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ D01_SA01_R01.txt  (SisFall format: <CODE>_<SUBJECT>_<TRIAL>.txt)\n",
    "‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ F01_SA01_R01.txt\n",
    "‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ SA02/ ...\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ SE01/ ... (elderly subjects)\n",
    "‚îÇ\n",
    "‚îî‚îÄ‚îÄ processed/\n",
    "    ‚îú‚îÄ‚îÄ kfall_features.pkl\n",
    "    ‚îú‚îÄ‚îÄ sisfall_features.pkl\n",
    "    ‚îî‚îÄ‚îÄ fused_dataset.pkl\n",
    "\"\"\"\n",
    "\n",
    "print(proposed_structure)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DATASET COMPARISON\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# KFall structure\n",
    "kfall_sensor = base_dir / \"KFall\" / \"sensor_data\"\n",
    "if kfall_sensor.exists():\n",
    "    kfall_subjects = sorted([d.name for d in kfall_sensor.iterdir() if d.is_dir()])\n",
    "    sample_kfall = kfall_sensor / kfall_subjects[0]\n",
    "    sample_kfall_file = list(sample_kfall.glob(\"*.csv\"))[0]\n",
    "    \n",
    "    df_kfall = pd.read_csv(sample_kfall_file)\n",
    "    \n",
    "    print(\"\\nüìä KFALL DATASET:\")\n",
    "    print(f\"   Subjects: {len(kfall_subjects)} (SA06-SA38)\")\n",
    "    print(f\"   Sampling Rate: 100 Hz (needs upsampling to 200 Hz)\")\n",
    "    print(f\"   File Format: S##T##R##.csv\")\n",
    "    print(f\"   Columns: {df_kfall.columns.tolist()}\")\n",
    "    print(f\"   Data Shape (sample): {df_kfall.shape}\")\n",
    "    print(f\"   Has Labels: ‚úÖ Yes (temporal annotations in Excel files)\")\n",
    "\n",
    "# SisFall structure\n",
    "sisfall_dir = base_dir / \"SisFall\"\n",
    "if sisfall_dir.exists():\n",
    "    sisfall_subjects = sorted([d.name for d in sisfall_dir.iterdir() if d.is_dir()])\n",
    "    adults = [s for s in sisfall_subjects if s.startswith('SA')]\n",
    "    elderly = [s for s in sisfall_subjects if s.startswith('SE')]\n",
    "    \n",
    "    sample_sisfall = sisfall_dir / adults[0]\n",
    "    sample_sisfall_file = list(sample_sisfall.glob(\"*.txt\"))[0]\n",
    "    \n",
    "    # Read SisFall file - more robust parsing\n",
    "    try:\n",
    "        # Method 1: Read line by line and parse manually\n",
    "        with open(sample_sisfall_file, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        \n",
    "        data = []\n",
    "        for line in lines:\n",
    "            # Remove semicolon and split by comma or whitespace\n",
    "            line = line.strip().replace(';', '')\n",
    "            values = line.replace(',', ' ').split()\n",
    "            if len(values) == 9:  # Should have 9 columns\n",
    "                data.append([float(v) for v in values])\n",
    "        \n",
    "        df_sisfall = pd.DataFrame(data)\n",
    "        \n",
    "        print(\"\\nüìä SISFALL DATASET:\")\n",
    "        print(f\"   Subjects: {len(sisfall_subjects)} total\")\n",
    "        print(f\"     - Adults (SA): {len(adults)} (SA01-SA23)\")\n",
    "        print(f\"     - Elderly (SE): {len(elderly)} (SE01-SE15)\")\n",
    "        print(f\"   Sampling Rate: 200 Hz ‚úÖ\")\n",
    "        print(f\"   File Format: <CODE>_<SUBJECT>_<TRIAL>.txt\")\n",
    "        print(f\"   Columns: 9 (ADXL345: 0-2, ITG3200: 3-5, MMA8451Q: 6-8)\")\n",
    "        print(f\"   Data Shape (sample): {df_sisfall.shape}\")\n",
    "        print(f\"   Has Labels: ‚ùå No (must use Algorithm 1)\")\n",
    "        print(f\"   Data Format: Raw bits (needs conversion to physical units)\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error reading SisFall file: {e}\")\n",
    "        print(\"   Will handle this in the preprocessing pipeline\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ACTIVITIES NEEDED FOR PAPER REPRODUCTION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nüìã FROM KFALL (Table I):\")\n",
    "kfall_needed = {\n",
    "    'T10': 'Stumble while walking',\n",
    "    'T28': 'Vertical fall while walking (fainting)',\n",
    "    'T30': 'Forward fall while walking (trip)',\n",
    "    'T31': 'Forward fall while jogging (trip)',\n",
    "    'T32': 'Forward fall while walking (slip)',\n",
    "    'T33': 'Lateral fall while walking (slip)',\n",
    "    'T34': 'Backward fall while walking (slip)'\n",
    "}\n",
    "for code, desc in kfall_needed.items():\n",
    "    print(f\"   {code}: {desc}\")\n",
    "\n",
    "print(\"\\nüìã FROM SISFALL (Table I):\")\n",
    "print(\"\\n   ADL Activities:\")\n",
    "sisfall_adl = {\n",
    "    'D01': 'Walking slowly',\n",
    "    'D02': 'Walking quickly',\n",
    "    'D03': 'Jogging slowly',\n",
    "    'D04': 'Jogging quickly',\n",
    "    'D05': 'Walking upstairs/downstairs slowly',\n",
    "    'D06': 'Walking upstairs/downstairs quickly',\n",
    "    'D18': 'Stumble while walking'\n",
    "}\n",
    "for code, desc in sisfall_adl.items():\n",
    "    print(f\"   {code}: {desc}\")\n",
    "\n",
    "print(\"\\n   Fall Activities:\")\n",
    "sisfall_falls = {\n",
    "    'F01': 'Fall forward while walking (slip)',\n",
    "    'F02': 'Fall backward while walking (slip)',\n",
    "    'F03': 'Lateral fall while walking (slip)',\n",
    "    'F04': 'Fall forward while walking (trip)',\n",
    "    'F05': 'Fall forward while jogging (trip)',\n",
    "    'F06': 'Vertical fall while walking (fainting)'\n",
    "}\n",
    "for code, desc in sisfall_falls.items():\n",
    "    print(f\"   {code}: {desc}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"NEXT STEPS\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\"\"\n",
    "1. ‚úÖ Data is properly organized\n",
    "2. ‚è≠Ô∏è  Implement preprocessing pipeline:\n",
    "   - Load and convert SisFall raw bits to physical units\n",
    "   - Upsample KFall from 100Hz to 200Hz\n",
    "   - Apply Algorithm 1 for temporal segmentation\n",
    "   - Extract features according to Table I\n",
    "3. ‚è≠Ô∏è  Z-score normalization and dataset fusion\n",
    "4. ‚è≠Ô∏è  Build and train FallNet\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # Fall Detection Data Preprocessing Pipeline - CORRECTED VERSION\n",
    "# \n",
    "# This notebook implements the preprocessing methodology from the paper:\n",
    "# \"A novel Feature extraction method for Pre-Impact Fall detection system using Deep learning and wearable sensors\"\n",
    "#\n",
    "# Key fixes:\n",
    "# - Removed Sp - 3 bug\n",
    "# - Fixed transitional window logic (no duplicates)\n",
    "# - Proper ADL extraction before falls\n",
    "# - Correct stumble/recovery processing\n",
    "\n",
    "# %% [markdown]\n",
    "## 1. Setup and Imports\n",
    "\n",
    "# %%\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from scipy.interpolate import CubicSpline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for better plots\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úÖ Imports complete\")\n",
    "\n",
    "# %% [markdown]\n",
    "## 2. Define Paths and Configuration\n",
    "\n",
    "# %%\n",
    "base_dir = Path(\"~/repos/summerschool2023/projects/fall-detection/fall_detection_data\").expanduser()\n",
    "kfall_sensor_dir = base_dir / \"KFall\" / \"sensor_data\"\n",
    "kfall_labels_dir = base_dir / \"KFall\" / \"label_data\"\n",
    "sisfall_dir = base_dir / \"SisFall\"\n",
    "processed_dir = base_dir / \"processed\"\n",
    "\n",
    "# Clean up processed directory\n",
    "print(\"üßπ Cleaning processed directory...\")\n",
    "if processed_dir.exists():\n",
    "    for f in processed_dir.glob(\"*\"):\n",
    "        if f.is_file():\n",
    "            f.unlink()\n",
    "            print(f\"  Deleted: {f.name}\")\n",
    "else:\n",
    "    processed_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"\\n‚úÖ Directories configured:\")\n",
    "print(f\"   KFall sensor data: {kfall_sensor_dir}\")\n",
    "print(f\"   KFall labels: {kfall_labels_dir}\")\n",
    "print(f\"   SisFall data: {sisfall_dir}\")\n",
    "print(f\"   Output: {processed_dir}\")\n",
    "\n",
    "# %% [markdown]\n",
    "## 3. Activity Mappings and Labels\n",
    "\n",
    "# %%\n",
    "# Activities from Table I in the paper\n",
    "kfall_fall_activities = ['T28', 'T30', 'T31', 'T32', 'T33', 'T34']\n",
    "kfall_stumble = ['T10']\n",
    "\n",
    "sisfall_adl_map = {\n",
    "    'D01': 'Walking', 'D02': 'Walking',\n",
    "    'D03': 'Jogging', 'D04': 'Jogging',\n",
    "    'D05': 'Walking_stairs_updown', 'D06': 'Walking_stairs_updown',\n",
    "    'D18': 'Stumble_while_walking'\n",
    "}\n",
    "\n",
    "sisfall_falls = ['F01', 'F02', 'F03', 'F04', 'F05', 'F06']\n",
    "\n",
    "# Label encoding (8-class classifier)\n",
    "label_map = {\n",
    "    'Walking': 0,\n",
    "    'Jogging': 1,\n",
    "    'Walking_stairs_updown': 2,\n",
    "    'Stumble_while_walking': 3,\n",
    "    'Fall_Recovery': 4,\n",
    "    'Fall_Initiation': 5,\n",
    "    'Impact': 6,\n",
    "    'Aftermath': 7\n",
    "}\n",
    "\n",
    "reverse_label_map = {v: k for k, v in label_map.items()}\n",
    "\n",
    "print(\"üìã Label Mapping:\")\n",
    "for label_name, label_id in label_map.items():\n",
    "    print(f\"   {label_id}: {label_name}\")\n",
    "\n",
    "# Save label map immediately\n",
    "with open(processed_dir / \"label_map.json\", \"w\") as f:\n",
    "    json.dump(label_map, f, indent=2)\n",
    "print(\"\\n‚úÖ Label map saved\")\n",
    "\n",
    "# %% [markdown]\n",
    "## 4. Data Loading Functions\n",
    "\n",
    "# %%\n",
    "def load_sisfall_file(filepath):\n",
    "    \"\"\"Load and convert SisFall file from bits to physical units\"\"\"\n",
    "    with open(filepath, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    data = []\n",
    "    for line in lines:\n",
    "        line = line.strip().replace(';', '').replace(',', ' ')\n",
    "        values = line.split()\n",
    "        if len(values) == 9:\n",
    "            data.append([float(v) for v in values])\n",
    "    \n",
    "    if len(data) == 0:\n",
    "        return None\n",
    "    \n",
    "    data = np.array(data)\n",
    "    \n",
    "    # Convert to physical units\n",
    "    converted = np.zeros((data.shape[0], 6))\n",
    "    \n",
    "    # ADXL345 (columns 0-2): ¬±16g, 13-bit\n",
    "    adxl_factor = (2 * 16) / (2**13)\n",
    "    converted[:, 0:3] = data[:, 0:3] * adxl_factor\n",
    "    \n",
    "    # ITG3200 (columns 3-5): ¬±2000¬∞/s, 16-bit  \n",
    "    itg_factor = (2 * 2000) / (2**16)\n",
    "    converted[:, 3:6] = data[:, 3:6] * itg_factor\n",
    "    \n",
    "    return converted\n",
    "\n",
    "def load_kfall_file(filepath):\n",
    "    \"\"\"Load KFall CSV file\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(filepath)\n",
    "        data = df[['AccX', 'AccY', 'AccZ', 'GyrX', 'GyrY', 'GyrZ']].values\n",
    "        return data\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "print(\"‚úÖ Data loading functions defined\")\n",
    "\n",
    "# %% [markdown]\n",
    "## 5. Upsampling Function (KFall 100Hz ‚Üí 200Hz)\n",
    "\n",
    "# %%\n",
    "def upsample_to_200hz(data, original_freq=100):\n",
    "    \"\"\"Upsample KFall data from 100Hz to 200Hz using cubic spline\"\"\"\n",
    "    n_samples, n_features = data.shape\n",
    "    original_time = np.arange(n_samples) / original_freq\n",
    "    target_time = np.arange(0, n_samples / original_freq, 1 / 200)\n",
    "    \n",
    "    upsampled = np.zeros((len(target_time), n_features))\n",
    "    for i in range(n_features):\n",
    "        cs = CubicSpline(original_time, data[:, i])\n",
    "        upsampled[:, i] = cs(target_time)\n",
    "    \n",
    "    return upsampled\n",
    "\n",
    "print(\"‚úÖ Upsampling function defined\")\n",
    "\n",
    "# %% [markdown]\n",
    "## 6. Algorithm 1: Temporal Feature Extraction (CORRECTED)\n",
    "\n",
    "# %%\n",
    "def extract_temporal_features(data, sampling_freq=200):\n",
    "    \"\"\"\n",
    "    Algorithm 1 from the paper: Automatic temporal feature extraction\n",
    "    Uses Y-axis acceleration (gravity direction)\n",
    "    \n",
    "    FIXED: Removed Sp - 3 bug\n",
    "    \"\"\"\n",
    "    acc_y = data[:, 1]  # Y-axis\n",
    "    W_s = sampling_freq // 4  # 50 samples (0.25s)\n",
    "    \n",
    "    # Calculate std on non-overlapping windows\n",
    "    std_devs = []\n",
    "    window_positions = []\n",
    "    for i in range(0, len(acc_y) - W_s, W_s):\n",
    "        window = acc_y[i:i + W_s]\n",
    "        std_devs.append(np.std(window))\n",
    "        window_positions.append(i)\n",
    "    \n",
    "    if len(std_devs) == 0:\n",
    "        return None\n",
    "    \n",
    "    # Find segmentation point\n",
    "    # CRITICAL FIX: Don't subtract 3!\n",
    "    max_std_idx = np.argmax(std_devs)\n",
    "    Sp = max_std_idx  # Paper says: \"The starting frame of Sw will become Sp\"\n",
    "    \n",
    "    segments = {\n",
    "        'std_devs': std_devs,\n",
    "        'window_positions': window_positions,\n",
    "        'Sp': Sp,\n",
    "        'W_s': W_s,\n",
    "        \n",
    "        # Phase boundaries (in samples)\n",
    "        'adl_end': Sp * W_s,\n",
    "        'fall_init_start': Sp * W_s,\n",
    "        'fall_init_end': min((Sp + 4) * W_s, len(data)),\n",
    "        'transitional_end': min((Sp + 2) * W_s, len(data)),\n",
    "        'impact_start': min((Sp + 4) * W_s, len(data)),\n",
    "        'impact_end': min((Sp + 8) * W_s, len(data)),\n",
    "        'aftermath_start': min((Sp + 8) * W_s, len(data)),\n",
    "    }\n",
    "    \n",
    "    return segments\n",
    "\n",
    "print(\"‚úÖ Algorithm 1 implemented (CORRECTED)\")\n",
    "\n",
    "# %% [markdown]\n",
    "## 7. Feature Extraction Functions (CORRECTED)\n",
    "\n",
    "# %%\n",
    "def process_fall_activity(data):\n",
    "    \"\"\"\n",
    "    Extract features from fall activity using Algorithm 1\n",
    "    \n",
    "    FIXED:\n",
    "    - No duplicate Fall_Initiation samples\n",
    "    - Properly extracts ADL before fall\n",
    "    - Uses transitional window for 50% of samples (random selection)\n",
    "    \"\"\"\n",
    "    segments = extract_temporal_features(data)\n",
    "    if segments is None:\n",
    "        return []\n",
    "    \n",
    "    results = []\n",
    "    W_s = segments['W_s']\n",
    "    \n",
    "    # 1. ADL phase (before fall) - if available\n",
    "    adl_start = max(0, segments['fall_init_start'] - 200)\n",
    "    adl_end = segments['fall_init_start']\n",
    "    \n",
    "    if adl_end - adl_start >= 200 and adl_start >= 0:\n",
    "        adl_segment = data[adl_start:adl_end]\n",
    "        \n",
    "        # Determine ADL type based on variance\n",
    "        acc_std = np.std(adl_segment[:, 1])\n",
    "        if acc_std > 0.5:\n",
    "            adl_label = label_map['Jogging']\n",
    "        else:\n",
    "            adl_label = label_map['Walking']\n",
    "        \n",
    "        results.append((adl_segment[:200], adl_label))\n",
    "    \n",
    "    # 2. Fall Initiation - ONE sample per fall\n",
    "    # Randomly choose between transitional window (0.5s) or full window (1s)\n",
    "    fi_start = segments['fall_init_start']\n",
    "    \n",
    "    if np.random.random() < 0.5:\n",
    "        # Use transitional window (0.5s) for early detection training\n",
    "        tw_end = segments['transitional_end']\n",
    "        if tw_end <= len(data) and (tw_end - fi_start) >= 100:\n",
    "            tw_segment = data[fi_start:tw_end]\n",
    "            \n",
    "            # Interpolate to 200 samples\n",
    "            if len(tw_segment) != 200:\n",
    "                time_orig = np.linspace(0, 1, len(tw_segment))\n",
    "                time_new = np.linspace(0, 1, 200)\n",
    "                tw_interp = np.zeros((200, 6))\n",
    "                for i in range(6):\n",
    "                    tw_interp[:, i] = np.interp(time_new, time_orig, tw_segment[:, i])\n",
    "                results.append((tw_interp, label_map['Fall_Initiation']))\n",
    "            else:\n",
    "                results.append((tw_segment, label_map['Fall_Initiation']))\n",
    "    else:\n",
    "        # Use full Fall Initiation window (1s)\n",
    "        fi_end = segments['fall_init_end']\n",
    "        if fi_end <= len(data) and (fi_end - fi_start) >= 200:\n",
    "            fi_segment = data[fi_start:fi_end]\n",
    "            results.append((fi_segment[:200], label_map['Fall_Initiation']))\n",
    "    \n",
    "    # 3. Impact\n",
    "    impact_start = segments['impact_start']\n",
    "    impact_end = segments['impact_end']\n",
    "    if impact_end <= len(data) and (impact_end - impact_start) >= 200:\n",
    "        impact_segment = data[impact_start:impact_end]\n",
    "        results.append((impact_segment[:200], label_map['Impact']))\n",
    "    \n",
    "    # 4. Aftermath\n",
    "    aftermath_start = segments['aftermath_start']\n",
    "    if len(data) - aftermath_start >= 200:\n",
    "        aftermath_segment = data[aftermath_start:aftermath_start + 200]\n",
    "        results.append((aftermath_segment, label_map['Aftermath']))\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def process_stumble_activity(data):\n",
    "    \"\"\"\n",
    "    Process stumble/fall recovery\n",
    "    \n",
    "    Stumble = temporary loss of balance WITHOUT falling (recovers)\n",
    "    \"\"\"\n",
    "    segments = extract_temporal_features(data)\n",
    "    if segments is None:\n",
    "        return []\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # Extract the \"stumble\" moment (the imbalance event)\n",
    "    stumble_start = segments['fall_init_start']\n",
    "    stumble_end = segments['transitional_end']\n",
    "    \n",
    "    if stumble_end <= len(data) and (stumble_end - stumble_start) >= 100:\n",
    "        stumble_segment = data[stumble_start:stumble_end]\n",
    "        \n",
    "        # Interpolate to 200 samples if needed\n",
    "        if len(stumble_segment) < 200:\n",
    "            time_orig = np.linspace(0, 1, len(stumble_segment))\n",
    "            time_new = np.linspace(0, 1, 200)\n",
    "            stumble_interp = np.zeros((200, 6))\n",
    "            for i in range(6):\n",
    "                stumble_interp[:, i] = np.interp(time_new, time_orig, stumble_segment[:, i])\n",
    "            results.append((stumble_interp, label_map['Stumble_while_walking']))\n",
    "        else:\n",
    "            results.append((stumble_segment[:200], label_map['Stumble_while_walking']))\n",
    "    \n",
    "    # Fall recovery - the recovery period after stumble\n",
    "    recovery_start = segments['transitional_end']\n",
    "    recovery_end = segments['impact_end']\n",
    "    \n",
    "    if recovery_end <= len(data) and (recovery_end - recovery_start) >= 200:\n",
    "        recovery_segment = data[recovery_start:recovery_end]\n",
    "        results.append((recovery_segment[:200], label_map['Fall_Recovery']))\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def process_adl_activity(data, label_name):\n",
    "    \"\"\"\n",
    "    Extract 1-second non-overlapping windows from ADL activities\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    label = label_map[label_name]\n",
    "    \n",
    "    # Extract up to 20 seconds (as per paper)\n",
    "    max_samples = min(len(data), 4000)  # 20 seconds at 200Hz\n",
    "    \n",
    "    # Non-overlapping 1-second windows\n",
    "    for i in range(0, max_samples - 200, 200):\n",
    "        segment = data[i:i + 200]\n",
    "        if len(segment) == 200:\n",
    "            results.append((segment, label))\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"‚úÖ Feature extraction functions defined (CORRECTED)\")\n",
    "\n",
    "# %% [markdown]\n",
    "## 8. Process KFall Dataset\n",
    "\n",
    "# %%\n",
    "def process_kfall_dataset():\n",
    "    \"\"\"Process all KFall data\"\"\"\n",
    "    print(\"=\"*80)\n",
    "    print(\"PROCESSING KFALL DATASET\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    X_data = []\n",
    "    y_labels = []\n",
    "    \n",
    "    subjects = sorted([d for d in kfall_sensor_dir.iterdir() if d.is_dir()])\n",
    "    print(f\"Found {len(subjects)} subjects\")\n",
    "    \n",
    "    for subject_dir in tqdm(subjects, desc=\"Processing KFall subjects\"):\n",
    "        files = list(subject_dir.glob(\"*.csv\"))\n",
    "        \n",
    "        for file in files:\n",
    "            # Extract activity code from filename: S06T10R01.csv -> T10\n",
    "            filename = file.stem\n",
    "            if len(filename) < 6:\n",
    "                continue\n",
    "            activity_code = filename[3:6]  # e.g., T10, T28\n",
    "            \n",
    "            # Load and upsample\n",
    "            data = load_kfall_file(file)\n",
    "            if data is None or len(data) < 100:\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                data_upsampled = upsample_to_200hz(data)\n",
    "                \n",
    "                # Process based on activity type\n",
    "                if activity_code in kfall_fall_activities:\n",
    "                    features = process_fall_activity(data_upsampled)\n",
    "                elif activity_code in kfall_stumble:\n",
    "                    features = process_stumble_activity(data_upsampled)\n",
    "                else:\n",
    "                    continue\n",
    "                \n",
    "                for segment, label in features:\n",
    "                    if segment.shape == (200, 6):\n",
    "                        X_data.append(segment)\n",
    "                        y_labels.append(label)\n",
    "            except Exception as e:\n",
    "                print(f\"  Error processing {file.name}: {e}\")\n",
    "                continue\n",
    "    \n",
    "    return np.array(X_data), np.array(y_labels)\n",
    "\n",
    "# Run KFall processing\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "X_kfall, y_kfall = process_kfall_dataset()\n",
    "print(f\"\\n‚úÖ KFall processed:\")\n",
    "print(f\"   X shape: {X_kfall.shape}\")\n",
    "print(f\"   y shape: {y_kfall.shape}\")\n",
    "\n",
    "# %% [markdown]\n",
    "## 9. Process SisFall Dataset\n",
    "\n",
    "# %%\n",
    "def process_sisfall_dataset():\n",
    "    \"\"\"Process all SisFall data\"\"\"\n",
    "    print(\"=\"*80)\n",
    "    print(\"PROCESSING SISFALL DATASET\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    X_data = []\n",
    "    y_labels = []\n",
    "    \n",
    "    subjects = sorted([d for d in sisfall_dir.iterdir() \n",
    "                      if d.is_dir() and (d.name.startswith('SA') or d.name.startswith('SE'))])\n",
    "    print(f\"Found {len(subjects)} subjects\")\n",
    "    \n",
    "    for subject_dir in tqdm(subjects, desc=\"Processing SisFall subjects\"):\n",
    "        files = list(subject_dir.glob(\"*.txt\"))\n",
    "        \n",
    "        for file in files:\n",
    "            # Extract activity code: D01_SA01_R01.txt -> D01\n",
    "            filename = file.stem\n",
    "            parts = filename.split('_')\n",
    "            if len(parts) < 2:\n",
    "                continue\n",
    "            activity_code = parts[0]\n",
    "            \n",
    "            # Load data\n",
    "            data = load_sisfall_file(file)\n",
    "            if data is None or len(data) < 200:\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                # Process based on activity type\n",
    "                if activity_code in sisfall_adl_map:\n",
    "                    label_name = sisfall_adl_map[activity_code]\n",
    "                    features = process_adl_activity(data, label_name)\n",
    "                elif activity_code in sisfall_falls:\n",
    "                    features = process_fall_activity(data)\n",
    "                else:\n",
    "                    continue\n",
    "                \n",
    "                for segment, label in features:\n",
    "                    if segment.shape == (200, 6):\n",
    "                        X_data.append(segment)\n",
    "                        y_labels.append(label)\n",
    "            except Exception as e:\n",
    "                # Silently skip problematic files\n",
    "                continue\n",
    "    \n",
    "    return np.array(X_data), np.array(y_labels)\n",
    "\n",
    "# Run SisFall processing\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "X_sisfall, y_sisfall = process_sisfall_dataset()\n",
    "print(f\"\\n‚úÖ SisFall processed:\")\n",
    "print(f\"   X shape: {X_sisfall.shape}\")\n",
    "print(f\"   y shape: {y_sisfall.shape}\")\n",
    "\n",
    "# %% [markdown]\n",
    "## 10. Z-Score Normalization and Dataset Fusion\n",
    "\n",
    "# %%\n",
    "def normalize_and_fuse(X_kfall, y_kfall, X_sisfall, y_sisfall):\n",
    "    \"\"\"\n",
    "    Z-score normalization and dataset fusion (paper methodology)\n",
    "    \n",
    "    Paper says: \"Z-score standardization was again employed before the \n",
    "    final data was fed into the network to normalize the features extracted \n",
    "    from the two datasets\"\n",
    "    \"\"\"\n",
    "    print(\"=\"*80)\n",
    "    print(\"NORMALIZING AND FUSING DATASETS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Reshape for normalization\n",
    "    n_kfall, ts, feat = X_kfall.shape\n",
    "    X_kfall_flat = X_kfall.reshape(-1, feat)\n",
    "    \n",
    "    n_sisfall = X_sisfall.shape[0]\n",
    "    X_sisfall_flat = X_sisfall.reshape(-1, feat)\n",
    "    \n",
    "    print(f\"\\nStep 1: Normalize each dataset separately\")\n",
    "    # Normalize KFall\n",
    "    scaler_kfall = StandardScaler()\n",
    "    X_kfall_norm = scaler_kfall.fit_transform(X_kfall_flat)\n",
    "    X_kfall_norm = X_kfall_norm.reshape(n_kfall, ts, feat)\n",
    "    print(f\"  KFall normalized: {X_kfall_norm.shape}\")\n",
    "    \n",
    "    # Normalize SisFall\n",
    "    scaler_sisfall = StandardScaler()\n",
    "    X_sisfall_norm = scaler_sisfall.fit_transform(X_sisfall_flat)\n",
    "    X_sisfall_norm = X_sisfall_norm.reshape(n_sisfall, ts, feat)\n",
    "    print(f\"  SisFall normalized: {X_sisfall_norm.shape}\")\n",
    "    \n",
    "    print(f\"\\nStep 2: Fuse datasets\")\n",
    "    # Fuse\n",
    "    X_fused = np.concatenate([X_kfall_norm, X_sisfall_norm], axis=0)\n",
    "    y_fused = np.concatenate([y_kfall, y_sisfall], axis=0)\n",
    "    print(f\"  Fused dataset: {X_fused.shape}\")\n",
    "    \n",
    "    print(f\"\\nStep 3: Normalize fused dataset\")\n",
    "    # Final normalization\n",
    "    X_fused_flat = X_fused.reshape(-1, feat)\n",
    "    scaler_final = StandardScaler()\n",
    "    X_fused_norm = scaler_final.fit_transform(X_fused_flat)\n",
    "    X_fused_norm = X_fused_norm.reshape(-1, ts, feat)\n",
    "    print(f\"  Final normalized: {X_fused_norm.shape}\")\n",
    "    \n",
    "    # Verify normalization\n",
    "    print(f\"\\nVerification:\")\n",
    "    print(f\"  Mean: {X_fused_norm.mean():.6f} (should be ~0)\")\n",
    "    print(f\"  Std:  {X_fused_norm.std():.6f} (should be ~1)\")\n",
    "    \n",
    "    return X_fused_norm, y_fused, scaler_final\n",
    "\n",
    "# Normalize and fuse\n",
    "X_final, y_final, scaler = normalize_and_fuse(X_kfall, y_kfall, X_sisfall, y_sisfall)\n",
    "\n",
    "print(f\"\\n‚úÖ Final fused dataset:\")\n",
    "print(f\"   X shape: {X_final.shape}\")\n",
    "print(f\"   y shape: {y_final.shape}\")\n",
    "\n",
    "# %% [markdown]\n",
    "## 11. Verify Data Quality\n",
    "\n",
    "# %%\n",
    "from collections import Counter\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"DATA QUALITY VERIFICATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. Class distribution\n",
    "counts = Counter(y_final)\n",
    "print(\"\\n1. Class Distribution:\")\n",
    "for cls_id in sorted(counts.keys()):\n",
    "    count = counts[cls_id]\n",
    "    pct = count / len(y_final) * 100\n",
    "    print(f\"   {cls_id}: {reverse_label_map[cls_id]:30s} - {count:5d} ({pct:5.2f}%)\")\n",
    "\n",
    "print(f\"\\n   Total samples: {len(y_final)}\")\n",
    "\n",
    "# 2. CRITICAL: Variance test\n",
    "print(\"\\n2. Variance Test (Acc-Y axis):\")\n",
    "print(f\"   {'Class':<35s} {'Variance':<12s}\")\n",
    "print(f\"   {'-'*50}\")\n",
    "\n",
    "variances = []\n",
    "for cls_id in sorted(counts.keys()):\n",
    "    class_samples = X_final[y_final == cls_id]\n",
    "    var = class_samples[:, :, 1].var()\n",
    "    variances.append((reverse_label_map[cls_id], var))\n",
    "    print(f\"   {reverse_label_map[cls_id]:<35s} {var:>10.4f}\")\n",
    "\n",
    "# Sort by variance\n",
    "variances_sorted = sorted(variances, key=lambda x: x[1], reverse=True)\n",
    "print(f\"\\n3. Variance Ranking:\")\n",
    "for i, (name, var) in enumerate(variances_sorted, 1):\n",
    "    print(f\"   {i}. {name:<35s}: {var:.4f}\")\n",
    "\n",
    "# Check if Fall_Initiation is in top 2\n",
    "fall_init_rank = next(i for i, (name, _) in enumerate(variances_sorted, 1) if name == 'Fall_Initiation')\n",
    "\n",
    "if fall_init_rank <= 2:\n",
    "    print(f\"\\n‚úÖ PASS: Fall_Initiation ranked #{fall_init_rank} (should be #1 or #2)\")\n",
    "else:\n",
    "    print(f\"\\n‚ùå FAIL: Fall_Initiation ranked #{fall_init_rank} (should be #1 or #2)\")\n",
    "    print(\"   Segmentation may be incorrect!\")\n",
    "\n",
    "# 4. Check for NaN/Inf\n",
    "print(f\"\\n4. Data Integrity:\")\n",
    "print(f\"   NaN values: {np.isnan(X_final).sum()}\")\n",
    "print(f\"   Inf values: {np.isinf(X_final).sum()}\")\n",
    "\n",
    "# 5. Shape verification\n",
    "print(f\"\\n5. Shape Verification:\")\n",
    "print(f\"   Expected: (N, 200, 6)\")\n",
    "print(f\"   Actual:   {X_final.shape}\")\n",
    "print(f\"   ‚úÖ PASS\" if X_final.shape[1:] == (200, 6) else \"   ‚ùå FAIL\")\n",
    "\n",
    "# %% [markdown]\n",
    "## 12. Visualize Samples\n",
    "\n",
    "# %%\n",
    "fig, axes = plt.subplots(4, 2, figsize=(16, 14))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for class_id in range(8):\n",
    "    class_indices = np.where(y_final == class_id)[0]\n",
    "    if len(class_indices) > 0:\n",
    "        sample_idx = class_indices[0]\n",
    "        sample_data = X_final[sample_idx]\n",
    "        \n",
    "        time = np.arange(200) / 200\n",
    "        axes[class_id].plot(time, sample_data[:, 0], label='Acc-X', alpha=0.7, linewidth=1)\n",
    "        axes[class_id].plot(time, sample_data[:, 1], label='Acc-Y', alpha=0.7, linewidth=1)\n",
    "        axes[class_id].plot(time, sample_data[:, 2], label='Acc-Z', alpha=0.7, linewidth=1)\n",
    "        \n",
    "        axes[class_id].set_title(f'Class {class_id}: {reverse_label_map[class_id]}', \n",
    "                                fontsize=11, fontweight='bold')\n",
    "        axes[class_id].set_xlabel('Time (s)')\n",
    "        axes[class_id].set_ylabel('Normalized Acc')\n",
    "        axes[class_id].legend(loc='upper right', fontsize=8)\n",
    "        axes[class_id].grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Sample Segments from Each Activity Class', \n",
    "             fontsize=14, fontweight='bold', y=0.995)\n",
    "plt.tight_layout()\n",
    "plt.savefig(processed_dir / 'sample_visualization.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"‚úÖ Visualization saved to {processed_dir / 'sample_visualization.png'}\")\n",
    "\n",
    "# %% [markdown]\n",
    "## 13. Save Processed Data\n",
    "\n",
    "# %%\n",
    "print(\"=\"*80)\n",
    "print(\"SAVING PROCESSED DATA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Save arrays\n",
    "np.save(processed_dir / \"X_data.npy\", X_final)\n",
    "np.save(processed_dir / \"y_labels.npy\", y_final)\n",
    "\n",
    "# Save scaler\n",
    "with open(processed_dir / \"scaler.pkl\", 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "# Save label map (both formats)\n",
    "with open(processed_dir / \"label_map.pkl\", 'wb') as f:\n",
    "    pickle.dump(label_map, f)\n",
    "\n",
    "with open(processed_dir / \"label_map.json\", 'w') as f:\n",
    "    json.dump(label_map, f, indent=2)\n",
    "\n",
    "print(f\"\\n‚úÖ Saved to {processed_dir}/\")\n",
    "print(f\"   üìÑ X_data.npy: {X_final.shape}\")\n",
    "print(f\"   üìÑ y_labels.npy: {y_final.shape}\")\n",
    "print(f\"   üìÑ scaler.pkl\")\n",
    "print(f\"   üìÑ label_map.pkl\")\n",
    "print(f\"   üìÑ label_map.json\")\n",
    "\n",
    "# %% [markdown]\n",
    "## 14. Final Summary\n",
    "\n",
    "# %%\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PREPROCESSING PIPELINE COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "summary = f\"\"\"\n",
    "‚úÖ Successfully processed {len(y_final):,} samples\n",
    "\n",
    "Dataset Breakdown:\n",
    "  - KFall samples: {len(y_kfall):,}\n",
    "  - SisFall samples: {len(y_sisfall):,}\n",
    "  \n",
    "Data Shape:\n",
    "  - Features: {X_final.shape}\n",
    "  - Labels: {y_final.shape}\n",
    "  \n",
    "Normalization:\n",
    "  - Mean: {X_final.mean():.6f}\n",
    "  - Std: {X_final.std():.6f}\n",
    "  \n",
    "Quality Check:\n",
    "  - Fall_Initiation rank: #{fall_init_rank} (should be ‚â§2)\n",
    "  - Status: {'‚úÖ READY FOR TRAINING' if fall_init_rank <= 2 else '‚ùå NEEDS REVIEW'}\n",
    "\n",
    "Next Steps:\n",
    "  1. Load data with: X = np.load('processed/X_data.npy')\n",
    "  2. Train FallNet model\n",
    "  3. Evaluate on stratified K-fold cross-validation\n",
    "\"\"\"\n",
    "\n",
    "print(summary)\n",
    "\n",
    "# %%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what files exist in your processed directory\n",
    "print(\"=\"*80)\n",
    "print(\"CHECKING PROCESSED DATA FILES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "processed_files = list(output_dir.glob(\"*\"))\n",
    "print(f\"\\nFiles in {output_dir}:\")\n",
    "for f in sorted(processed_files):\n",
    "    if f.is_file():\n",
    "        size_mb = f.stat().st_size / (1024 * 1024)\n",
    "        modified = pd.Timestamp(f.stat().st_mtime, unit='s')\n",
    "        print(f\"  {f.name:30s} | {size_mb:8.2f} MB | Modified: {modified}\")\n",
    "\n",
    "# Check if the data you loaded is actually the new one\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"VERIFY DATA FRESHNESS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "X_data_path = output_dir / \"X_data.npy\"\n",
    "y_labels_path = output_dir / \"y_labels.npy\"\n",
    "\n",
    "if X_data_path.exists():\n",
    "    mod_time = pd.Timestamp(X_data_path.stat().st_mtime, unit='s')\n",
    "    print(f\"\\nX_data.npy was last modified: {mod_time}\")\n",
    "    print(f\"Current time: {pd.Timestamp.now()}\")\n",
    "    age_minutes = (pd.Timestamp.now() - mod_time).total_seconds() / 60\n",
    "    print(f\"Age: {age_minutes:.1f} minutes ago\")\n",
    "    \n",
    "    if age_minutes > 30:\n",
    "        print(\"\\n‚ö†Ô∏è  WARNING: Data is more than 30 minutes old!\")\n",
    "        print(\"   You might be using old preprocessed data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the newly processed data\n",
    "X_data = np.load(processed_dir / \"X_data.npy\")\n",
    "y_labels = np.load(processed_dir / \"y_labels.npy\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 1: Merge Impact and Aftermath\n",
    "# ============================================================================\n",
    "print(\"Merging Impact and Aftermath classes...\")\n",
    "y_labels[y_labels == 7] = 6  # Change Aftermath (7) to Impact (6)\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 2: Remove Fall_Recovery (NEW!)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"REMOVING FALL_RECOVERY CLASS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# Show before\n",
    "counts_before = Counter(y_labels)\n",
    "print(f\"\\nBefore removal:\")\n",
    "print(f\"  Total samples: {len(y_labels):,}\")\n",
    "print(f\"  Fall_Recovery (class 4): {counts_before[4]} samples\")\n",
    "\n",
    "# Remove Fall_Recovery (class 4)\n",
    "mask = y_labels != 4\n",
    "X_data = X_data[mask]\n",
    "y_labels_temp = y_labels[mask]\n",
    "\n",
    "removed_count = (~mask).sum()\n",
    "print(f\"\\n‚úÖ Removed {removed_count} Fall_Recovery samples\")\n",
    "\n",
    "# Shift labels down (5‚Üí4, 6‚Üí5)\n",
    "y_labels = y_labels_temp.copy()\n",
    "y_labels[y_labels_temp > 4] -= 1  # Classes 5,6 become 4,5\n",
    "\n",
    "print(f\"\\nAfter removal:\")\n",
    "print(f\"  Total samples: {len(y_labels):,}\")\n",
    "print(f\"  Removed: {removed_count} samples ({removed_count/(len(y_labels)+removed_count)*100:.2f}%)\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 3: Update label map (NOW 6 CLASSES: 0-5)\n",
    "# ============================================================================\n",
    "label_map = {\n",
    "    'Walking': 0,\n",
    "    'Jogging': 1,\n",
    "    'Walking_stairs_updown': 2,\n",
    "    'Stumble_while_walking': 3,\n",
    "    'Fall_Initiation': 4,      # Was 5, now 4 ‚Üê SHIFTED DOWN!\n",
    "    'Impact_Aftermath': 5,     # Was 6, now 5 ‚Üê SHIFTED DOWN!\n",
    "}\n",
    "reverse_label_map = {v: k for k, v in label_map.items()}\n",
    "\n",
    "print(f\"\\n‚úÖ Updated to 6 classes (0-5):\")\n",
    "for name, idx in sorted(label_map.items(), key=lambda x: x[1]):\n",
    "    print(f\"  Class {idx}: {name}\")\n",
    "\n",
    "y_categorical = keras.utils.to_categorical(y_labels, num_classes=6)  # ‚Üê HERE!\n",
    "print(f\"y_categorical shape: {y_categorical.shape}\")\n",
    "\n",
    "# ============================================================================\n",
    "# DIAGNOSTICS\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"POST-REMOVAL DATA DIAGNOSTICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. Class distribution\n",
    "class_counts = Counter(y_labels)\n",
    "print(\"\\n1. Class Distribution (6 classes):\")\n",
    "for cls_idx in sorted(class_counts.keys()):\n",
    "    count = class_counts[cls_idx]\n",
    "    pct = count / len(y_labels) * 100\n",
    "    print(f\"   Class {cls_idx} ({reverse_label_map[cls_idx]:30s}): {count:5d} ({pct:5.2f}%)\")\n",
    "\n",
    "# Calculate imbalance\n",
    "max_count = max(class_counts.values())\n",
    "min_count = min(class_counts.values())\n",
    "print(f\"\\nImbalance ratio: {max_count/min_count:.2f}x (was 36.8x with Fall_Recovery)\")\n",
    "\n",
    "# 2. Per-class signal statistics\n",
    "print(\"\\n2. Per-Class Signal Statistics (Acc-Y axis):\")\n",
    "print(f\"   {'Class':<35s} {'Mean':<10s} {'Std':<10s} {'Min':<10s} {'Max':<10s}\")\n",
    "print(f\"   {'-'*75}\")\n",
    "for cls_idx in sorted(class_counts.keys()):\n",
    "    class_samples = X_data[y_labels == cls_idx]\n",
    "    acc_y = class_samples[:, :, 1]  # Y-axis acceleration\n",
    "    \n",
    "    mean_val = acc_y.mean()\n",
    "    std_val = acc_y.std()\n",
    "    min_val = acc_y.min()\n",
    "    max_val = acc_y.max()\n",
    "    \n",
    "    print(f\"   {reverse_label_map[cls_idx]:<35s} {mean_val:>8.4f}  {std_val:>8.4f}  {min_val:>8.2f}  {max_val:>8.2f}\")\n",
    "\n",
    "# 3. Variance ranking\n",
    "print(\"\\n3. Variance Ranking (Fall_Initiation should be #1):\")\n",
    "variances = []\n",
    "for cls_idx in sorted(class_counts.keys()):\n",
    "    class_samples = X_data[y_labels == cls_idx]\n",
    "    acc_y_var = class_samples[:, :, 1].var()\n",
    "    variances.append((reverse_label_map[cls_idx], acc_y_var, cls_idx))\n",
    "variances.sort(key=lambda x: x[1], reverse=True)\n",
    "for i, (name, var, idx) in enumerate(variances, 1):\n",
    "    print(f\"   {i}. {name:<35s}: {var:.4f}\")\n",
    "\n",
    "# 4. Visualize samples (update to 6 classes)\n",
    "fig, axes = plt.subplots(3, 2, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "critical_classes = [\n",
    "    label_map['Walking'],\n",
    "    label_map['Fall_Initiation'],\n",
    "    label_map['Impact_Aftermath'],\n",
    "    label_map['Stumble_while_walking'],\n",
    "    label_map['Jogging'],\n",
    "    label_map['Walking_stairs_updown']\n",
    "]\n",
    "for i, cls_idx in enumerate(critical_classes):\n",
    "    if cls_idx in class_counts:\n",
    "        sample_idx = np.where(y_labels == cls_idx)[0][0]\n",
    "        sample_data = X_data[sample_idx]\n",
    "        \n",
    "        time = np.arange(200) / 200\n",
    "        axes[i].plot(time, sample_data[:, 0], label='Acc-X', alpha=0.7, linewidth=1)\n",
    "        axes[i].plot(time, sample_data[:, 1], label='Acc-Y', alpha=0.7, linewidth=1)\n",
    "        axes[i].plot(time, sample_data[:, 2], label='Acc-Z', alpha=0.7, linewidth=1)\n",
    "        \n",
    "        axes[i].set_title(f'{reverse_label_map[cls_idx]}', fontsize=11, fontweight='bold')\n",
    "        axes[i].set_xlabel('Time (s)')\n",
    "        axes[i].set_ylabel('Normalized Acc')\n",
    "        axes[i].legend(fontsize=8)\n",
    "        axes[i].grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ DATA READY FOR TRAINING (6 CLASSES)\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # Data Loading and Preprocessing\n",
    "# Load preprocessed data, merge classes, remove Fall_Recovery\n",
    "\n",
    "# %%\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "from tensorflow import keras\n",
    "\n",
    "# Setup paths\n",
    "base_dir = Path(\"~/repos/summerschool2023/projects/fall-detection/fall_detection_data\").expanduser()\n",
    "processed_dir = base_dir / \"processed\"\n",
    "output_dir = base_dir / \"models\"\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"LOADING AND PREPROCESSING DATA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# %% Load the newly processed data\n",
    "X_data = np.load(processed_dir / \"X_data.npy\")\n",
    "y_labels = np.load(processed_dir / \"y_labels.npy\")\n",
    "\n",
    "print(f\"\\nOriginal data loaded:\")\n",
    "print(f\"  X_data shape: {X_data.shape}\")\n",
    "print(f\"  y_labels shape: {y_labels.shape}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 1: Merge Impact and Aftermath\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 1: MERGING IMPACT AND AFTERMATH\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "counts_before_merge = Counter(y_labels)\n",
    "print(f\"Before merge:\")\n",
    "print(f\"  Impact (6): {counts_before_merge[6]} samples\")\n",
    "print(f\"  Aftermath (7): {counts_before_merge[7]} samples\")\n",
    "\n",
    "y_labels[y_labels == 7] = 6  # Change Aftermath (7) to Impact (6)\n",
    "\n",
    "counts_after_merge = Counter(y_labels)\n",
    "print(f\"\\nAfter merge:\")\n",
    "print(f\"  Impact_Aftermath (6): {counts_after_merge[6]} samples\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 2: Remove Fall_Recovery\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 2: REMOVING FALL_RECOVERY CLASS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Show before\n",
    "counts_before = Counter(y_labels)\n",
    "print(f\"\\nBefore removal:\")\n",
    "print(f\"  Total samples: {len(y_labels):,}\")\n",
    "print(f\"  Fall_Recovery (class 4): {counts_before[4]} samples\")\n",
    "\n",
    "# Remove Fall_Recovery (class 4)\n",
    "mask = y_labels != 4\n",
    "X_data = X_data[mask]\n",
    "y_labels_temp = y_labels[mask]\n",
    "\n",
    "removed_count = (~mask).sum()\n",
    "print(f\"\\n‚úÖ Removed {removed_count} Fall_Recovery samples\")\n",
    "\n",
    "# Shift labels down (5‚Üí4, 6‚Üí5)\n",
    "y_labels = y_labels_temp.copy()\n",
    "y_labels[y_labels_temp > 4] -= 1  # Classes 5,6 become 4,5\n",
    "\n",
    "print(f\"\\nAfter removal:\")\n",
    "print(f\"  Total samples: {len(y_labels):,}\")\n",
    "print(f\"  Removed: {removed_count} samples ({removed_count/(len(y_labels)+removed_count)*100:.2f}%)\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 3: Update label map (NOW 6 CLASSES: 0-5)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 3: CREATING 6-CLASS LABEL MAP\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "label_map = {\n",
    "    'Walking': 0,\n",
    "    'Jogging': 1,\n",
    "    'Walking_stairs_updown': 2,\n",
    "    'Stumble_while_walking': 3,\n",
    "    'Fall_Initiation': 4,      # Was 5, now 4\n",
    "    'Impact_Aftermath': 5,     # Was 6, now 5\n",
    "}\n",
    "reverse_label_map = {v: k for k, v in label_map.items()}\n",
    "\n",
    "print(f\"\\n‚úÖ Updated to 6 classes (0-5):\")\n",
    "for name, idx in sorted(label_map.items(), key=lambda x: x[1]):\n",
    "    print(f\"  Class {idx}: {name}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 4: Create categorical labels\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 4: CREATING CATEGORICAL LABELS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "y_categorical = keras.utils.to_categorical(y_labels, num_classes=6)\n",
    "\n",
    "print(f\"\\n‚úÖ y_categorical created:\")\n",
    "print(f\"   Shape: {y_categorical.shape}\")\n",
    "print(f\"   Expected: ({len(y_labels)}, 6)\")\n",
    "\n",
    "# Verification\n",
    "assert X_data.shape[0] == y_labels.shape[0] == y_categorical.shape[0], \\\n",
    "    \"Data shapes don't match!\"\n",
    "\n",
    "print(f\"\\n‚úÖ All data aligned:\")\n",
    "print(f\"   X_data:        {X_data.shape}\")\n",
    "print(f\"   y_labels:      {y_labels.shape}\")\n",
    "print(f\"   y_categorical: {y_categorical.shape}\")\n",
    "print(f\"   All have {X_data.shape[0]:,} samples\")\n",
    "\n",
    "# ============================================================================\n",
    "# DIAGNOSTICS\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DATA QUALITY DIAGNOSTICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. Class distribution\n",
    "class_counts = Counter(y_labels)\n",
    "print(\"\\n1. Class Distribution (6 classes):\")\n",
    "for cls_idx in sorted(class_counts.keys()):\n",
    "    count = class_counts[cls_idx]\n",
    "    pct = count / len(y_labels) * 100\n",
    "    print(f\"   Class {cls_idx} ({reverse_label_map[cls_idx]:30s}): {count:5d} ({pct:5.2f}%)\")\n",
    "\n",
    "# Calculate imbalance\n",
    "max_count = max(class_counts.values())\n",
    "min_count = min(class_counts.values())\n",
    "print(f\"\\nImbalance ratio: {max_count/min_count:.2f}x\")\n",
    "print(f\"  (was 36.8x with Fall_Recovery)\")\n",
    "\n",
    "# 2. Per-class signal statistics\n",
    "print(\"\\n2. Per-Class Signal Statistics (Acc-Y axis):\")\n",
    "print(f\"   {'Class':<35s} {'Mean':<10s} {'Std':<10s} {'Min':<10s} {'Max':<10s}\")\n",
    "print(f\"   {'-'*75}\")\n",
    "for cls_idx in sorted(class_counts.keys()):\n",
    "    class_samples = X_data[y_labels == cls_idx]\n",
    "    acc_y = class_samples[:, :, 1]  # Y-axis acceleration\n",
    "    \n",
    "    mean_val = acc_y.mean()\n",
    "    std_val = acc_y.std()\n",
    "    min_val = acc_y.min()\n",
    "    max_val = acc_y.max()\n",
    "    \n",
    "    print(f\"   {reverse_label_map[cls_idx]:<35s} {mean_val:>8.4f}  {std_val:>8.4f}  {min_val:>8.2f}  {max_val:>8.2f}\")\n",
    "\n",
    "# 3. Variance ranking\n",
    "print(\"\\n3. Variance Ranking (Fall_Initiation should be #1):\")\n",
    "variances = []\n",
    "for cls_idx in sorted(class_counts.keys()):\n",
    "    class_samples = X_data[y_labels == cls_idx]\n",
    "    acc_y_var = class_samples[:, :, 1].var()\n",
    "    variances.append((reverse_label_map[cls_idx], acc_y_var, cls_idx))\n",
    "variances.sort(key=lambda x: x[1], reverse=True)\n",
    "for i, (name, var, idx) in enumerate(variances, 1):\n",
    "    print(f\"   {i}. {name:<35s}: {var:.4f}\")\n",
    "\n",
    "# 4. Visualize samples\n",
    "fig, axes = plt.subplots(3, 2, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "critical_classes = [\n",
    "    label_map['Walking'],\n",
    "    label_map['Fall_Initiation'],\n",
    "    label_map['Impact_Aftermath'],\n",
    "    label_map['Stumble_while_walking'],\n",
    "    label_map['Jogging'],\n",
    "    label_map['Walking_stairs_updown']\n",
    "]\n",
    "\n",
    "for i, cls_idx in enumerate(critical_classes):\n",
    "    if cls_idx in class_counts:\n",
    "        sample_idx = np.where(y_labels == cls_idx)[0][0]\n",
    "        sample_data = X_data[sample_idx]\n",
    "        \n",
    "        time = np.arange(200) / 200\n",
    "        axes[i].plot(time, sample_data[:, 0], label='Acc-X', alpha=0.7, linewidth=1)\n",
    "        axes[i].plot(time, sample_data[:, 1], label='Acc-Y', alpha=0.7, linewidth=1)\n",
    "        axes[i].plot(time, sample_data[:, 2], label='Acc-Z', alpha=0.7, linewidth=1)\n",
    "        \n",
    "        axes[i].set_title(f'{reverse_label_map[cls_idx]}', fontsize=11, fontweight='bold')\n",
    "        axes[i].set_xlabel('Time (s)')\n",
    "        axes[i].set_ylabel('Normalized Acc')\n",
    "        axes[i].legend(fontsize=8)\n",
    "        axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ DATA READY FOR TRAINING (6 CLASSES)\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # FallNet Model Architecture\n",
    "# \n",
    "# Implementing the CNN-LSTM ensemble model from Table II in the paper\n",
    "\n",
    "# %%\n",
    "import gc\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU available: {tf.config.list_physical_devices('GPU')}\")\n",
    "\n",
    "# %% [markdown]\n",
    "## 1. Model Architecture Definition\n",
    "\n",
    "# %%\n",
    "class FallNet:\n",
    "    \"\"\"\n",
    "    FallNet: CNN-LSTM Ensemble for Pre-Impact Fall Detection\n",
    "    Based on Table II in the paper\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_shape=(200, 6), n_classes=6):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_shape: (timesteps, features) = (200, 6)\n",
    "            n_classes: Number of output classes (6)\n",
    "        \"\"\"\n",
    "        self.input_shape = input_shape\n",
    "        self.n_classes = n_classes\n",
    "        self.model = None\n",
    "    \n",
    "    def build_lstm_branch(self, inputs):\n",
    "        \"\"\"\n",
    "        LSTM Branch:\n",
    "        - LSTM(256, tanh)\n",
    "        - Dense(128, ReLU)\n",
    "        - Dense(64, ReLU)\n",
    "        - Dense(32, ReLU)\n",
    "        - Dense(8, Softmax)\n",
    "        \"\"\"\n",
    "        # LSTM layer\n",
    "        x = layers.LSTM(\n",
    "            units=256,\n",
    "            activation='tanh',\n",
    "            return_sequences=False,\n",
    "            name='lstm_layer'\n",
    "        )(inputs)\n",
    "        \n",
    "        # Dense layers with dropout\n",
    "        x = layers.Dense(128, activation='relu', name='lstm_dense1')(x)\n",
    "        x = layers.Dropout(0.2, name='lstm_dropout1')(x)\n",
    "        \n",
    "        x = layers.Dense(64, activation='relu', name='lstm_dense2')(x)\n",
    "        x = layers.Dropout(0.2, name='lstm_dropout2')(x)\n",
    "        \n",
    "        x = layers.Dense(32, activation='relu', name='lstm_dense3')(x)\n",
    "        x = layers.Dropout(0.2, name='lstm_dropout3')(x)\n",
    "        \n",
    "        # Output layer\n",
    "        lstm_output = layers.Dense(\n",
    "            self.n_classes, \n",
    "            activation='softmax',\n",
    "            name='lstm_output'\n",
    "        )(x)\n",
    "        \n",
    "        return lstm_output\n",
    "    \n",
    "    def build_cnn_branch(self, inputs):\n",
    "        \"\"\"\n",
    "        CNN Branch:\n",
    "        - Conv1D(128 filters, kernel_size=3, ReLU)\n",
    "        - MaxPooling1D(pool_size=2)\n",
    "        - Dense(1024, ReLU)\n",
    "        - Dense(512, ReLU)\n",
    "        - Dense(8, Softmax)\n",
    "        \"\"\"\n",
    "        # 1D Convolutional layer\n",
    "        x = layers.Conv1D(\n",
    "            filters=128,\n",
    "            kernel_size=3,\n",
    "            activation='relu',\n",
    "            padding='same',\n",
    "            name='conv1d_layer'\n",
    "        )(inputs)\n",
    "        \n",
    "        # Max pooling\n",
    "        x = layers.MaxPooling1D(\n",
    "            pool_size=2,\n",
    "            name='maxpool_layer'\n",
    "        )(x)\n",
    "        # Flatten for dense layers\n",
    "        x = layers.Flatten(name='flatten_layer')(x)\n",
    "        \n",
    "        # Dense layers with dropout\n",
    "        x = layers.Dense(1024, activation='relu', name='cnn_dense1')(x)\n",
    "        x = layers.Dropout(0.2, name='cnn_dropout1')(x)\n",
    "        \n",
    "        x = layers.Dense(512, activation='relu', name='cnn_dense2')(x)\n",
    "        x = layers.Dropout(0.2, name='cnn_dropout2')(x)\n",
    "        \n",
    "        # Output layer\n",
    "        cnn_output = layers.Dense(\n",
    "            self.n_classes,\n",
    "            activation='softmax',\n",
    "            name='cnn_output'\n",
    "        )(x)\n",
    "        \n",
    "        return cnn_output\n",
    "    \n",
    "    def build_ensemble(self):\n",
    "        \"\"\"\n",
    "        Build the complete ensemble model\n",
    "        Combines LSTM and CNN branches\n",
    "        \"\"\"\n",
    "        # Input layer\n",
    "        inputs = layers.Input(shape=self.input_shape, name='input')\n",
    "        \n",
    "        # Build both branches\n",
    "        lstm_output = self.build_lstm_branch(inputs)\n",
    "        cnn_output = self.build_cnn_branch(inputs)\n",
    "        \n",
    "        # Ensemble: Average the predictions from both branches\n",
    "        ensemble_output = layers.Average(name='ensemble_average')([lstm_output, cnn_output])\n",
    "        \n",
    "        # Create model\n",
    "        self.model = models.Model(\n",
    "            inputs=inputs,\n",
    "            outputs=ensemble_output,\n",
    "            name='FallNet'\n",
    "        )\n",
    "        \n",
    "        return self.model\n",
    "    \n",
    "    def compile_model(self, learning_rate=None):\n",
    "        \"\"\"\n",
    "        Compile the model with Adam optimizer and categorical crossentropy\n",
    "        \"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Model not built yet. Call build_ensemble() first.\")\n",
    "        \n",
    "        # Use default Adam learning rate if not specified\n",
    "        optimizer = keras.optimizers.Adam(learning_rate=learning_rate) if learning_rate else keras.optimizers.Adam()\n",
    "        \n",
    "        self.model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy', \n",
    "                    keras.metrics.Precision(name='precision'),\n",
    "                    keras.metrics.Recall(name='recall')]\n",
    "        )\n",
    "        \n",
    "        return self.model\n",
    "    \n",
    "    def get_model(self):\n",
    "        \"\"\"Return the compiled model\"\"\"\n",
    "        return self.model\n",
    "\n",
    "print(\"‚úÖ FallNet class defined\")\n",
    "\n",
    "# %% [markdown]\n",
    "## 2. Build and Visualize the Model\n",
    "\n",
    "# %%\n",
    "# Create FallNet instance\n",
    "fallnet = FallNet(input_shape=(200, 6), n_classes=7)\n",
    "\n",
    "# Build the ensemble\n",
    "model = fallnet.build_ensemble()\n",
    "\n",
    "# Compile the model\n",
    "model = fallnet.compile_model()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FALLNET MODEL ARCHITECTURE\")\n",
    "print(\"=\"*80)\n",
    "model.summary()\n",
    "\n",
    "# %% [markdown]\n",
    "## 3. Visualize Model Architecture\n",
    "\n",
    "# %%\n",
    "# Plot model architecture\n",
    "try:\n",
    "    keras.utils.plot_model(\n",
    "        model,\n",
    "        to_file=output_dir / 'fallnet_architecture.png',\n",
    "        show_shapes=True,\n",
    "        show_layer_names=True,\n",
    "        rankdir='TB',  # Top to Bottom\n",
    "        expand_nested=True,\n",
    "        dpi=96\n",
    "    )\n",
    "    \n",
    "    from IPython.display import Image, display\n",
    "    display(Image(filename=str(output_dir / 'fallnet_architecture.png')))\n",
    "    print(f\"\\n‚úÖ Model architecture saved to {output_dir / 'fallnet_architecture.png'}\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not plot model (requires graphviz): {e}\")\n",
    "    print(\"Install with: pip install pydot graphviz\")\n",
    "\n",
    "# %% [markdown]\n",
    "## 4. Count Model Parameters  \n",
    "\n",
    "# %%\n",
    "def count_parameters(model):\n",
    "    \"\"\"Count trainable and non-trainable parameters\"\"\"\n",
    "    trainable = np.sum([np.prod(v.shape) for v in model.trainable_weights])\n",
    "    non_trainable = np.sum([np.prod(v.shape) for v in model.non_trainable_weights])\n",
    "    return trainable, non_trainable\n",
    "\n",
    "trainable, non_trainable = count_parameters(model)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL PARAMETERS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Trainable parameters:     {trainable:,}\")\n",
    "print(f\"Non-trainable parameters: {non_trainable:,}\")\n",
    "print(f\"Total parameters:         {trainable + non_trainable:,}\")\n",
    "\n",
    "# %% [markdown]\n",
    "## 5. Define Training Configuration\n",
    "\n",
    "# %%\n",
    "# Training hyperparameters from Table II\n",
    "BATCH_SIZE = 512\n",
    "EPOCHS = 200\n",
    "LEARNING_RATE = None  # Use default Adam learning rate\n",
    "\n",
    "\n",
    "fold_callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=20,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=10,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "            filepath=str(output_dir / f'fallnet_fold_{fold}.keras'),  # ‚Üê NOW fold exists!\n",
    "            monitor='val_accuracy',\n",
    "            save_best_only=True,\n",
    "            mode='max',\n",
    "            verbose=1\n",
    "    )\n",
    "        \n",
    "]\n",
    "\n",
    "\n",
    "print(\"‚úÖ Training configuration set:\")\n",
    "print(f\"   Batch size: {BATCH_SIZE}\")\n",
    "print(f\"   Epochs: {EPOCHS}\")\n",
    "print(f\"   Callbacks: Early Stopping, ReduceLROnPlateau, ModelCheckpoint\")\n",
    "\n",
    "# %% [markdown]\n",
    "## 6. Prepare Data for Training\n",
    "\n",
    "# %%\n",
    "# Load the preprocessed data\n",
    "X_data = np.load(processed_dir / \"X_data.npy\")\n",
    "y_labels = np.load(processed_dir / \"y_labels.npy\")\n",
    "\n",
    "print(f\"Loaded data:\")\n",
    "print(f\"  X shape: {X_data.shape}\")\n",
    "print(f\"  y shape: {y_labels.shape}\")\n",
    "\n",
    "# Convert labels to categorical (one-hot encoding)\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "#_categorical = to_categorical(y_labels, num_classes=7)\n",
    "print(f\"  y_categorical shape: {y_categorical.shape}\")\n",
    "\n",
    "# %% [markdown]\n",
    "## 7. Stratified K-Fold Cross-Validation Setup\n",
    "\n",
    "# %%\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Stratified K-Fold (K=5) as in the paper\n",
    "K_FOLDS = 5\n",
    "skf = StratifiedKFold(n_splits=K_FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "print(f\"\\n‚úÖ Stratified {K_FOLDS}-Fold Cross-Validation configured\")\n",
    "print(f\"   Total samples: {len(X_data):,}\")\n",
    "print(f\"   Samples per fold (approx): {len(X_data) // K_FOLDS:,}\")\n",
    "\n",
    "# %% [markdown]\n",
    "## 8. Training Loop with K-Fold CV\n",
    "\n",
    "# %%\n",
    "# Store results for each fold\n",
    "fold_results = []\n",
    "fold_histories = []\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STARTING K-FOLD CROSS-VALIDATION TRAINING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_data, y_labels), 1):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"FOLD {fold}/{K_FOLDS}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_val = X_data[train_idx], X_data[val_idx]\n",
    "    y_train, y_val = y_categorical[train_idx], y_categorical[val_idx]\n",
    "    \n",
    "    print(f\"Train set: {X_train.shape[0]:,} samples\")\n",
    "    print(f\"Val set:   {X_val.shape[0]:,} samples\")\n",
    "    \n",
    "    # Build a fresh model for this fold\n",
    "    fallnet_fold = FallNet(input_shape=(200, 6), n_classes=6)\n",
    "    model_fold = fallnet_fold.build_ensemble()\n",
    "    model_fold = fallnet_fold.compile_model()\n",
    "    \n",
    "    # Train the model\n",
    "    print(f\"\\nTraining fold {fold}...\")\n",
    "    history = model_fold.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epochs=EPOCHS,\n",
    "        callbacks=fold_callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    val_loss, val_acc, val_precision, val_recall = model_fold.evaluate(X_val, y_val, verbose=0)\n",
    "    \n",
    "    # Calculate F1-score\n",
    "    val_f1 = 2 * (val_precision * val_recall) / (val_precision + val_recall) if (val_precision + val_recall) > 0 else 0\n",
    "    \n",
    "    print(f\"\\n{'='*40}\")\n",
    "    print(f\"Fold {fold} Results:\")\n",
    "    print(f\"{'='*40}\")\n",
    "    print(f\"Validation Loss:      {val_loss:.4f}\")\n",
    "    print(f\"Validation Accuracy:  {val_acc:.4f}\")\n",
    "    print(f\"Validation Precision: {val_precision:.4f}\")\n",
    "    print(f\"Validation Recall:    {val_recall:.4f}\")\n",
    "    print(f\"Validation F1-Score:  {val_f1:.4f}\")\n",
    "    \n",
    "    # Store results\n",
    "    fold_results.append({\n",
    "        'fold': fold,\n",
    "        'val_loss': val_loss,\n",
    "        'val_accuracy': val_acc,\n",
    "        'val_precision': val_precision,\n",
    "        'val_recall': val_recall,\n",
    "        'val_f1': val_f1\n",
    "    })\n",
    "    \n",
    "    fold_histories.append(history.history)\n",
    "    \n",
    "    # Save model for this fold\n",
    "    model_fold.save(output_dir / f'fallnet_fold_{fold}.keras')\n",
    "    print(f\"\\n‚úÖ Model saved: fallnet_fold_{fold}.keras\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"K-FOLD CROSS-VALIDATION COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# %% [markdown]\n",
    "## 9. Aggregate Results Across Folds\n",
    "\n",
    "# %%\n",
    "# Convert to DataFrame\n",
    "results_df = pd.DataFrame(fold_results)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESULTS ACROSS ALL FOLDS\")\n",
    "print(\"=\"*80)\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AVERAGE PERFORMANCE\")\n",
    "print(\"=\"*80)\n",
    "mean_results = results_df.mean(numeric_only=True)\n",
    "std_results = results_df.std(numeric_only=True)\n",
    "\n",
    "for metric in ['val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_f1']:\n",
    "    print(f\"{metric:20s}: {mean_results[metric]:.4f} ¬± {std_results[metric]:.4f}\")\n",
    "\n",
    "# %% [markdown]\n",
    "## 10. Visualize Training History\n",
    "\n",
    "# %%\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "metrics = [\n",
    "    ('loss', 'Loss'),\n",
    "    ('accuracy', 'Accuracy'),\n",
    "    ('precision', 'Precision'),\n",
    "    ('recall', 'Recall')\n",
    "]\n",
    "\n",
    "for idx, (metric, title) in enumerate(metrics):\n",
    "    ax = axes[idx // 2, idx % 2]\n",
    "    \n",
    "    for fold, history in enumerate(fold_histories, 1):\n",
    "        epochs = range(1, len(history[metric]) + 1)\n",
    "        ax.plot(epochs, history[metric], label=f'Fold {fold} Train', alpha=0.6)\n",
    "        ax.plot(epochs, history[f'val_{metric}'], label=f'Fold {fold} Val', linestyle='--', alpha=0.6)\n",
    "    \n",
    "    ax.set_title(f'{title} Across All Folds', fontsize=12, fontweight='bold')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel(title)\n",
    "    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / 'training_history.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n‚úÖ Training history saved to {output_dir / 'training_history.png'}\")\n",
    "\n",
    "# %% [markdown]\n",
    "## 11. Compare with Paper Results\n",
    "\n",
    "# %%\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPARISON WITH PAPER RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "paper_results = {\n",
    "    'Accuracy': 0.9752,\n",
    "    'Precision (avg)': 0.9753,\n",
    "    'Recall (avg)': 0.9752,\n",
    "    'F1-score (avg)': 0.9750,\n",
    "    'Fall_Initiation Recall': 0.9924,\n",
    "    'Fall_Initiation F1': 0.9879\n",
    "}\n",
    "\n",
    "our_results = {\n",
    "    'Accuracy': mean_results['val_accuracy'],\n",
    "    'Precision (avg)': mean_results['val_precision'],\n",
    "    'Recall (avg)': mean_results['val_recall'],\n",
    "    'F1-score (avg)': mean_results['val_f1']\n",
    "}\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Metric': list(paper_results.keys())[:4],\n",
    "    'Paper': [paper_results[k] for k in list(paper_results.keys())[:4]],\n",
    "    'Our Implementation': [our_results[k] for k in our_results.keys()]\n",
    "})\n",
    "\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "print(\"\\nüìù Note: For detailed class-wise metrics (especially Fall_Initiation),\")\n",
    "print(\"   we need to generate a confusion matrix and classification report.\")\n",
    "\n",
    "# %%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # FallNet Training Pipeline\n",
    "# CNN-LSTM ensemble for fall detection with 6 classes\n",
    "\n",
    "# %%\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_score, recall_score, f1_score\n",
    "import warnings\n",
    "import gc\n",
    "warnings.filterwarnings('ignore')\n",
    "keras.backend.clear_session()\n",
    "gc.collect()\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU available: {tf.config.list_physical_devices('GPU')}\")\n",
    "\n",
    "# %% [markdown]\n",
    "## 1. FallNet Model Architecture\n",
    "\n",
    "# %%\n",
    "class FallNet:\n",
    "    \"\"\"\n",
    "    FallNet: CNN-LSTM Ensemble for Pre-Impact Fall Detection\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_shape=(200, 6), n_classes=6):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_shape: (timesteps, features) = (200, 6)\n",
    "            n_classes: Number of output classes (6)\n",
    "Skip to Main\n",
    "02_DataExplorationBothDataSets\n",
    "Last Checkpoint: 5 days ago\n",
    "[Python 3 (ipykernel)]\n",
    "\n",
    "import tensorflow as tf\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / 'training_history.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n‚úÖ Training history saved to {output_dir / 'training_history.png'}\")\n",
    "\n",
    "# %% [markdown]\n",
    "## 11. Compare with Paper Results\n",
    "\n",
    "# %%\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPARISON WITH PAPER RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "paper_results = {\n",
    "    'Accuracy': 0.9752,\n",
    "    'Precision (avg)': 0.9753,\n",
    "    'Recall (avg)': 0.9752,\n",
    "    'F1-score (avg)': 0.9750,\n",
    "    'Fall_Initiation Recall': 0.9924,\n",
    "    'Fall_Initiation F1': 0.9879\n",
    "}\n",
    "\n",
    "our_results = {\n",
    "    'Accuracy': mean_results['val_accuracy'],\n",
    "    'Precision (avg)': mean_results['val_precision'],\n",
    "    'Recall (avg)': mean_results['val_recall'],\n",
    "    'F1-score (avg)': mean_results['val_f1']\n",
    "}\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Metric': list(paper_results.keys())[:4],\n",
    "    'Paper': [paper_results[k] for k in list(paper_results.keys())[:4]],\n",
    "    'Our Implementation': [our_results[k] for k in our_results.keys()]\n",
    "})\n",
    "\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "print(\"\\nüìù Note: For detailed class-wise metrics (especially Fall_Initiation),\")\n",
    "print(\"   we need to generate a confusion matrix and classification report.\")\n",
    "\n",
    "# %%\n",
    "\n",
    "TensorFlow version: 2.20.0\n",
    "GPU available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
    "‚úÖ FallNet class defined\n",
    "\n",
    "================================================================================\n",
    "FALLNET MODEL ARCHITECTURE\n",
    "================================================================================\n",
    "\n",
    "Model: \"FallNet\"\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        self.input_shape = input_shape\n",
    "        self.n_classes = n_classes\n",
    "        self.model = None\n",
    "    \n",
    "    def build_lstm_branch(self, inputs):\n",
    "        \"\"\"LSTM Branch\"\"\"\n",
    "        x = layers.LSTM(\n",
    "            units=256,\n",
    "            activation='tanh',\n",
    "            return_sequences=False,\n",
    "            name='lstm_layer'\n",
    "        )(inputs)\n",
    "        \n",
    "        x = layers.Dense(128, activation='relu', name='lstm_dense1')(x)\n",
    "        x = layers.Dropout(0.2, name='lstm_dropout1')(x)\n",
    "        \n",
    "        x = layers.Dense(64, activation='relu', name='lstm_dense2')(x)\n",
    "        x = layers.Dropout(0.2, name='lstm_dropout2')(x)\n",
    "        \n",
    "        x = layers.Dense(32, activation='relu', name='lstm_dense3')(x)\n",
    "        x = layers.Dropout(0.2, name='lstm_dropout3')(x)\n",
    "        \n",
    "        lstm_output = layers.Dense(\n",
    "            self.n_classes, \n",
    "            activation='softmax',\n",
    "            name='lstm_output'\n",
    "        )(x)\n",
    "        \n",
    "        return lstm_output\n",
    "    \n",
    "    def build_cnn_branch(self, inputs):\n",
    "        \"\"\"CNN Branch\"\"\"\n",
    "        x = layers.Conv1D(\n",
    "            filters=128,\n",
    "            kernel_size=3,\n",
    "            activation='relu',\n",
    "            padding='same',\n",
    "            name='conv1d_layer'\n",
    "        )(inputs)\n",
    "        \n",
    "        x = layers.MaxPooling1D(pool_size=2, name='maxpool_layer')(x)\n",
    "        x = layers.Flatten(name='flatten_layer')(x)\n",
    "        \n",
    "        x = layers.Dense(1024, activation='relu', name='cnn_dense1')(x)\n",
    "        x = layers.Dropout(0.2, name='cnn_dropout1')(x)\n",
    "        \n",
    "        x = layers.Dense(512, activation='relu', name='cnn_dense2')(x)\n",
    "        x = layers.Dropout(0.2, name='cnn_dropout2')(x)\n",
    "        \n",
    "        cnn_output = layers.Dense(\n",
    "            self.n_classes,\n",
    "            activation='softmax',\n",
    "            name='cnn_output'\n",
    "        )(x)\n",
    "        \n",
    "        return cnn_output\n",
    "    \n",
    "    def build_ensemble(self):\n",
    "        \"\"\"Build the complete ensemble model\"\"\"\n",
    "        inputs = layers.Input(shape=self.input_shape, name='input')\n",
    "        \n",
    "        lstm_output = self.build_lstm_branch(inputs)\n",
    "        cnn_output = self.build_cnn_branch(inputs)\n",
    "        \n",
    "        ensemble_output = layers.Average(name='ensemble_average')([lstm_output, cnn_output])\n",
    "        \n",
    "        self.model = models.Model(\n",
    "            inputs=inputs,\n",
    "            outputs=ensemble_output,\n",
    "            name='FallNet'\n",
    "        )\n",
    "        \n",
    "        return self.model\n",
    "    \n",
    "    def compile_model(self, learning_rate=None):\n",
    "        \"\"\"Compile model\"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Model not built yet. Call build_ensemble() first.\")\n",
    "        \n",
    "        optimizer = keras.optimizers.Adam(learning_rate=learning_rate) if learning_rate else keras.optimizers.Adam()\n",
    "        \n",
    "        self.model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=[\n",
    "                'accuracy', \n",
    "                keras.metrics.Precision(name='precision'),\n",
    "                keras.metrics.Recall(name='recall')\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        return self.model\n",
    "\n",
    "print(\"‚úÖ FallNet class defined\")\n",
    "\n",
    "# %% [markdown]\n",
    "## 2. Build and Display Model\n",
    "\n",
    "# %%\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BUILDING FALLNET MODEL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create instance with 6 classes\n",
    "fallnet = FallNet(input_shape=(200, 6), n_classes=6)\n",
    "\n",
    "# Build ensemble\n",
    "model = fallnet.build_ensemble()\n",
    "\n",
    "# Compile\n",
    "model = fallnet.compile_model()\n",
    "\n",
    "# Display architecture\n",
    "print(\"\\n\")\n",
    "model.summary()\n",
    "\n",
    "# Count parameters\n",
    "def count_parameters(model):\n",
    "    trainable = np.sum([np.prod(v.shape) for v in model.trainable_weights])\n",
    "    non_trainable = np.sum([np.prod(v.shape) for v in model.non_trainable_weights])\n",
    "    return trainable, non_trainable\n",
    "\n",
    "trainable, non_trainable = count_parameters(model)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL PARAMETERS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Trainable:     {trainable:,}\")\n",
    "print(f\"Non-trainable: {non_trainable:,}\")\n",
    "print(f\"Total:         {trainable + non_trainable:,}\")\n",
    "\n",
    "# %% [markdown]\n",
    "## 3. Training Configuration\n",
    "\n",
    "# %%\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 200\n",
    "K_FOLDS = 5\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAINING CONFIGURATION\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "print(f\"Max epochs: {EPOCHS}\")\n",
    "print(f\"K-Folds:    {K_FOLDS}\")\n",
    "print(f\"Using data from previous cell (6 classes, {len(y_labels):,} samples)\")\n",
    "\n",
    "# %% [markdown]\n",
    "## 4. Verify Data Before Training\n",
    "\n",
    "# %%\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PRE-TRAINING VERIFICATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"‚úÖ Data shapes:\")\n",
    "print(f\"   X_data:        {X_data.shape}\")\n",
    "print(f\"   y_labels:      {y_labels.shape}\")\n",
    "print(f\"   y_categorical: {y_categorical.shape}\")\n",
    "print(f\"\\n‚úÖ Classes: {len(np.unique(y_labels))} (should be 6)\")\n",
    "print(f\"‚úÖ Label range: {y_labels.min()}-{y_labels.max()} (should be 0-5)\")\n",
    "print(f\"‚úÖ Model output: {model.output_shape[-1]} (should be 6)\")\n",
    "\n",
    "assert X_data.shape[0] == y_labels.shape[0] == y_categorical.shape[0], \"Shape mismatch!\"\n",
    "assert len(np.unique(y_labels)) == 6, \"Should have 6 classes!\"\n",
    "assert y_labels.max() == 5, \"Max label should be 5!\"\n",
    "assert model.output_shape[-1] == 6, \"Model should output 6 classes!\"\n",
    "\n",
    "print(\"\\n‚úÖ All checks passed - ready to train!\")\n",
    "\n",
    "# %% [markdown]\n",
    "## 5. K-Fold Cross-Validation Training\n",
    "\n",
    "# %%\n",
    "skf = StratifiedKFold(n_splits=K_FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "fold_results = []\n",
    "fold_histories = []\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STARTING K-FOLD CROSS-VALIDATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_data, y_labels), 1):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"FOLD {fold}/{K_FOLDS}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_val = X_data[train_idx], X_data[val_idx]\n",
    "    y_train, y_val = y_categorical[train_idx], y_categorical[val_idx]\n",
    "    \n",
    "    print(f\"Train: {X_train.shape[0]:,} samples | Val: {X_val.shape[0]:,} samples\")\n",
    "    \n",
    "    # Build fresh model for this fold\n",
    "    fallnet_fold = FallNet(input_shape=(200, 6), n_classes=6)\n",
    "    model_fold = fallnet_fold.build_ensemble()\n",
    "    model_fold = fallnet_fold.compile_model()\n",
    "    \n",
    "    # Define callbacks for THIS fold\n",
    "    fold_callbacks = [\n",
    "        EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=20,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=10,\n",
    "            min_lr=1e-7,\n",
    "            verbose=1\n",
    "        ),\n",
    "        ModelCheckpoint(\n",
    "            filepath=str(output_dir / f'fallnet_fold_cnn_lstm_original{fold}.keras'),\n",
    "            monitor='val_accuracy',\n",
    "            save_best_only=True,\n",
    "            mode='max',\n",
    "            verbose=1\n",
    "        )\n",
    "    ]\n",
    "    # %% [markdown]\n",
    "## 5.5 Calculate Class Weights\n",
    "\n",
    "# %%\n",
    "    from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"CALCULATING CLASS WEIGHTS\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "# Calculate balanced weights\n",
    "    class_weights_array = compute_class_weight(\n",
    "        class_weight='balanced',\n",
    "        classes=np.unique(y_labels),\n",
    "        y=y_labels\n",
    "    )\n",
    "\n",
    "# Cap at 3x to prevent training instability\n",
    "    MAX_WEIGHT = 3.0\n",
    "    class_weights_array_capped = np.clip(class_weights_array, None, MAX_WEIGHT)\n",
    "    class_weights = dict(enumerate(class_weights_array_capped))\n",
    "\n",
    "    print(\"\\nClass Distribution:\")\n",
    "    from collections import Counter\n",
    "    counts = Counter(y_labels)\n",
    "    for cls_idx in range(6):\n",
    "        count = counts[cls_idx]\n",
    "        pct = count / len(y_labels) * 100\n",
    "        weight = class_weights[cls_idx]\n",
    "        print(f\"  {reverse_label_map[cls_idx]:<30s}: {count:>5d} ({pct:>5.2f}%) ‚Üí weight: {weight:.2f}x\")\n",
    "\n",
    "    print(f\"\\n‚úÖ Weight range: {min(class_weights.values()):.2f}x to {max(class_weights.values()):.2f}x\")\n",
    "    print(f\"‚úÖ Max/Min ratio: {max(class_weights.values())/min(class_weights.values()):.2f}x (was 4.0x without capping)\")\n",
    "    # Train WITHOUT class weights\n",
    "    print(f\"\\nTraining fold {fold}...\")\n",
    "    history = model_fold.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epochs=EPOCHS,\n",
    "        class_weight=class_weights,  # ‚Üê ADD THIS LINE!\n",
    "        callbacks=fold_callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Evaluate\n",
    "    val_loss, val_acc, val_precision, val_recall = model_fold.evaluate(X_val, y_val, verbose=0)\n",
    "    val_f1 = 2 * (val_precision * val_recall) / (val_precision + val_recall) if (val_precision + val_recall) > 0 else 0\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Fold {fold} Results:\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"Loss:      {val_loss:.4f}\")\n",
    "    print(f\"Accuracy:  {val_acc:.4f}\")\n",
    "    print(f\"Precision: {val_precision:.4f}\")\n",
    "    print(f\"Recall:    {val_recall:.4f}\")\n",
    "    print(f\"F1-Score:  {val_f1:.4f}\")\n",
    "    \n",
    "    # Store results\n",
    "    fold_results.append({\n",
    "        'fold': fold,\n",
    "        'val_loss': val_loss,\n",
    "        'val_accuracy': val_acc,\n",
    "        'val_precision': val_precision,\n",
    "        'val_recall': val_recall,\n",
    "        'val_f1': val_f1\n",
    "    })\n",
    "    \n",
    "    fold_histories.append(history.history)\n",
    "    \n",
    "    print(f\"‚úÖ Model saved: fallnet_fold_cnn_lstm_{fold}.keras\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"K-FOLD CROSS-VALIDATION COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# %% [markdown]\n",
    "## 6. Aggregate Results\n",
    "\n",
    "# %%\n",
    "results_df = pd.DataFrame(fold_results)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESULTS ACROSS ALL FOLDS\")\n",
    "print(\"=\"*80)\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AVERAGE PERFORMANCE ¬± STD\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "mean_results = results_df.mean(numeric_only=True)\n",
    "std_results = results_df.std(numeric_only=True)\n",
    "\n",
    "metrics_table = []\n",
    "for metric in ['val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_f1']:\n",
    "    metrics_table.append({\n",
    "        'Metric': metric,\n",
    "        'Mean': f\"{mean_results[metric]:.4f}\",\n",
    "        'Std': f\"¬±{std_results[metric]:.4f}\"\n",
    "    })\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics_table)\n",
    "print(metrics_df.to_string(index=False))\n",
    "\n",
    "# %% [markdown]\n",
    "## 7. Visualize Training History\n",
    "\n",
    "# %%\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "metrics = [\n",
    "    ('loss', 'Loss'),\n",
    "    ('accuracy', 'Accuracy'),\n",
    "    ('precision', 'Precision'),\n",
    "    ('recall', 'Recall')\n",
    "]\n",
    "\n",
    "for idx, (metric, title) in enumerate(metrics):\n",
    "    ax = axes[idx // 2, idx % 2]\n",
    "    \n",
    "    for fold, history in enumerate(fold_histories, 1):\n",
    "        epochs = range(1, len(history[metric]) + 1)\n",
    "        ax.plot(epochs, history[metric], label=f'Fold {fold} Train', alpha=0.5, linewidth=1)\n",
    "        ax.plot(epochs, history[f'val_{metric}'], label=f'Fold {fold} Val', \n",
    "                linestyle='--', alpha=0.7, linewidth=1.5)\n",
    "    \n",
    "    ax.set_title(f'{title} Across All Folds', fontsize=13, fontweight='bold')\n",
    "    ax.set_xlabel('Epoch', fontsize=11)\n",
    "    ax.set_ylabel(title, fontsize=11)\n",
    "    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=7)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('FallNet Training History - 5-Fold Cross-Validation', \n",
    "             fontsize=15, fontweight='bold', y=0.995)\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / 'training_history.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"‚úÖ Training history saved to {output_dir / 'training_history.png'}\")\n",
    "\n",
    "# %% [markdown]\n",
    "## 8. Detailed Evaluation on Best Fold\n",
    "\n",
    "# %%\n",
    "best_fold = int(results_df.loc[results_df['val_f1'].idxmax(), 'fold'])\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"DETAILED EVALUATION - BEST FOLD #{best_fold}\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Best fold F1-Score: {results_df.loc[results_df['fold']==best_fold, 'val_f1'].values[0]:.4f}\")\n",
    "\n",
    "# Load best model\n",
    "best_model = keras.models.load_model(output_dir / f'fallnet_fold_{best_fold}.keras')\n",
    "\n",
    "# Get predictions on ALL data\n",
    "y_pred_probs = best_model.predict(X_data, verbose=0)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "# Classification report\n",
    "class_names = [reverse_label_map[i] for i in range(6)]\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CLASSIFICATION REPORT (Best Fold on All Data)\")\n",
    "print(\"=\"*80)\n",
    "print(classification_report(y_labels, y_pred, target_names=class_names, digits=4))\n",
    "\n",
    "# %% [markdown]\n",
    "## 9. Per-Class Detailed Metrics\n",
    "\n",
    "# %%\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PER-CLASS DETAILED METRICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n{'Class':<40s} {'Precision':<12s} {'Recall':<12s} {'F1-Score':<12s} {'Support'}\")\n",
    "print(\"-\"*90)\n",
    "\n",
    "for cls_idx in range(6):\n",
    "    precision = precision_score(y_labels == cls_idx, y_pred == cls_idx, zero_division=0)\n",
    "    recall = recall_score(y_labels == cls_idx, y_pred == cls_idx, zero_division=0)\n",
    "    f1 = f1_score(y_labels == cls_idx, y_pred == cls_idx, zero_division=0)\n",
    "    support = np.sum(y_labels == cls_idx)\n",
    "    \n",
    "    print(f\"{reverse_label_map[cls_idx]:<40s} {precision:<12.4f} {recall:<12.4f} {f1:<12.4f} {support}\")\n",
    "\n",
    "# %% [markdown]\n",
    "## 10. Confusion Matrix\n",
    "\n",
    "# %%\n",
    "cm = confusion_matrix(y_labels, y_pred)\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(\n",
    "    cm, \n",
    "    annot=True, \n",
    "    fmt='d', \n",
    "    cmap='Blues',\n",
    "    xticklabels=class_names,\n",
    "    yticklabels=class_names,\n",
    "    cbar_kws={'label': 'Count'}\n",
    ")\n",
    "plt.title('Confusion Matrix - Best Fold (6 Classes)', fontsize=15, fontweight='bold', pad=20)\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right', fontsize=10)\n",
    "plt.yticks(rotation=0, fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / 'confusion_matrix_cnn_lstm.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"‚úÖ Confusion matrix saved to {output_dir / 'confusion_matrix_lstm.png'}\")\n",
    "\n",
    "# %% [markdown]\n",
    "## 11. Final Summary\n",
    "\n",
    "# %%\n",
    "# Get Fall_Initiation metrics\n",
    "fall_init_idx = label_map[\"Fall_Initiation\"]\n",
    "fall_init_precision = precision_score(y_labels == fall_init_idx, y_pred == fall_init_idx)\n",
    "fall_init_recall = recall_score(y_labels == fall_init_idx, y_pred == fall_init_idx)\n",
    "fall_init_f1 = f1_score(y_labels == fall_init_idx, y_pred == fall_init_idx)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAINING COMPLETE - FINAL SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "summary = f\"\"\"\n",
    "‚úÖ Successfully trained FallNet with 5-fold cross-validation\n",
    "\n",
    "Configuration:\n",
    "  - Model: CNN-LSTM Ensemble (6 classes)\n",
    "  - Total samples: {len(y_labels):,}\n",
    "  - Training samples per fold: ~{len(y_labels)*0.8//K_FOLDS:,.0f}\n",
    "  - Validation samples per fold: ~{len(y_labels)*0.2//K_FOLDS:,.0f}\n",
    "\n",
    "Average Performance (5-fold CV):\n",
    "  - Accuracy:  {mean_results['val_accuracy']:.4f} ¬± {std_results['val_accuracy']:.4f}\n",
    "  - Precision: {mean_results['val_precision']:.4f} ¬± {std_results['val_precision']:.4f}\n",
    "  - Recall:    {mean_results['val_recall']:.4f} ¬± {std_results['val_recall']:.4f}\n",
    "  - F1-Score:  {mean_results['val_f1']:.4f} ¬± {std_results['val_f1']:.4f}\n",
    "\n",
    "Fall_Initiation Performance (Critical Class):\n",
    "  - Recall (Sensitivity): {fall_init_recall:.4f}\n",
    "  - F1-Score:             {fall_init_f1:.4f}\n",
    "\n",
    "Saved Files:\n",
    "  - Training history:    {output_dir / 'training_history.png'}\n",
    "  - Confusion matrix:    {output_dir / 'confusion_matrix.png'}\n",
    "  - Best model:          {output_dir / f'fallnet_fold_cnn_lstm{best_fold}.keras'}\n",
    "  - All fold models:     {output_dir / 'fallnet_fold_*.keras'}\n",
    "\"\"\"\n",
    "\n",
    "print(summary)\n",
    "\n",
    "with open(output_dir / 'training_summary_cnn_lstm.txt', 'w') as f:\n",
    "    f.write(summary)\n",
    "\n",
    "print(f\"‚úÖ Summary saved to {output_dir / 'training_summary.txt'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "model_dir = Path.home() / 'repos/summerschool2023/projects/fall-detection/fall_detection_data/models'\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"DETAILED ANALYSIS: Fold 1 - fallnet_fold_cnn_lstm_original1.keras\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "class_names = ['Walking', 'Jogging', 'Walking_stairs_updown', \n",
    "               'Stumble_while_walking', 'Fall_Initiation', 'Impact_Aftermath']\n",
    "\n",
    "# Get Fold 1 validation data\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_data, y_labels), 1):\n",
    "    if fold == 1:  # Only Fold 1\n",
    "        X_val = X_data[val_idx]\n",
    "        y_val = y_labels[val_idx]\n",
    "        y_val_cat = y_categorical[val_idx]\n",
    "        \n",
    "        print(f\"\\nValidation set size: {len(X_val)}\")\n",
    "        print(f\"\\nClass distribution in Fold 1 validation:\")\n",
    "        for i, class_name in enumerate(class_names):\n",
    "            count = np.sum(y_val == i)\n",
    "            print(f\"  {class_name:30s}: {count:4d} samples\")\n",
    "        \n",
    "        # Load model\n",
    "        model_path = model_dir / 'fallnet_fold_cnn_lstm_original1.keras'\n",
    "        print(f\"\\nLoading: {model_path.name}\")\n",
    "        model = tf.keras.models.load_model(model_path)\n",
    "        \n",
    "        # Predict\n",
    "        print(\"Predicting...\")\n",
    "        y_pred_proba = model.predict(X_val, batch_size=64, verbose=0)\n",
    "        y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "        \n",
    "        # Overall metrics\n",
    "        val_loss, val_acc, val_precision, val_recall = model.evaluate(\n",
    "            X_val, y_val_cat, batch_size=64, verbose=0\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nOverall Metrics:\")\n",
    "        print(f\"  Accuracy:  {val_acc:.4f} ({val_acc*100:.2f}%)\")\n",
    "        print(f\"  Precision: {val_precision:.4f}\")\n",
    "        print(f\"  Recall:    {val_recall:.4f}\")\n",
    "        \n",
    "        # Detailed classification report\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"CLASSIFICATION REPORT\")\n",
    "        print(\"=\"*80)\n",
    "        report = classification_report(y_val, y_pred, target_names=class_names, digits=4)\n",
    "        print(report)\n",
    "        \n",
    "        # Focus on Fall_Initiation\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"FALL_INITIATION DETAILED ANALYSIS\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        fall_init_idx = 4  # Fall_Initiation is class 4\n",
    "        fall_init_mask = (y_val == fall_init_idx)\n",
    "        fall_init_true = y_val[fall_init_mask]\n",
    "        fall_init_pred = y_pred[fall_init_mask]\n",
    "        \n",
    "        total_falls = len(fall_init_true)\n",
    "        correct_falls = np.sum(fall_init_pred == fall_init_idx)\n",
    "        \n",
    "        print(f\"\\nTotal Fall_Initiation samples: {total_falls}\")\n",
    "        print(f\"Correctly predicted as falls:  {correct_falls} ({correct_falls/total_falls*100:.2f}%)\")\n",
    "        print(f\"Incorrectly predicted:          {total_falls - correct_falls} ({(total_falls-correct_falls)/total_falls*100:.2f}%)\")\n",
    "        \n",
    "        print(f\"\\nWhat did the model predict instead?\")\n",
    "        for i, class_name in enumerate(class_names):\n",
    "            count = np.sum(fall_init_pred == i)\n",
    "            if count > 0:\n",
    "                print(f\"  Predicted as {class_name:30s}: {count:4d} ({count/total_falls*100:.2f}%)\")\n",
    "        \n",
    "        # Confusion matrix\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"CONFUSION MATRIX\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        cm = confusion_matrix(y_val, y_pred)\n",
    "        \n",
    "        # Print Fall_Initiation row specifically\n",
    "        print(f\"\\nFall_Initiation (row 4) predictions:\")\n",
    "        for i, class_name in enumerate(class_names):\n",
    "            print(f\"  Predicted as {class_name:30s}: {cm[fall_init_idx, i]:4d}\")\n",
    "        \n",
    "        # Visualize confusion matrix\n",
    "        fig, ax = plt.subplots(figsize=(10, 8))\n",
    "        \n",
    "        cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        \n",
    "        sns.heatmap(cm_normalized, annot=True, fmt='.3f', cmap='Blues',\n",
    "                   xticklabels=class_names, yticklabels=class_names,\n",
    "                   ax=ax, cbar_kws={'label': 'Proportion'})\n",
    "        \n",
    "        ax.set_title('Fold 1 CNN-LSTM Confusion Matrix (Normalized)', \n",
    "                    fontsize=14, fontweight='bold')\n",
    "        ax.set_ylabel('True Label', fontsize=12)\n",
    "        ax.set_xlabel('Predicted Label', fontsize=12)\n",
    "        plt.setp(ax.get_xticklabels(), rotation=45, ha='right')\n",
    "        plt.setp(ax.get_yticklabels(), rotation=0)\n",
    "        \n",
    "        # Highlight Fall_Initiation row\n",
    "        ax.add_patch(plt.Rectangle((0, fall_init_idx), 6, 1, \n",
    "                                   fill=False, edgecolor='red', lw=3))\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(model_dir / 'fold1_confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"\\n‚úì Confusion matrix saved: {model_dir / 'fold1_confusion_matrix.png'}\")\n",
    "        \n",
    "        # Show prediction confidence for Fall_Initiation samples\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"PREDICTION CONFIDENCE ANALYSIS\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        fall_init_proba = y_pred_proba[fall_init_mask]\n",
    "        \n",
    "        print(f\"\\nFor the {total_falls} Fall_Initiation samples:\")\n",
    "        print(f\"  Mean confidence in Fall_Initiation class: {fall_init_proba[:, fall_init_idx].mean():.4f}\")\n",
    "        print(f\"  Max confidence in Fall_Initiation class:  {fall_init_proba[:, fall_init_idx].max():.4f}\")\n",
    "        print(f\"  Min confidence in Fall_Initiation class:  {fall_init_proba[:, fall_init_idx].min():.4f}\")\n",
    "        \n",
    "        # Find what the model is most confident about for these fall samples\n",
    "        most_confident_class = np.argmax(fall_init_proba, axis=1)\n",
    "        print(f\"\\nWhat class does the model think these falls are?\")\n",
    "        for i, class_name in enumerate(class_names):\n",
    "            count = np.sum(most_confident_class == i)\n",
    "            if count > 0:\n",
    "                avg_conf = fall_init_proba[most_confident_class == i, i].mean()\n",
    "                print(f\"  {class_name:30s}: {count:4d} samples (avg confidence: {avg_conf:.4f})\")\n",
    "        \n",
    "        break\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FOLD 1 ANALYSIS COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from pathlib import Path\n",
    "\n",
    "model_dir = Path.home() / 'repos/summerschool2023/projects/fall-detection/fall_detection_data/models'\n",
    "\n",
    "# Check the specific file\n",
    "model_path = model_dir / 'fallnet_fold_cnn_lstm_original5.keras'\n",
    "\n",
    "print(f\"Checking: {model_path.name}\")\n",
    "print(f\"File exists: {model_path.exists()}\")\n",
    "\n",
    "if model_path.exists():\n",
    "    print(f\"File size: {model_path.stat().st_size / (1024*1024):.1f} MB\")\n",
    "    print(f\"Modified: {model_path.stat().st_mtime}\")\n",
    "    \n",
    "    # Load it\n",
    "    try:\n",
    "        print(\"\\nLoading model...\")\n",
    "        model = tf.keras.models.load_model(model_path)\n",
    "        print(\"‚úì Model loaded successfully\")\n",
    "        \n",
    "        # Check architecture\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"MODEL SUMMARY\")\n",
    "        print(\"=\"*80)\n",
    "        model.summary()\n",
    "        \n",
    "        # Evaluate on Fold 5 validation data\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"EVALUATING ON FOLD 5 VALIDATION DATA\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        \n",
    "        for fold, (train_idx, val_idx) in enumerate(skf.split(X_data, y_labels), 1):\n",
    "            if fold == 5:  # Only check fold 5\n",
    "                X_val = X_data[val_idx]\n",
    "                y_val = y_labels[val_idx]\n",
    "                y_val_cat = y_categorical[val_idx]\n",
    "                \n",
    "                # Predict\n",
    "                y_pred_proba = model.predict(X_val, batch_size=64, verbose=1)\n",
    "                y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "                \n",
    "                # Evaluate\n",
    "                val_loss, val_acc, val_precision, val_recall = model.evaluate(\n",
    "                    X_val, y_val_cat, batch_size=64, verbose=0\n",
    "                )\n",
    "                \n",
    "                print(f\"\\nFold 5 Results:\")\n",
    "                print(f\"  Accuracy:  {val_acc:.4f} ({val_acc*100:.2f}%)\")\n",
    "                print(f\"  Precision: {val_precision:.4f}\")\n",
    "                print(f\"  Recall:    {val_recall:.4f}\")\n",
    "                print(f\"  Loss:      {val_loss:.4f}\")\n",
    "                \n",
    "                # Detailed classification report\n",
    "                class_names = ['Walking', 'Jogging', 'Walking_stairs_updown', \n",
    "                              'Stumble_while_walking', 'Fall_Initiation', 'Impact_Aftermath']\n",
    "                \n",
    "                print(\"\\n\" + \"=\"*80)\n",
    "                print(\"DETAILED CLASSIFICATION REPORT\")\n",
    "                print(\"=\"*80)\n",
    "                \n",
    "                report = classification_report(\n",
    "                    y_val, y_pred,\n",
    "                    target_names=class_names,\n",
    "                    digits=3\n",
    "                )\n",
    "                print(report)\n",
    "                \n",
    "                break\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚úó Error loading model: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "# Also check what other \"original\" models exist\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ALL 'ORIGINAL' MODEL FILES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for model_file in sorted(model_dir.glob(\"*original*.keras\")):\n",
    "    print(f\"{model_file.name:50s} {model_file.stat().st_size / (1024*1024):6.1f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "import gc\n",
    "\n",
    "# Clear Keras session\n",
    "K.clear_session()\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Force garbage collection\n",
    "gc.collect()\n",
    "\n",
    "# Try to reset GPU memory stats (if available)\n",
    "try:\n",
    "    tf.config.experimental.reset_memory_stats('GPU:0')\n",
    "    print(\"‚úì GPU memory stats reset\")\n",
    "except:\n",
    "    print(\"‚ö†Ô∏è  Could not reset GPU memory stats\")\n",
    "\n",
    "print(\"‚úì Memory cleared\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "model_dir = Path.home() / 'repos/summerschool2023/projects/fall-detection/fall_detection_data/models'\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"EVALUATING ALL 5: fallnet_fold_cnn_lstm_original[1-5].keras\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "class_names = ['Walking', 'Jogging', 'Walking_stairs_updown', \n",
    "               'Stumble_while_walking', 'Fall_Initiation', 'Impact_Aftermath']\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "all_y_true = []\n",
    "all_y_pred = []\n",
    "fold_results = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_data, y_labels), 1):\n",
    "    model_path = model_dir / f'fallnet_fold_cnn_lstm_{fold}.keras'\n",
    "    \n",
    "    if not model_path.exists():\n",
    "        print(f\"\\nFold {fold}: ‚úó File not found: {model_path.name}\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"FOLD {fold}: {model_path.name}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"File size: {model_path.stat().st_size / (1024*1024):.1f} MB\")\n",
    "    \n",
    "    try:\n",
    "        # Load model\n",
    "        print(\"Loading model...\", end=' ')\n",
    "        model = tf.keras.models.load_model(model_path)\n",
    "        print(\"‚úì\")\n",
    "        \n",
    "        # Get validation data\n",
    "        X_val = X_data[val_idx]\n",
    "        y_val = y_labels[val_idx]\n",
    "        y_val_cat = y_categorical[val_idx]\n",
    "        \n",
    "        print(f\"Validation samples: {len(X_val)}\")\n",
    "        \n",
    "        # Predict\n",
    "        print(\"Predicting...\", end=' ')\n",
    "        y_pred_proba = model.predict(X_val, batch_size=64, verbose=0)\n",
    "        y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "        print(\"‚úì\")\n",
    "        \n",
    "        # Evaluate\n",
    "        print(\"Evaluating...\", end=' ')\n",
    "        val_loss, val_acc, val_precision, val_recall = model.evaluate(\n",
    "            X_val, y_val_cat, batch_size=64, verbose=0\n",
    "        )\n",
    "        print(\"‚úì\")\n",
    "        \n",
    "        # Get per-class metrics for this fold\n",
    "        report_dict = classification_report(\n",
    "            y_val, y_pred,\n",
    "            target_names=class_names,\n",
    "            output_dict=True,\n",
    "            zero_division=0\n",
    "        )\n",
    "        \n",
    "        fall_init_recall = report_dict['Fall_Initiation']['recall']\n",
    "        fall_init_f1 = report_dict['Fall_Initiation']['f1-score']\n",
    "        fall_init_precision = report_dict['Fall_Initiation']['precision']\n",
    "        \n",
    "        print(f\"\\nResults:\")\n",
    "        print(f\"  Overall Accuracy:       {val_acc:.4f} ({val_acc*100:.2f}%)\")\n",
    "        print(f\"  Overall Precision:      {val_precision:.4f}\")\n",
    "        print(f\"  Overall Recall:         {val_recall:.4f}\")\n",
    "        print(f\"  Loss:                   {val_loss:.4f}\")\n",
    "        print(f\"\\n  Fall_Initiation:\")\n",
    "        print(f\"    Precision: {fall_init_precision:.4f}\")\n",
    "        print(f\"    Recall:    {fall_init_recall:.4f} ({'‚úì' if fall_init_recall > 0.90 else '‚úó'})\")\n",
    "        print(f\"    F1-Score:  {fall_init_f1:.4f}\")\n",
    "        \n",
    "        # Store results\n",
    "        all_y_true.extend(y_val)\n",
    "        all_y_pred.extend(y_pred)\n",
    "        fold_results.append({\n",
    "            'fold': fold,\n",
    "            'accuracy': val_acc,\n",
    "            'precision': val_precision,\n",
    "            'recall': val_recall,\n",
    "            'loss': val_loss,\n",
    "            'fall_init_precision': fall_init_precision,\n",
    "            'fall_init_recall': fall_init_recall,\n",
    "            'fall_init_f1': fall_init_f1\n",
    "        })\n",
    "        \n",
    "        # Clear memory\n",
    "        del model\n",
    "        tf.keras.backend.clear_session()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚úó Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "# ============================================================================\n",
    "# SUMMARY\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY: ALL 5 FOLDS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if len(fold_results) > 0:\n",
    "    df = pd.DataFrame(fold_results)\n",
    "    \n",
    "    # Format table nicely\n",
    "    print(\"\\nPer-Fold Results:\")\n",
    "    print(df.to_string(index=False, float_format=lambda x: f'{x:.4f}'))\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"AVERAGE PERFORMANCE ¬± STANDARD DEVIATION\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Overall Accuracy:          {df['accuracy'].mean():.4f} ¬± {df['accuracy'].std():.4f}\")\n",
    "    print(f\"Overall Precision:         {df['precision'].mean():.4f} ¬± {df['precision'].std():.4f}\")\n",
    "    print(f\"Overall Recall:            {df['recall'].mean():.4f} ¬± {df['recall'].std():.4f}\")\n",
    "    print(f\"Loss:                      {df['loss'].mean():.4f} ¬± {df['loss'].std():.4f}\")\n",
    "    print(f\"\\nFall_Initiation Precision: {df['fall_init_precision'].mean():.4f} ¬± {df['fall_init_precision'].std():.4f}\")\n",
    "    print(f\"Fall_Initiation Recall:    {df['fall_init_recall'].mean():.4f} ¬± {df['fall_init_recall'].std():.4f}\")\n",
    "    print(f\"Fall_Initiation F1:        {df['fall_init_f1'].mean():.4f} ¬± {df['fall_init_f1'].std():.4f}\")\n",
    "    \n",
    "    # Best and worst folds\n",
    "    best_fold = df.loc[df['accuracy'].idxmax()]\n",
    "    worst_fold = df.loc[df['accuracy'].idxmin()]\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"BEST & WORST FOLDS\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Best:  Fold {best_fold['fold']:.0f} - {best_fold['accuracy']:.4f} ({best_fold['accuracy']*100:.2f}%)\")\n",
    "    print(f\"Worst: Fold {worst_fold['fold']:.0f} - {worst_fold['accuracy']:.4f} ({worst_fold['accuracy']*100:.2f}%)\")\n",
    "    print(f\"Range: {(best_fold['accuracy'] - worst_fold['accuracy'])*100:.2f}%\")\n",
    "\n",
    "# Detailed per-class performance (all folds combined)\n",
    "if len(all_y_true) > 0:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"DETAILED PER-CLASS PERFORMANCE (ALL FOLDS COMBINED)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    report = classification_report(\n",
    "        all_y_true, all_y_pred,\n",
    "        target_names=class_names,\n",
    "        digits=3\n",
    "    )\n",
    "    print(report)\n",
    "    \n",
    "    # Get report as dict\n",
    "    report_dict = classification_report(\n",
    "        all_y_true, all_y_pred,\n",
    "        target_names=class_names,\n",
    "        output_dict=True\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"CLASSES RANKED BY F1-SCORE (WORST TO BEST)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    class_f1 = [(cn, report_dict[cn]['f1-score'], report_dict[cn]['recall']) \n",
    "                for cn in class_names]\n",
    "    class_f1.sort(key=lambda x: x[1])\n",
    "    \n",
    "    for cn, f1, recall in class_f1:\n",
    "        print(f\"{cn:30s}: F1={f1:.3f}, Recall={recall:.3f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# COMPARISON TO OTHER MODELS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPARISON TO OTHER MODELS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if len(fold_results) > 0:\n",
    "    avg_acc = df['accuracy'].mean()\n",
    "    avg_std = df['accuracy'].std()\n",
    "    \n",
    "    print(f\"CNN-LSTM 'original':  {avg_acc:.4f} ¬± {avg_std:.4f} ({avg_acc*100:.2f}%)\")\n",
    "    print(f\"CNN-only:             0.8998 ¬± 0.0042 (89.98%)\")\n",
    "    print(f\"CNN-LMU:              0.8997 ¬± 0.0029 (89.97%)\")\n",
    "    print(f\"CNN-LSTM 'ensemble':  0.8858 ¬± 0.0385 (88.58%)\")\n",
    "    print(f\"\\nPaper target:         0.9752 (97.52%)\")\n",
    "    \n",
    "    # Determine winner\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    if avg_acc > 0.8998:\n",
    "        print(f\"üèÜ CNN-LSTM 'original' WINS!\")\n",
    "        print(f\"   Better than CNN-only by: +{(avg_acc - 0.8998)*100:.2f}%\")\n",
    "    elif avg_acc > 0.8997 and avg_acc <= 0.8998:\n",
    "        print(f\"‚öñÔ∏è  CNN-LSTM 'original' ties with CNN-only\")\n",
    "        print(f\"   Difference: {(avg_acc - 0.8998)*100:.2f}%\")\n",
    "    else:\n",
    "        print(f\"‚ùå CNN-LSTM 'original' loses to CNN-only\")\n",
    "        print(f\"   Worse by: {(avg_acc - 0.8998)*100:.2f}%\")\n",
    "    \n",
    "    print(f\"\\n   Gap to paper: {(0.9752 - avg_acc)*100:.2f}%\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "print(\"\\n‚úÖ EVALUATION COMPLETE!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from keras_lmu import LMU  # Import LMU\n",
    "\n",
    "# Setup\n",
    "class_names = ['Walking', 'Jogging', 'Walking_stairs_updown', \n",
    "               'Stumble_while_walking', 'Fall_Initiation', 'Impact_Aftermath']\n",
    "\n",
    "model_dir = Path.home() / 'repos/summerschool2023/projects/fall-detection/fall_detection_data/models'\n",
    "\n",
    "# Just analyze ONE model first to test\n",
    "print(\"Analyzing CNN-LMU (your best model)...\")\n",
    "\n",
    "all_y_true = []\n",
    "all_y_pred = []\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_data, y_labels), 1):\n",
    "    model_path = model_dir / f'fallnet_fold_{fold}.keras'  # CNN-LMU\n",
    "    \n",
    "    if not model_path.exists():\n",
    "        print(f\"Fold {fold}: File not found\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"Loading fold {fold}...\", end=' ')\n",
    "    \n",
    "    try:\n",
    "        # Load model WITH custom objects\n",
    "        model = tf.keras.models.load_model(\n",
    "            model_path,\n",
    "            custom_objects={'LMU': LMU}  # ‚Üê THIS IS THE KEY FIX\n",
    "        )\n",
    "        \n",
    "        # Get validation data\n",
    "        X_val = X_data[val_idx]\n",
    "        y_val = y_labels[val_idx]\n",
    "        \n",
    "        # Predict\n",
    "        y_pred_proba = model.predict(X_val, batch_size=64, verbose=0)\n",
    "        y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "        \n",
    "        # Store\n",
    "        all_y_true.extend(y_val)\n",
    "        all_y_pred.extend(y_pred)\n",
    "        \n",
    "        print(\"‚úì\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚úó Error: {e}\")\n",
    "\n",
    "# Generate report\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CNN-LMU Per-Class Performance (All Folds Combined)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "report = classification_report(\n",
    "    all_y_true, all_y_pred,\n",
    "    target_names=class_names,\n",
    "    digits=3\n",
    ")\n",
    "\n",
    "print(report)\n",
    "\n",
    "# Extract per-class metrics\n",
    "report_dict = classification_report(\n",
    "    all_y_true, all_y_pred,\n",
    "    target_names=class_names,\n",
    "    output_dict=True\n",
    ")\n",
    "\n",
    "# Simple bar chart\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "classes = class_names\n",
    "f1_scores = [report_dict[cn]['f1-score'] for cn in class_names]\n",
    "recalls = [report_dict[cn]['recall'] for cn in class_names]\n",
    "precisions = [report_dict[cn]['precision'] for cn in class_names]\n",
    "\n",
    "x = np.arange(len(classes))\n",
    "width = 0.25\n",
    "\n",
    "ax.bar(x - width, precisions, width, label='Precision', alpha=0.8)\n",
    "ax.bar(x, recalls, width, label='Recall', alpha=0.8)\n",
    "ax.bar(x + width, f1_scores, width, label='F1-Score', alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('Class', fontsize=12)\n",
    "ax.set_ylabel('Score', fontsize=12)\n",
    "ax.set_title('CNN-LMU: Per-Class Performance', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(classes, rotation=45, ha='right')\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "ax.set_ylim([0, 1.05])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(model_dir / 'cnn_lmu_per_class.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n‚úì Saved to: {model_dir / 'cnn_lmu_per_class.png'}\")\n",
    "\n",
    "# Show which classes are weakest\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Classes Ranked by F1-Score (Worst to Best)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "class_f1 = [(cn, report_dict[cn]['f1-score']) for cn in class_names]\n",
    "class_f1.sort(key=lambda x: x[1])\n",
    "\n",
    "for cn, f1 in class_f1:\n",
    "    print(f\"{cn:30s}: {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "model_dir = Path.home() / 'repos/summerschool2023/projects/fall-detection/fall_detection_data/models'\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"EVALUATING: fallnet_fold_cnn_lstm_original[1-5].keras\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "class_names = ['Walking', 'Jogging', 'Walking_stairs_updown', \n",
    "               'Stumble_while_walking', 'Fall_Initiation', 'Impact_Aftermath']\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "all_y_true = []\n",
    "all_y_pred = []\n",
    "fold_results = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_data, y_labels), 1):\n",
    "    model_path = model_dir / f'fallnet_fold_cnn_lstm_{fold}.keras'\n",
    "    \n",
    "    if not model_path.exists():\n",
    "        print(f\"\\nFold {fold}: ‚úó File not found\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\nFold {fold}: {model_path.name}\")\n",
    "    print(f\"  File size: {model_path.stat().st_size / (1024*1024):.1f} MB\")\n",
    "    \n",
    "    try:\n",
    "        # Load model\n",
    "        model = tf.keras.models.load_model(model_path)\n",
    "        \n",
    "        # Get validation data\n",
    "        X_val = X_data[val_idx]\n",
    "        y_val = y_labels[val_idx]\n",
    "        y_val_cat = y_categorical[val_idx]\n",
    "        \n",
    "        # Predict\n",
    "        y_pred_proba = model.predict(X_val, batch_size=64, verbose=0)\n",
    "        y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "        \n",
    "        # Evaluate\n",
    "        val_loss, val_acc, val_precision, val_recall = model.evaluate(\n",
    "            X_val, y_val_cat, batch_size=64, verbose=0\n",
    "        )\n",
    "        \n",
    "        # Get per-class metrics for this fold\n",
    "        report_dict = classification_report(\n",
    "            y_val, y_pred,\n",
    "            target_names=class_names,\n",
    "            output_dict=True,\n",
    "            zero_division=0\n",
    "        )\n",
    "        \n",
    "        fall_init_recall = report_dict['Fall_Initiation']['recall']\n",
    "        fall_init_f1 = report_dict['Fall_Initiation']['f1-score']\n",
    "        \n",
    "        print(f\"  Accuracy:  {val_acc:.4f} ({val_acc*100:.2f}%)\")\n",
    "        print(f\"  Precision: {val_precision:.4f}\")\n",
    "        print(f\"  Recall:    {val_recall:.4f}\")\n",
    "        print(f\"  Fall_Initiation Recall: {fall_init_recall:.4f}\")\n",
    "        print(f\"  Fall_Initiation F1:     {fall_init_f1:.4f}\")\n",
    "        \n",
    "        # Store results\n",
    "        all_y_true.extend(y_val)\n",
    "        all_y_pred.extend(y_pred)\n",
    "        fold_results.append({\n",
    "            'fold': fold,\n",
    "            'accuracy': val_acc,\n",
    "            'precision': val_precision,\n",
    "            'recall': val_recall,\n",
    "            'loss': val_loss,\n",
    "            'fall_init_recall': fall_init_recall,\n",
    "            'fall_init_f1': fall_init_f1\n",
    "        })\n",
    "        \n",
    "        # Clear memory\n",
    "        del model\n",
    "        tf.keras.backend.clear_session()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚úó Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "# Summary table\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PER-FOLD SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if len(fold_results) > 0:\n",
    "    df = pd.DataFrame(fold_results)\n",
    "    print(df.to_string(index=False))\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"AVERAGE PERFORMANCE ¬± STD\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Accuracy:             {df['accuracy'].mean():.4f} ¬± {df['accuracy'].std():.4f}\")\n",
    "    print(f\"Precision:            {df['precision'].mean():.4f} ¬± {df['precision'].std():.4f}\")\n",
    "    print(f\"Recall:               {df['recall'].mean():.4f} ¬± {df['recall'].std():.4f}\")\n",
    "    print(f\"Fall_Initiation Recall: {df['fall_init_recall'].mean():.4f} ¬± {df['fall_init_recall'].std():.4f}\")\n",
    "    print(f\"Fall_Initiation F1:     {df['fall_init_f1'].mean():.4f} ¬± {df['fall_init_f1'].std():.4f}\")\n",
    "\n",
    "# Detailed per-class performance (all folds combined)\n",
    "if len(all_y_true) > 0:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"DETAILED PER-CLASS PERFORMANCE (ALL FOLDS)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    report = classification_report(\n",
    "        all_y_true, all_y_pred,\n",
    "        target_names=class_names,\n",
    "        digits=3\n",
    "    )\n",
    "    print(report)\n",
    "    \n",
    "    # Get report as dict for comparison\n",
    "    report_dict = classification_report(\n",
    "        all_y_true, all_y_pred,\n",
    "        target_names=class_names,\n",
    "        output_dict=True\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"PER-CLASS F1-SCORES RANKED\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    class_f1 = [(cn, report_dict[cn]['f1-score']) for cn in class_names]\n",
    "    class_f1.sort(key=lambda x: x[1])\n",
    "    \n",
    "    for cn, f1 in class_f1:\n",
    "        print(f\"{cn:30s}: {f1:.3f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPARISON TO OTHER MODELS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if len(fold_results) > 0:\n",
    "    avg_acc = df['accuracy'].mean()\n",
    "    \n",
    "    print(f\"CNN-LSTM 'original' (these models): {avg_acc:.4f} ({avg_acc*100:.2f}%)\")\n",
    "    print(f\"CNN-only:                           0.8998 (89.98%)\")\n",
    "    print(f\"CNN-LMU:                            0.8997 (89.97%)\")\n",
    "    print(f\"CNN-LSTM 'ensemble':                0.8858 (88.58%)\")\n",
    "    print(f\"\\nPaper target:                       0.9752 (97.52%)\")\n",
    "    \n",
    "    if avg_acc > 0.8998:\n",
    "        print(f\"\\n‚úì These CNN-LSTM models are the BEST! (+{(avg_acc - 0.8998)*100:.2f}%)\")\n",
    "    else:\n",
    "        print(f\"\\n‚úó Still behind CNN-only by {(0.8998 - avg_acc)*100:.2f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EVALUATION COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from keras_lmu import LMU  # For CNN-LMU\n",
    "\n",
    "# Setup\n",
    "class_names = ['Walking', 'Jogging', 'Walking_stairs_updown', \n",
    "               'Stumble_while_walking', 'Fall_Initiation', 'Impact_Aftermath']\n",
    "\n",
    "model_dir = Path.home() / 'repos/summerschool2023/projects/fall-detection/fall_detection_data/models'\n",
    "\n",
    "# Define models to compare\n",
    "models_to_compare = {\n",
    "    'CNN-only': {\n",
    "        'pattern': 'cnn_only_fold_{}.keras',\n",
    "        'custom_objects': None\n",
    "    },\n",
    "    'CNN-LSTM': {\n",
    "        'pattern': 'fallnet_fold_cnn_lstm_{}.keras',\n",
    "        'custom_objects': None\n",
    "    },\n",
    "    'CNN-LMU': {\n",
    "        'pattern': 'fallnet_reg_lmu_fold_{}.keras',\n",
    "        'custom_objects': {'LMU': LMU}  # Need this for LMU\n",
    "    }\n",
    "}\n",
    "\n",
    "# Collect per-class metrics for each model\n",
    "all_results = {}\n",
    "\n",
    "for model_name, model_info in models_to_compare.items():\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Analyzing {model_name}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    all_y_true = []\n",
    "    all_y_pred = []\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X_data, y_labels), 1):\n",
    "        model_path = model_dir / model_info['pattern'].format(fold)\n",
    "        \n",
    "        if not model_path.exists():\n",
    "            print(f\"  ‚ö†Ô∏è  Fold {fold} not found\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"  Loading fold {fold}...\", end=' ')\n",
    "        \n",
    "        try:\n",
    "            # Load model with custom objects if needed\n",
    "            if model_info['custom_objects']:\n",
    "                model = tf.keras.models.load_model(\n",
    "                    model_path,\n",
    "                    custom_objects=model_info['custom_objects']\n",
    "                )\n",
    "            else:\n",
    "                model = tf.keras.models.load_model(model_path)\n",
    "            \n",
    "            # Get validation data\n",
    "            X_val = X_data[val_idx]\n",
    "            y_val = y_labels[val_idx]\n",
    "            \n",
    "            # Predict\n",
    "            y_pred_proba = model.predict(X_val, batch_size=64, verbose=0)\n",
    "            y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "            \n",
    "            # Store\n",
    "            all_y_true.extend(y_val)\n",
    "            all_y_pred.extend(y_pred)\n",
    "            \n",
    "            print(\"‚úì\")\n",
    "            \n",
    "            # Clear memory\n",
    "            del model\n",
    "            tf.keras.backend.clear_session()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚úó Error: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Generate classification report\n",
    "    if len(all_y_true) > 0:\n",
    "        report_dict = classification_report(\n",
    "            all_y_true, all_y_pred,\n",
    "            target_names=class_names,\n",
    "            output_dict=True,\n",
    "            zero_division=0\n",
    "        )\n",
    "        all_results[model_name] = {\n",
    "            'report': report_dict,\n",
    "            'y_true': all_y_true,\n",
    "            'y_pred': all_y_pred\n",
    "        }\n",
    "        \n",
    "        # Print summary\n",
    "        print(f\"\\n  {model_name} Overall: {report_dict['accuracy']:.3f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYSIS COMPLETE - Generating Visualizations...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ============================================================================\n",
    "# VISUALIZATION 1: Per-Class Metrics Comparison (Side-by-Side Bars)\n",
    "# ============================================================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "metrics_to_plot = ['precision', 'recall', 'f1-score']\n",
    "\n",
    "for idx, metric in enumerate(metrics_to_plot):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    x = np.arange(len(class_names))\n",
    "    width = 0.25\n",
    "    \n",
    "    for i, model_name in enumerate(models_to_compare.keys()):\n",
    "        if model_name in all_results:\n",
    "            scores = []\n",
    "            for cn in class_names:\n",
    "                if cn in all_results[model_name]['report']:\n",
    "                    scores.append(all_results[model_name]['report'][cn][metric])\n",
    "                else:\n",
    "                    scores.append(0)\n",
    "            \n",
    "            ax.bar(x + i*width, scores, width, label=model_name, alpha=0.8)\n",
    "    \n",
    "    ax.set_xlabel('Class', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel(metric.capitalize(), fontsize=12, fontweight='bold')\n",
    "    ax.set_title(f'{metric.capitalize()} by Class', fontsize=14, fontweight='bold')\n",
    "    ax.set_xticks(x + width)\n",
    "    ax.set_xticklabels(class_names, rotation=45, ha='right', fontsize=10)\n",
    "    ax.legend(fontsize=10)\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    ax.set_ylim([0.80, 1.05])\n",
    "    ax.axhline(y=0.9, color='red', linestyle='--', alpha=0.3, label='90%')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(model_dir / 'per_class_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"‚úì Saved: {model_dir / 'per_class_comparison.png'}\")\n",
    "\n",
    "# ============================================================================\n",
    "# VISUALIZATION 2: F1-Score Heatmap\n",
    "# ============================================================================\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "\n",
    "heatmap_data = []\n",
    "model_labels = []\n",
    "\n",
    "for model_name in models_to_compare.keys():\n",
    "    if model_name in all_results:\n",
    "        row = []\n",
    "        for class_name in class_names:\n",
    "            if class_name in all_results[model_name]['report']:\n",
    "                row.append(all_results[model_name]['report'][class_name]['f1-score'])\n",
    "            else:\n",
    "                row.append(0)\n",
    "        heatmap_data.append(row)\n",
    "        model_labels.append(model_name)\n",
    "\n",
    "heatmap_df = pd.DataFrame(heatmap_data, columns=class_names, index=model_labels)\n",
    "\n",
    "sns.heatmap(heatmap_df, annot=True, fmt='.3f', cmap='RdYlGn', \n",
    "            vmin=0.85, vmax=1.0, center=0.925,\n",
    "            cbar_kws={'label': 'F1-Score'}, ax=ax, linewidths=0.5)\n",
    "\n",
    "ax.set_title('F1-Score Heatmap: Model vs Class Performance', \n",
    "             fontsize=16, fontweight='bold', pad=20)\n",
    "ax.set_xlabel('Class', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Model', fontsize=12, fontweight='bold')\n",
    "plt.setp(ax.get_xticklabels(), rotation=45, ha='right', fontsize=10)\n",
    "plt.setp(ax.get_yticklabels(), rotation=0, fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(model_dir / 'f1_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"‚úì Saved: {model_dir / 'f1_heatmap.png'}\")\n",
    "\n",
    "# ============================================================================\n",
    "# VISUALIZATION 3: Overall Model Comparison (Bar Chart)\n",
    "# ============================================================================\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "models = []\n",
    "accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1s = []\n",
    "\n",
    "for model_name in models_to_compare.keys():\n",
    "    if model_name in all_results:\n",
    "        report = all_results[model_name]['report']\n",
    "        models.append(model_name)\n",
    "        accuracies.append(report['accuracy'])\n",
    "        precisions.append(report['weighted avg']['precision'])\n",
    "        recalls.append(report['weighted avg']['recall'])\n",
    "        f1s.append(report['weighted avg']['f1-score'])\n",
    "\n",
    "x = np.arange(len(models))\n",
    "width = 0.2\n",
    "\n",
    "ax.bar(x - 1.5*width, accuracies, width, label='Accuracy', alpha=0.8)\n",
    "ax.bar(x - 0.5*width, precisions, width, label='Precision', alpha=0.8)\n",
    "ax.bar(x + 0.5*width, recalls, width, label='Recall', alpha=0.8)\n",
    "ax.bar(x + 1.5*width, f1s, width, label='F1-Score', alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('Model', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Score', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Overall Model Performance Comparison', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(models, fontsize=11)\n",
    "ax.legend(fontsize=10)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "ax.set_ylim([0.85, 0.95])\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, (acc, prec, rec, f1) in enumerate(zip(accuracies, precisions, recalls, f1s)):\n",
    "    ax.text(i - 1.5*width, acc + 0.003, f'{acc:.3f}', ha='center', fontsize=9)\n",
    "    ax.text(i - 0.5*width, prec + 0.003, f'{prec:.3f}', ha='center', fontsize=9)\n",
    "    ax.text(i + 0.5*width, rec + 0.003, f'{rec:.3f}', ha='center', fontsize=9)\n",
    "    ax.text(i + 1.5*width, f1 + 0.003, f'{f1:.3f}', ha='center', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(model_dir / 'overall_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"‚úì Saved: {model_dir / 'overall_comparison.png'}\")\n",
    "\n",
    "# ============================================================================\n",
    "# DETAILED TEXT SUMMARY\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DETAILED PER-CLASS COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "summary_data = []\n",
    "for class_name in class_names:\n",
    "    row = {'Class': class_name}\n",
    "    for model_name in models_to_compare.keys():\n",
    "        if model_name in all_results:\n",
    "            report = all_results[model_name]['report']\n",
    "            if class_name in report:\n",
    "                f1 = report[class_name]['f1-score']\n",
    "                recall = report[class_name]['recall']\n",
    "                precision = report[class_name]['precision']\n",
    "                row[f'{model_name}_F1'] = f'{f1:.3f}'\n",
    "                row[f'{model_name}_Recall'] = f'{recall:.3f}'\n",
    "                row[f'{model_name}_Precision'] = f'{precision:.3f}'\n",
    "    summary_data.append(row)\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(summary_df.to_string(index=False))\n",
    "\n",
    "# Save summary\n",
    "summary_df.to_csv(model_dir / 'per_class_comparison.csv', index=False)\n",
    "print(f\"\\n‚úì Summary CSV saved: {model_dir / 'per_class_comparison.csv'}\")\n",
    "\n",
    "# ============================================================================\n",
    "# FIND BEST MODEL PER CLASS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BEST MODEL FOR EACH CLASS (by F1-Score)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for class_name in class_names:\n",
    "    best_model = None\n",
    "    best_f1 = 0\n",
    "    \n",
    "    for model_name in models_to_compare.keys():\n",
    "        if model_name in all_results:\n",
    "            report = all_results[model_name]['report']\n",
    "            if class_name in report:\n",
    "                f1 = report[class_name]['f1-score']\n",
    "                if f1 > best_f1:\n",
    "                    best_f1 = f1\n",
    "                    best_model = model_name\n",
    "    \n",
    "    print(f\"{class_name:30s}: {best_model:15s} (F1={best_f1:.3f})\")\n",
    "\n",
    "# ============================================================================\n",
    "# OVERALL WINNER\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"OVERALL BEST MODEL (by Accuracy)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "best_overall = None\n",
    "best_acc = 0\n",
    "\n",
    "for model_name in models_to_compare.keys():\n",
    "    if model_name in all_results:\n",
    "        acc = all_results[model_name]['report']['accuracy']\n",
    "        print(f\"{model_name:15s}: {acc:.3f} ({acc*100:.2f}%)\")\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_overall = model_name\n",
    "\n",
    "print(f\"\\nüèÜ Winner: {best_overall} with {best_acc:.3f} ({best_acc*100:.2f}%) accuracy\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ALL VISUALIZATIONS COMPLETE!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "model_dir = Path.home() / 'repos/summerschool2023/projects/fall-detection/fall_detection_data/models'\n",
    "\n",
    "# Load the best model\n",
    "best_model_path = model_dir / 'fallnet_best_model.keras'\n",
    "print(f\"Loading: {best_model_path}\")\n",
    "\n",
    "best_model = tf.keras.models.load_model(best_model_path)\n",
    "\n",
    "# 1. Check the architecture\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL ARCHITECTURE\")\n",
    "print(\"=\"*80)\n",
    "best_model.summary()\n",
    "\n",
    "# 2. Check what accuracy it gets NOW on your current data\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EVALUATING ON CURRENT DATA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Use the same K-fold split to get validation data\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_data, y_labels), 1):\n",
    "    X_val = X_data[val_idx]\n",
    "    y_val = y_categorical[val_idx]\n",
    "    \n",
    "    val_loss, val_acc, val_precision, val_recall = best_model.evaluate(\n",
    "        X_val, y_val, batch_size=64, verbose=0\n",
    "    )\n",
    "    \n",
    "    print(f\"Fold {fold}: Accuracy = {val_acc:.4f} ({val_acc*100:.2f}%)\")\n",
    "    print(f\"          Precision = {val_precision:.4f}\")\n",
    "    print(f\"          Recall = {val_recall:.4f}\")\n",
    "    \n",
    "    # Just check fold 1 for now\n",
    "    break\n",
    "\n",
    "# 3. Compare architecture to your current FallNet\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPARING TO CURRENT FALLNET\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "current_model = FallNet(input_shape=(200, 6), n_classes=6).build_ensemble()\n",
    "print(\"\\nCurrent model:\")\n",
    "current_model.summary()\n",
    "\n",
    "# 4. Check for key differences\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"KEY CHECKS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Best model input shape: {best_model.input_shape}\")\n",
    "print(f\"Best model output shape: {best_model.output_shape}\")\n",
    "print(f\"Best model total params: {best_model.count_params():,}\")\n",
    "print(f\"\\nCurrent model input shape: {current_model.input_shape}\")\n",
    "print(f\"Current model output shape: {current_model.output_shape}\")\n",
    "print(f\"Current model total params: {current_model.count_params():,}\")\n",
    "\n",
    "# 5. Layer-by-layer comparison\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"LAYER COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nBest model has {len(best_model.layers)} layers\")\n",
    "print(f\"Current model has {len(current_model.layers)} layers\")\n",
    "\n",
    "print(\"\\nBest model layers:\")\n",
    "for i, layer in enumerate(best_model.layers[:10]):  # First 10 layers\n",
    "    print(f\"  {i}: {layer.name} - {layer.__class__.__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "import gc\n",
    "\n",
    "\n",
    "\n",
    "keras.backend.clear_session()\n",
    "gc.collect()\n",
    "\n",
    "class FallNet:\n",
    "    \"\"\"\n",
    "    FallNet: CNN-LSTM Ensemble (EXACT replication of paper)\n",
    "    Reference: Jain & Semwal, IEEE Sensors Journal 2022\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_shape=(200, 6), n_classes=6):  # 8 classes per paper\n",
    "        self.input_shape = input_shape\n",
    "        self.n_classes = n_classes\n",
    "        self.model = None\n",
    "    \n",
    "    def build_lstm_branch(self, inputs):\n",
    "        \"\"\"LSTM Branch - EXACT from paper Table II\"\"\"\n",
    "        x = layers.LSTM(\n",
    "            units=256,\n",
    "            activation='tanh',\n",
    "            return_sequences=False,\n",
    "            name='lstm_layer'\n",
    "        )(inputs)\n",
    "        \n",
    "        x = layers.Dense(128, activation='relu', \n",
    "                        kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
    "                        name='lstm_dense1')(x)\n",
    "        x = layers.Dropout(0.2, name='lstm_dropout1')(x)\n",
    "        \n",
    "        x = layers.Dense(64, activation='relu',\n",
    "                        kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
    "                        name='lstm_dense2')(x)\n",
    "        x = layers.Dropout(0.2, name='lstm_dropout2')(x)\n",
    "        \n",
    "        x = layers.Dense(32, activation='relu',\n",
    "                        kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
    "                        name='lstm_dense3')(x)\n",
    "        x = layers.Dropout(0.2, name='lstm_dropout3')(x)\n",
    "        \n",
    "        lstm_output = layers.Dense(\n",
    "            self.n_classes, \n",
    "            activation='softmax',\n",
    "            name='lstm_output'\n",
    "        )(x)\n",
    "        \n",
    "        return lstm_output\n",
    "    \n",
    "    def build_cnn_branch(self, inputs):\n",
    "        \"\"\"CNN Branch - EXACT from paper Table II\"\"\"\n",
    "        # Single Conv1D layer (paper specifies ONE, not two!)\n",
    "        x = layers.Conv1D(\n",
    "            filters=128,\n",
    "            kernel_size=3,\n",
    "            activation='relu',\n",
    "            padding='same',\n",
    "            name='conv1d_layer'\n",
    "        )(inputs)\n",
    "        \n",
    "        x = layers.MaxPooling1D(pool_size=2, name='maxpool_layer')(x)\n",
    "        x = layers.Flatten(name='flatten_layer')(x)\n",
    "        \n",
    "        # Large dense layers (CRITICAL for 97% accuracy)\n",
    "        x = layers.Dense(1024, activation='relu',\n",
    "                        kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
    "                        name='cnn_dense1')(x)\n",
    "        x = layers.Dropout(0.2, name='cnn_dropout1')(x)\n",
    "        \n",
    "        x = layers.Dense(512, activation='relu',\n",
    "                        kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
    "                        name='cnn_dense2')(x)\n",
    "        x = layers.Dropout(0.2, name='cnn_dropout2')(x)\n",
    "        \n",
    "        cnn_output = layers.Dense(\n",
    "            self.n_classes,\n",
    "            activation='softmax',\n",
    "            name='cnn_output'\n",
    "        )(x)\n",
    "        \n",
    "        return cnn_output\n",
    "    \n",
    "    def build_ensemble(self):\n",
    "        \"\"\"Build ensemble - average of CNN + LSTM\"\"\"\n",
    "        inputs = layers.Input(shape=self.input_shape, name='input')\n",
    "        \n",
    "        lstm_output = self.build_lstm_branch(inputs)\n",
    "        cnn_output = self.build_cnn_branch(inputs)\n",
    "        \n",
    "        # Average ensemble\n",
    "        ensemble_output = layers.Average(name='ensemble_average')([lstm_output, cnn_output])\n",
    "        \n",
    "        self.model = models.Model(\n",
    "            inputs=inputs,\n",
    "            outputs=ensemble_output,\n",
    "            name='FallNet_CNN_LSTM'\n",
    "        )\n",
    "        \n",
    "        return self.model\n",
    "    \n",
    "    def compile_model(self):\n",
    "        \"\"\"Compile with Adam optimizer (default LR per paper)\"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Model not built yet\")\n",
    "        \n",
    "        self.model.compile(\n",
    "            optimizer=keras.optimizers.Adam(),  # Default LR = 0.001\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=[\n",
    "                'accuracy', \n",
    "                keras.metrics.Precision(name='precision'),\n",
    "                keras.metrics.Recall(name='recall')\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        return self.model\n",
    "\n",
    "# ==========================================\n",
    "# TRAINING CONFIGURATION (EXACT from paper)\n",
    "# ==========================================\n",
    "\n",
    "BATCH_SIZE = 64  # Start here (was 512)\n",
    "EPOCHS = 200 # ‚Üê Paper uses 200\n",
    "K_FOLDS = 5\n",
    "MODEL_NAME = \"cnn_lstm_ensemble\"\n",
    "\n",
    "# Training loop (with memory management)\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=K_FOLDS, shuffle=True, random_state=42)\n",
    "fold_results = []\n",
    "fold_histories = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_data, y_labels), 1):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"FOLD {fold}/{K_FOLDS} - CNN-LSTM ENSEMBLE\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Clear memory\n",
    "    keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_val = X_data[train_idx], X_data[val_idx]\n",
    "    y_train, y_val = y_categorical[train_idx], y_categorical[val_idx]\n",
    "    \n",
    "    print(f\"Train: {X_train.shape[0]:,} samples | Val: {X_val.shape[0]:,} samples\")\n",
    "    \n",
    "    # Build model\n",
    "    fallnet_fold = FallNet(input_shape=(200, 6), n_classes=6)  # 8 classes!\n",
    "    model_fold = fallnet_fold.build_ensemble()\n",
    "    model_fold = fallnet_fold.compile_model()\n",
    "    \n",
    "    # Callbacks (EXACT from paper)\n",
    "    fold_callbacks = [\n",
    "        EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=20,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=10,\n",
    "            min_lr=1e-7,\n",
    "            verbose=1\n",
    "        ),\n",
    "        ModelCheckpoint(\n",
    "            filepath=str(output_dir / f'{MODEL_NAME}_fold_{fold}.keras'),\n",
    "            monitor='val_accuracy',\n",
    "            save_best_only=True,\n",
    "            mode='max',\n",
    "            verbose=1\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # Class weights\n",
    "    from sklearn.utils.class_weight import compute_class_weight\n",
    "    class_weights_array = compute_class_weight(\n",
    "        class_weight='balanced',\n",
    "        classes=np.unique(y_labels),\n",
    "        y=y_labels\n",
    "    )\n",
    "    MAX_WEIGHT = 3.0\n",
    "    class_weights_array_capped = np.clip(class_weights_array, None, MAX_WEIGHT)\n",
    "    class_weights = dict(enumerate(class_weights_array_capped))\n",
    "    \n",
    "    # Train with BATCH_SIZE=512\n",
    "    print(f\"\\nTraining fold {fold}...\")\n",
    "    history = model_fold.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        batch_size=BATCH_SIZE,  # 512!\n",
    "        epochs=EPOCHS,          # 200!\n",
    "        class_weight=class_weights,\n",
    "        callbacks=fold_callbacks,\n",
    "        verbose=2\n",
    "    )\n",
    "    \n",
    "    # Evaluate\n",
    "    val_loss, val_acc, val_precision, val_recall = model_fold.evaluate(\n",
    "        X_val, y_val, batch_size=BATCH_SIZE, verbose=0\n",
    "    )\n",
    "    val_f1 = 2 * (val_precision * val_recall) / (val_precision + val_recall) if (val_precision + val_recall) > 0 else 0\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Fold {fold} Results:\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"Loss:      {val_loss:.4f}\")\n",
    "    print(f\"Accuracy:  {val_acc:.4f}\")\n",
    "    print(f\"Precision: {val_precision:.4f}\")\n",
    "    print(f\"Recall:    {val_recall:.4f}\")\n",
    "    print(f\"F1-Score:  {val_f1:.4f}\")\n",
    "    \n",
    "    fold_results.append({\n",
    "        'fold': fold,\n",
    "        'val_loss': val_loss,\n",
    "        'val_accuracy': val_acc,\n",
    "        'val_precision': val_precision,\n",
    "        'val_recall': val_recall,\n",
    "        'val_f1': val_f1\n",
    "    })\n",
    "    \n",
    "    fold_histories.append(history.history)\n",
    "    \n",
    "    # Clear memory\n",
    "    del model_fold, fallnet_fold\n",
    "    del X_train, X_val, y_train, y_val, history\n",
    "    keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "    \n",
    "    print(f\"\\n‚úì Fold {fold} complete, memory cleared\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow import keras\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from pathlib import Path\n",
    "\n",
    "# Paths\n",
    "base_dir = Path.home() / 'repos/summerschool2023/projects/fall-detection/fall_detection_data'\n",
    "model_dir = base_dir / 'models'\n",
    "\n",
    "# Load data (assuming you have X_data, y_labels, y_categorical loaded)\n",
    "# If not, load them first\n",
    "\n",
    "# Setup same K-fold split used during training\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EVALUATING TRAINED CNN-LSTM MODELS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "fold_results = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_data, y_labels), 1):\n",
    "    print(f\"\\nEvaluating Fold {fold}...\")\n",
    "    \n",
    "    # Load model\n",
    "    model_path = model_dir / f'fallnet_fold_cnn_lstm_original{fold}.keras'\n",
    "    model = keras.models.load_model(model_path)\n",
    "    \n",
    "    # Get validation data for this fold\n",
    "    X_val = X_data[val_idx]\n",
    "    y_val = y_categorical[val_idx]\n",
    "    \n",
    "    # Evaluate\n",
    "    val_loss, val_acc, val_precision, val_recall = model.evaluate(\n",
    "        X_val, y_val, batch_size=64, verbose=0\n",
    "    )\n",
    "    \n",
    "    val_f1 = 2 * (val_precision * val_recall) / (val_precision + val_recall) if (val_precision + val_recall) > 0 else 0\n",
    "    \n",
    "    print(f\"  Accuracy:  {val_acc:.4f}\")\n",
    "    print(f\"  Precision: {val_precision:.4f}\")\n",
    "    print(f\"  Recall:    {val_recall:.4f}\")\n",
    "    print(f\"  F1-Score:  {val_f1:.4f}\")\n",
    "    \n",
    "    fold_results.append({\n",
    "        'fold': fold,\n",
    "        'accuracy': val_acc,\n",
    "        'precision': val_precision,\n",
    "        'recall': val_recall,\n",
    "        'f1': val_f1\n",
    "    })\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(fold_results)\n",
    "\n",
    "print(\"\\nPer-Fold Results:\")\n",
    "print(df.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AVERAGE PERFORMANCE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "mean_acc = df['accuracy'].mean()\n",
    "std_acc = df['accuracy'].std()\n",
    "mean_recall = df['recall'].mean()\n",
    "std_recall = df['recall'].std()\n",
    "\n",
    "print(f\"Accuracy:  {mean_acc:.4f} ¬± {std_acc:.4f} ({mean_acc*100:.2f}%)\")\n",
    "print(f\"Precision: {df['precision'].mean():.4f} ¬± {df['precision'].std():.4f}\")\n",
    "print(f\"Recall:    {mean_recall:.4f} ¬± {std_recall:.4f}\")\n",
    "print(f\"F1-Score:  {df['f1'].mean():.4f} ¬± {df['f1'].std():.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPARISON TO TARGET\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Target (Paper):    97.52%\")\n",
    "print(f\"Your Result:       {mean_acc*100:.2f}%\")\n",
    "print(f\"Difference:        {(mean_acc - 0.9752)*100:+.2f}%\")\n",
    "\n",
    "if mean_acc >= 0.97:\n",
    "    print(\"\\n‚úì SUCCESS: Achieved target performance!\")\n",
    "elif mean_acc >= 0.95:\n",
    "    print(\"\\n‚Üí CLOSE: Within 2-3% of target\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  GAP: More than 2% below target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best fold model\n",
    "best_fold = int(results_df.loc[results_df['val_f1'].idxmax(), 'fold'])\n",
    "best_model = keras.models.load_model(output_dir / f'fallnet_fold_{best_fold}.keras')\n",
    "\n",
    "# Get predictions on ALL data\n",
    "y_pred_probs = best_model.predict(X_data, verbose=0)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "# Classification report\n",
    "from sklearn.metrics import classification_report\n",
    "class_names = [reverse_label_map[i] for i in range(6)]\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PER-CLASS PERFORMANCE (BEST FOLD)\")\n",
    "print(\"=\"*80)\n",
    "print(classification_report(y_labels, y_pred, target_names=class_names, digits=4))\n",
    "\n",
    "# Fall_Initiation specific\n",
    "fall_init_idx = 4\n",
    "fall_init_recall = recall_score(y_labels == fall_init_idx, y_pred == fall_init_idx)\n",
    "fall_init_precision = precision_score(y_labels == fall_init_idx, y_pred == fall_init_idx)\n",
    "fall_init_f1 = f1_score(y_labels == fall_init_idx, y_pred == fall_init_idx)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FALL_INITIATION PERFORMANCE (CRITICAL CLASS)\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Precision: {fall_init_precision:.4f}\")\n",
    "print(f\"Recall:    {fall_init_recall:.4f}\")\n",
    "print(f\"F1-Score:  {fall_init_f1:.4f}\")\n",
    "print(f\"\\nPaper's Fall_Initiation Recall: 0.9924\")\n",
    "print(f\"Your Fall_Initiation Recall:    {fall_init_recall:.4f}\")\n",
    "print(f\"Difference:                     {fall_init_recall - 0.9924:+.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "base_dir = Path(\"~/repos/summerschool2023/projects/fall-detection/fall_detection_data\").expanduser()\n",
    "models_dir = base_dir / \"models\"\n",
    "processed_dir = base_dir / \"processed\"\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"EVALUATING fallnet_fold_1.keras (Jan 5, 14:39)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Load 6-class data\n",
    "X_data = np.load(processed_dir / \"X_data.npy\")\n",
    "y_labels = np.load(processed_dir / \"y_labels.npy\")\n",
    "\n",
    "print(f\"\\nüìä Data loaded:\")\n",
    "print(f\"   X_data: {X_data.shape}\")\n",
    "print(f\"   y_labels: {y_labels.shape}\")\n",
    "print(f\"   Classes: {sorted(np.unique(y_labels))}\")\n",
    "\n",
    "# Load label map\n",
    "with open(processed_dir / \"label_map.json\", \"r\") as f:\n",
    "    label_map = json.load(f)\n",
    "reverse_label_map = {v: k for k, v in label_map.items()}\n",
    "\n",
    "class_names = [reverse_label_map[i] for i in range(6)]\n",
    "\n",
    "print(f\"\\nüìã Classes:\")\n",
    "for idx, name in enumerate(class_names):\n",
    "    print(f\"   {idx}: {name}\")\n",
    "\n",
    "# Load model\n",
    "print(f\"\\nüîß Loading model...\")\n",
    "model = keras.models.load_model(models_dir / 'fallnet_fold_1.keras')\n",
    "\n",
    "print(f\"‚úÖ Model loaded successfully\")\n",
    "print(f\"   Input shape: {model.input_shape}\")\n",
    "print(f\"   Output shape: {model.output_shape}\")\n",
    "print(f\"   Total params: {model.count_params():,}\")\n",
    "\n",
    "# Make predictions\n",
    "print(f\"\\nüîÆ Making predictions on {len(X_data):,} samples...\")\n",
    "y_pred_probs = model.predict(X_data, verbose=0)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "# Overall accuracy\n",
    "overall_acc = (y_pred == y_labels).mean()\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(f\"OVERALL ACCURACY: {overall_acc:.4f} ({overall_acc*100:.2f}%)\")\n",
    "print(f\"=\"*80)\n",
    "\n",
    "# Classification Report\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(\"CLASSIFICATION REPORT\")\n",
    "print(\"=\"*80)\n",
    "print(classification_report(y_labels, y_pred, target_names=class_names, digits=4))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_labels, y_pred)\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(\"CONFUSION MATRIX\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'True \\\\ Pred':<25s}\", end=\"\")\n",
    "for name in class_names:\n",
    "    print(f\"{name[:10]:>10s}\", end=\"\")\n",
    "print()\n",
    "\n",
    "for i, true_name in enumerate(class_names):\n",
    "    print(f\"{true_name[:25]:<25s}\", end=\"\")\n",
    "    for j in range(6):\n",
    "        print(f\"{cm[i,j]:>10d}\", end=\"\")\n",
    "    total = cm[i].sum()\n",
    "    correct = cm[i,i]\n",
    "    acc_row = correct / total if total > 0 else 0\n",
    "    print(f\"  | {correct:>5d}/{total:<5d} ({acc_row*100:>5.1f}%)\")\n",
    "\n",
    "# Per-class metrics\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(\"PER-CLASS METRICS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'Class':<30s} {'Precision':<12s} {'Recall':<12s} {'F1-Score':<12s} {'Support'}\")\n",
    "print(\"-\"*90)\n",
    "\n",
    "for cls_idx in range(6):\n",
    "    precision = precision_score(y_labels == cls_idx, y_pred == cls_idx, zero_division=0)\n",
    "    recall = recall_score(y_labels == cls_idx, y_pred == cls_idx, zero_division=0)\n",
    "    f1 = f1_score(y_labels == cls_idx, y_pred == cls_idx, zero_division=0)\n",
    "    support = (y_labels == cls_idx).sum()\n",
    "    \n",
    "    status = \"‚úÖ\" if recall > 0.90 else \"‚ö†Ô∏è\" if recall > 0.80 else \"‚ùå\"\n",
    "    print(f\"{class_names[cls_idx]:<30s} {precision:<12.4f} {recall:<12.4f} {f1:<12.4f} {support:>7d} {status}\")\n",
    "\n",
    "# Fall_Initiation (Critical Class)\n",
    "fall_init_idx = label_map[\"Fall_Initiation\"]\n",
    "fall_init_precision = precision_score(y_labels == fall_init_idx, y_pred == fall_init_idx)\n",
    "fall_init_recall = recall_score(y_labels == fall_init_idx, y_pred == fall_init_idx)\n",
    "fall_init_f1 = f1_score(y_labels == fall_init_idx, y_pred == fall_init_idx)\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(\"FALL_INITIATION (CRITICAL CLASS)\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Precision: {fall_init_precision:.4f} ({fall_init_precision*100:.2f}%)\")\n",
    "print(f\"Recall:    {fall_init_recall:.4f} ({fall_init_recall*100:.2f}%)\")\n",
    "print(f\"F1-Score:  {fall_init_f1:.4f} ({fall_init_f1*100:.2f}%)\")\n",
    "print(f\"\\nüìä Comparison with Paper:\")\n",
    "print(f\"   Paper:  99.24% recall\")\n",
    "print(f\"   Yours:  {fall_init_recall*100:.2f}% recall\")\n",
    "print(f\"   Diff:   {(fall_init_recall - 0.9924)*100:+.2f}%\")\n",
    "\n",
    "# Final Summary\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if overall_acc > 0.95:\n",
    "    print(f\"üéâ EXCELLENT! {overall_acc*100:.2f}% accuracy - Publication quality!\")\n",
    "elif overall_acc > 0.85:\n",
    "    print(f\"‚úÖ GOOD! {overall_acc*100:.2f}% accuracy - Solid baseline for SNN comparison!\")\n",
    "elif overall_acc > 0.70:\n",
    "    print(f\"ü§î MODERATE: {overall_acc*100:.2f}% - Matches K-fold expectations\")\n",
    "else:\n",
    "    print(f\"‚ùå POOR: {overall_acc*100:.2f}% - This might be the wrong model\")\n",
    "\n",
    "print(f\"\\nüìÅ Model used: fallnet_fold_1.keras\")\n",
    "print(f\"üìÖ Saved: Jan 5, 2025 at 14:39\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "20",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "## Fold Data Distribution Analysis\n",
    "\n",
    "# %%\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYZING DATA DISTRIBUTION ACROSS FOLDS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "fold_distributions = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_data, y_labels), 1):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"FOLD {fold}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Get labels for this fold\n",
    "    train_labels = y_labels[train_idx]\n",
    "    val_labels = y_labels[val_idx]\n",
    "    \n",
    "    # Count distribution\n",
    "    train_dist = Counter(train_labels)\n",
    "    val_dist = Counter(val_labels)\n",
    "    \n",
    "    print(f\"\\nTraining set ({len(train_labels)} samples):\")\n",
    "    for cls_idx in sorted(train_dist.keys()):\n",
    "        count = train_dist[cls_idx]\n",
    "        pct = count / len(train_labels) * 100\n",
    "        print(f\"  {reverse_label_map[cls_idx]:<30s}: {count:>5d} ({pct:>5.2f}%)\")\n",
    "    \n",
    "    print(f\"\\nValidation set ({len(val_labels)} samples):\")\n",
    "    for cls_idx in sorted(val_dist.keys()):\n",
    "        count = val_dist[cls_idx]\n",
    "        pct = count / len(val_labels) * 100\n",
    "        print(f\"  {reverse_label_map[cls_idx]:<30s}: {count:>5d} ({pct:>5.2f}%)\")\n",
    "    \n",
    "    # Calculate key metrics\n",
    "    fold_info = {\n",
    "        'fold': fold,\n",
    "        'train_size': len(train_labels),\n",
    "        'val_size': len(val_labels),\n",
    "        'train_fall_init': train_dist.get(5, 0),  # Fall_Initiation is class 5\n",
    "        'val_fall_init': val_dist.get(5, 0),\n",
    "        'train_fall_recovery': train_dist.get(4, 0),  # Fall_Recovery is class 4\n",
    "        'val_fall_recovery': val_dist.get(4, 0),\n",
    "        'train_impact_aftermath': train_dist.get(6, 0),  # Impact_Aftermath is class 6\n",
    "        'val_impact_aftermath': val_dist.get(6, 0),\n",
    "    }\n",
    "    \n",
    "    fold_distributions.append(fold_info)\n",
    "\n",
    "# Create comparison DataFrame\n",
    "import pandas as pd\n",
    "fold_df = pd.DataFrame(fold_distributions)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPARISON ACROSS FOLDS\")\n",
    "print(\"=\"*80)\n",
    "print(fold_df.to_string(index=False))\n",
    "\n",
    "# Visualize distribution\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "fig.suptitle('Class Distribution Across Folds', fontsize=16, fontweight='bold')\n",
    "\n",
    "for fold in range(1, 6):\n",
    "    ax = axes[(fold-1)//3, (fold-1)%3]\n",
    "    \n",
    "    fold_idx = fold - 1\n",
    "    train_idx, val_idx = list(skf.split(X_data, y_labels))[fold_idx]\n",
    "    \n",
    "    train_labels = y_labels[train_idx]\n",
    "    val_labels = y_labels[val_idx]\n",
    "    \n",
    "    train_dist = Counter(train_labels)\n",
    "    val_dist = Counter(val_labels)\n",
    "    \n",
    "    classes = sorted(set(train_dist.keys()) | set(val_dist.keys()))\n",
    "    train_counts = [train_dist.get(c, 0) for c in classes]\n",
    "    val_counts = [val_dist.get(c, 0) for c in classes]\n",
    "    \n",
    "    x = np.arange(len(classes))\n",
    "    width = 0.35\n",
    "    \n",
    "    ax.bar(x - width/2, train_counts, width, label='Train', alpha=0.8)\n",
    "    ax.bar(x + width/2, val_counts, width, label='Val', alpha=0.8)\n",
    "    \n",
    "    ax.set_xlabel('Class')\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.set_title(f'Fold {fold}')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels([reverse_label_map[c][:10] for c in classes], rotation=45, ha='right')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Hide the 6th subplot (we only have 5 folds)\n",
    "axes[1, 2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / 'fold_distributions.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n‚úÖ Fold distribution analysis saved to {output_dir / 'fold_distributions.png'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "## First Epoch Performance Analysis\n",
    "\n",
    "# %%\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYZING FIRST EPOCH RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# You need to have saved the fold_histories from training\n",
    "# If you have them:\n",
    "\n",
    "for fold in range(1, 6):\n",
    "    if fold-1 < len(fold_histories):\n",
    "        history = fold_histories[fold-1]\n",
    "        \n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"FOLD {fold} - FIRST EPOCH\")\n",
    "        print(f\"{'='*50}\")\n",
    "        print(f\"Train Loss:      {history['loss'][0]:.4f}\")\n",
    "        print(f\"Train Accuracy:  {history['accuracy'][0]:.4f}\")\n",
    "        print(f\"Val Loss:        {history['val_loss'][0]:.4f}\")\n",
    "        print(f\"Val Accuracy:    {history['val_accuracy'][0]:.4f}\")\n",
    "        \n",
    "        # Check for warning signs\n",
    "        if history['val_loss'][0] > 2.0:\n",
    "            print(\"‚ö†Ô∏è  WARNING: Very high initial loss!\")\n",
    "        if history['val_accuracy'][0] < 0.20:\n",
    "            print(\"‚ö†Ô∏è  WARNING: Worse than random guessing!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After training, add this cell:\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "# Get predictions on all data\n",
    "best_model = keras.models.load_model(output_dir / f'fallnet_fold_{best_fold}.keras')\n",
    "y_pred_probs = best_model.predict(X_data, verbose=0)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "# Create confusion matrix\n",
    "cm = confusion_matrix(y_labels, y_pred)\n",
    "\n",
    "# Create DataFrame for better visualization\n",
    "class_names = [reverse_label_map[i] for i in range(8)]\n",
    "cm_df = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CONFUSION MATRIX (Counts)\")\n",
    "print(\"=\"*80)\n",
    "print(cm_df)\n",
    "\n",
    "# Normalized version (percentages)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "cm_normalized_df = pd.DataFrame(cm_normalized, index=class_names, columns=class_names)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CONFUSION MATRIX (Percentages - Row-wise)\")\n",
    "print(\"=\"*80)\n",
    "print(cm_normalized_df.round(3))\n",
    "\n",
    "# Check prediction distribution\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PREDICTION DISTRIBUTION\")\n",
    "print(\"=\"*80)\n",
    "pred_counts = pd.Series(y_pred).value_counts().sort_index()\n",
    "for cls_idx, count in pred_counts.items():\n",
    "    pct = count / len(y_pred) * 100\n",
    "    print(f\"{reverse_label_map[cls_idx]:<40s} {count:>6d} ({pct:>5.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tensorflow import keras\n",
    "\n",
    "base_dir = Path(\"~/repos/summerschool2023/projects/fall-detection/fall_detection_data\").expanduser()\n",
    "models_dir = base_dir / \"models\"\n",
    "processed_dir = base_dir / \"processed\"\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"COMPLETE DATA/MODEL AUDIT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. Check what's in processed data on disk\n",
    "print(\"\\nüìä PROCESSED DATA ON DISK:\")\n",
    "y_disk = np.load(processed_dir / \"y_labels.npy\")\n",
    "X_disk = np.load(processed_dir / \"X_data.npy\")\n",
    "\n",
    "print(f\"X_data.npy:\")\n",
    "print(f\"  Shape: {X_disk.shape}\")\n",
    "print(f\"y_labels.npy:\")\n",
    "print(f\"  Shape: {y_disk.shape}\")\n",
    "print(f\"  Classes: {sorted(np.unique(y_disk))}\")\n",
    "print(f\"  Number of classes: {len(np.unique(y_disk))}\")\n",
    "print(f\"  Range: {y_disk.min()}-{y_disk.max()}\")\n",
    "\n",
    "if len(np.unique(y_disk)) == 8:\n",
    "    print(\"\\n‚ùå DISK DATA: 8 classes (0-7) - ORIGINAL preprocessed data\")\n",
    "elif len(np.unique(y_disk)) == 6:\n",
    "    print(\"\\n‚úÖ DISK DATA: 6 classes (0-5) - CLEANED data\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è  DISK DATA: {len(np.unique(y_disk))} classes - UNEXPECTED!\")\n",
    "\n",
    "# 2. Check what the models expect\n",
    "print(\"\\nü§ñ MODEL EXPECTATIONS:\")\n",
    "model = keras.models.load_model(models_dir / 'fallnet_fold_1.keras')\n",
    "print(f\"Model input shape: {model.input_shape}\")\n",
    "print(f\"Model output shape: {model.output_shape}\")\n",
    "print(f\"Model expects {model.output_shape[-1]} classes\")\n",
    "\n",
    "# 3. Try a prediction to see what happens\n",
    "print(\"\\nüîÆ TEST PREDICTION:\")\n",
    "try:\n",
    "    y_pred_probs = model.predict(X_disk[:10], verbose=0)\n",
    "    print(f\"‚úÖ Prediction successful!\")\n",
    "    print(f\"   Prediction shape: {y_pred_probs.shape}\")\n",
    "    print(f\"   Model outputs: {y_pred_probs.shape[-1]} class probabilities\")\n",
    "    \n",
    "    # Check what classes it's actually predicting\n",
    "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "    print(f\"   Predicted classes (first 10): {y_pred}\")\n",
    "    print(f\"   Actual classes (first 10):    {y_disk[:10]}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Prediction failed: {e}\")\n",
    "\n",
    "# 4. The verdict\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DIAGNOSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if len(np.unique(y_disk)) == model.output_shape[-1]:\n",
    "    print(f\"‚úÖ MATCH: Data has {len(np.unique(y_disk))} classes, model outputs {model.output_shape[-1]} classes\")\n",
    "    print(\"\\n   The model SHOULD work with this data!\")\n",
    "    print(\"   If evaluation fails, something else is wrong.\")\n",
    "else:\n",
    "    print(f\"‚ùå MISMATCH!\")\n",
    "    print(f\"   Data has {len(np.unique(y_disk))} classes (range: {y_disk.min()}-{y_disk.max()})\")\n",
    "    print(f\"   Model expects {model.output_shape[-1]} classes\")\n",
    "    print(f\"\\n   This is why evaluation fails!\")\n",
    "    \n",
    "    if len(np.unique(y_disk)) == 8 and model.output_shape[-1] == 6:\n",
    "        print(\"\\n   SOLUTION: Your models were trained on 6-class data IN MEMORY\")\n",
    "        print(\"   But y_labels.npy on disk still has 8 classes!\")\n",
    "        print(\"   You need to save the 6-class data to disk.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # Data Loading and Preprocessing\n",
    "# Load preprocessed data, merge classes, remove Fall_Recovery\n",
    "\n",
    "# %%\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "from tensorflow import keras\n",
    "\n",
    "# Setup paths\n",
    "base_dir = Path(\"~/repos/summerschool2023/projects/fall-detection/fall_detection_data\").expanduser()\n",
    "processed_dir = base_dir / \"processed\"\n",
    "output_dir = base_dir / \"models\"\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"LOADING AND PREPROCESSING DATA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# %% Load the newly processed data\n",
    "X_data = np.load(processed_dir / \"X_data.npy\")\n",
    "y_labels = np.load(processed_dir / \"y_labels.npy\")\n",
    "\n",
    "print(f\"\\nOriginal data loaded:\")\n",
    "print(f\"  X_data shape: {X_data.shape}\")\n",
    "print(f\"  y_labels shape: {y_labels.shape}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 1: Merge Impact and Aftermath\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 1: MERGING IMPACT AND AFTERMATH\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "counts_before_merge = Counter(y_labels)\n",
    "print(f\"Before merge:\")\n",
    "print(f\"  Impact (6): {counts_before_merge[6]} samples\")\n",
    "print(f\"  Aftermath (7): {counts_before_merge[7]} samples\")\n",
    "\n",
    "y_labels[y_labels == 7] = 6  # Change Aftermath (7) to Impact (6)\n",
    "\n",
    "counts_after_merge = Counter(y_labels)\n",
    "print(f\"\\nAfter merge:\")\n",
    "print(f\"  Impact_Aftermath (6): {counts_after_merge[6]} samples\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 2: Remove Fall_Recovery\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 2: REMOVING FALL_RECOVERY CLASS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Show before\n",
    "counts_before = Counter(y_labels)\n",
    "print(f\"\\nBefore removal:\")\n",
    "print(f\"  Total samples: {len(y_labels):,}\")\n",
    "print(f\"  Fall_Recovery (class 4): {counts_before[4]} samples\")\n",
    "\n",
    "# Remove Fall_Recovery (class 4)\n",
    "mask = y_labels != 4\n",
    "X_data = X_data[mask]\n",
    "y_labels_temp = y_labels[mask]\n",
    "\n",
    "removed_count = (~mask).sum()\n",
    "print(f\"\\n‚úÖ Removed {removed_count} Fall_Recovery samples\")\n",
    "\n",
    "# Shift labels down (5‚Üí4, 6‚Üí5)\n",
    "y_labels = y_labels_temp.copy()\n",
    "y_labels[y_labels_temp > 4] -= 1  # Classes 5,6 become 4,5\n",
    "\n",
    "print(f\"\\nAfter removal:\")\n",
    "print(f\"  Total samples: {len(y_labels):,}\")\n",
    "print(f\"  Removed: {removed_count} samples ({removed_count/(len(y_labels)+removed_count)*100:.2f}%)\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 3: Update label map (NOW 6 CLASSES: 0-5)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 3: CREATING 6-CLASS LABEL MAP\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "label_map = {\n",
    "    'Walking': 0,\n",
    "    'Jogging': 1,\n",
    "    'Walking_stairs_updown': 2,\n",
    "    'Stumble_while_walking': 3,\n",
    "    'Fall_Initiation': 4,      # Was 5, now 4\n",
    "    'Impact_Aftermath': 5,     # Was 6, now 5\n",
    "}\n",
    "reverse_label_map = {v: k for k, v in label_map.items()}\n",
    "\n",
    "print(f\"\\n‚úÖ Updated to 6 classes (0-5):\")\n",
    "for name, idx in sorted(label_map.items(), key=lambda x: x[1]):\n",
    "    print(f\"  Class {idx}: {name}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 4: Create categorical labels\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 4: CREATING CATEGORICAL LABELS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "y_categorical = keras.utils.to_categorical(y_labels, num_classes=6)\n",
    "\n",
    "print(f\"\\n‚úÖ y_categorical created:\")\n",
    "print(f\"   Shape: {y_categorical.shape}\")\n",
    "print(f\"   Expected: ({len(y_labels)}, 6)\")\n",
    "\n",
    "# Verification\n",
    "assert X_data.shape[0] == y_labels.shape[0] == y_categorical.shape[0], \\\n",
    "    \"Data shapes don't match!\"\n",
    "\n",
    "print(f\"\\n‚úÖ All data aligned:\")\n",
    "print(f\"   X_data:        {X_data.shape}\")\n",
    "print(f\"   y_labels:      {y_labels.shape}\")\n",
    "print(f\"   y_categorical: {y_categorical.shape}\")\n",
    "print(f\"   All have {X_data.shape[0]:,} samples\")\n",
    "\n",
    "# ============================================================================\n",
    "# DIAGNOSTICS\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DATA QUALITY DIAGNOSTICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. Class distribution\n",
    "class_counts = Counter(y_labels)\n",
    "print(\"\\n1. Class Distribution (6 classes):\")\n",
    "for cls_idx in sorted(class_counts.keys()):\n",
    "    count = class_counts[cls_idx]\n",
    "    pct = count / len(y_labels) * 100\n",
    "    print(f\"   Class {cls_idx} ({reverse_label_map[cls_idx]:30s}): {count:5d} ({pct:5.2f}%)\")\n",
    "\n",
    "# Calculate imbalance\n",
    "max_count = max(class_counts.values())\n",
    "min_count = min(class_counts.values())\n",
    "print(f\"\\nImbalance ratio: {max_count/min_count:.2f}x\")\n",
    "print(f\"  (was 36.8x with Fall_Recovery)\")\n",
    "\n",
    "# 2. Per-class signal statistics\n",
    "print(\"\\n2. Per-Class Signal Statistics (Acc-Y axis):\")\n",
    "print(f\"   {'Class':<35s} {'Mean':<10s} {'Std':<10s} {'Min':<10s} {'Max':<10s}\")\n",
    "print(f\"   {'-'*75}\")\n",
    "for cls_idx in sorted(class_counts.keys()):\n",
    "    class_samples = X_data[y_labels == cls_idx]\n",
    "    acc_y = class_samples[:, :, 1]  # Y-axis acceleration\n",
    "    \n",
    "    mean_val = acc_y.mean()\n",
    "    std_val = acc_y.std()\n",
    "    min_val = acc_y.min()\n",
    "    max_val = acc_y.max()\n",
    "    \n",
    "    print(f\"   {reverse_label_map[cls_idx]:<35s} {mean_val:>8.4f}  {std_val:>8.4f}  {min_val:>8.2f}  {max_val:>8.2f}\")\n",
    "\n",
    "# 3. Variance ranking\n",
    "print(\"\\n3. Variance Ranking (Fall_Initiation should be #1):\")\n",
    "variances = []\n",
    "for cls_idx in sorted(class_counts.keys()):\n",
    "    class_samples = X_data[y_labels == cls_idx]\n",
    "    acc_y_var = class_samples[:, :, 1].var()\n",
    "    variances.append((reverse_label_map[cls_idx], acc_y_var, cls_idx))\n",
    "variances.sort(key=lambda x: x[1], reverse=True)\n",
    "for i, (name, var, idx) in enumerate(variances, 1):\n",
    "    print(f\"   {i}. {name:<35s}: {var:.4f}\")\n",
    "\n",
    "# 4. Visualize samples\n",
    "fig, axes = plt.subplots(3, 2, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "critical_classes = [\n",
    "    label_map['Walking'],\n",
    "    label_map['Fall_Initiation'],\n",
    "    label_map['Impact_Aftermath'],\n",
    "    label_map['Stumble_while_walking'],\n",
    "    label_map['Jogging'],\n",
    "    label_map['Walking_stairs_updown']\n",
    "]\n",
    "\n",
    "for i, cls_idx in enumerate(critical_classes):\n",
    "    if cls_idx in class_counts:\n",
    "        sample_idx = np.where(y_labels == cls_idx)[0][0]\n",
    "        sample_data = X_data[sample_idx]\n",
    "        \n",
    "        time = np.arange(200) / 200\n",
    "        axes[i].plot(time, sample_data[:, 0], label='Acc-X', alpha=0.7, linewidth=1)\n",
    "        axes[i].plot(time, sample_data[:, 1], label='Acc-Y', alpha=0.7, linewidth=1)\n",
    "        axes[i].plot(time, sample_data[:, 2], label='Acc-Z', alpha=0.7, linewidth=1)\n",
    "        \n",
    "        axes[i].set_title(f'{reverse_label_map[cls_idx]}', fontsize=11, fontweight='bold')\n",
    "        axes[i].set_xlabel('Time (s)')\n",
    "        axes[i].set_ylabel('Normalized Acc')\n",
    "        axes[i].legend(fontsize=8)\n",
    "        axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ DATA READY FOR TRAINING (6 CLASSES)\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SAVING 6-CLASS DATA TO DISK\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Save 6-class data with different names (preserve 8-class original)\n",
    "np.save(processed_dir / \"X_data_6class.npy\", X_data)\n",
    "np.save(processed_dir / \"y_labels_6class.npy\", y_labels)\n",
    "\n",
    "# Save 6-class label map\n",
    "with open(processed_dir / \"label_map_6class.json\", 'w') as f:\n",
    "    json.dump(label_map, f, indent=2)\n",
    "\n",
    "print(f\"\\n‚úÖ Saved 6-class data:\")\n",
    "print(f\"   üìÑ X_data_6class.npy: {X_data.shape}\")\n",
    "print(f\"   üìÑ y_labels_6class.npy: {y_labels.shape}\")\n",
    "print(f\"   üìÑ label_map_6class.json\")\n",
    "\n",
    "print(f\"\\n‚úÖ Original 8-class data preserved:\")\n",
    "print(f\"   üìÑ X_data.npy: (16891, 200, 6) - untouched\")\n",
    "print(f\"   üìÑ y_labels.npy: (16891,) - untouched\")\n",
    "print(f\"   üìÑ label_map.json - untouched\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"NOW YOU CAN EVALUATE YOUR MODELS!\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nTo load 6-class data in future sessions:\")\n",
    "print(\"   X_data = np.load(processed_dir / 'X_data_6class.npy')\")\n",
    "print(\"   y_labels = np.load(processed_dir / 'y_labels_6class.npy')\")\n",
    "print(\"\\nTo load 8-class data (original):\")\n",
    "print(\"   X_data = np.load(processed_dir / 'X_data.npy')\")\n",
    "print(\"   y_labels = np.load(processed_dir / 'y_labels.npy')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # Evaluate FallNet Model (6-Class Data)\n",
    "\n",
    "# %%\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from collections import Counter\n",
    "\n",
    "# ============================================================================\n",
    "# Setup Paths\n",
    "# ============================================================================\n",
    "base_dir = Path(\"~/repos/summerschool2023/projects/fall-detection/fall_detection_data\").expanduser()\n",
    "processed_dir = base_dir / \"processed\"\n",
    "models_dir = base_dir / \"models\"\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"LOADING 6-CLASS DATA AND MODEL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ============================================================================\n",
    "# Load 6-Class Data\n",
    "# ============================================================================\n",
    "X_data = np.load(processed_dir / \"X_data_6class.npy\")\n",
    "y_labels = np.load(processed_dir / \"y_labels_6class.npy\")\n",
    "\n",
    "print(f\"\\nüìä Data loaded:\")\n",
    "print(f\"   X_data: {X_data.shape}\")\n",
    "print(f\"   y_labels: {y_labels.shape}\")\n",
    "print(f\"   Unique classes: {sorted(np.unique(y_labels))}\")\n",
    "print(f\"   Number of classes: {len(np.unique(y_labels))}\")\n",
    "\n",
    "# ============================================================================\n",
    "# Load 6-Class Label Map\n",
    "# ============================================================================\n",
    "with open(processed_dir / \"label_map_6class.json\", \"r\") as f:\n",
    "    label_map = json.load(f)\n",
    "\n",
    "reverse_label_map = {v: k for k, v in label_map.items()}\n",
    "class_names = [reverse_label_map[i] for i in range(6)]\n",
    "\n",
    "print(f\"\\nüìã Class names:\")\n",
    "for idx, name in enumerate(class_names):\n",
    "    count = (y_labels == idx).sum()\n",
    "    pct = count / len(y_labels) * 100\n",
    "    print(f\"   {idx}: {name:<30s} ({count:>5,} samples, {pct:>5.2f}%)\")\n",
    "\n",
    "# ============================================================================\n",
    "# Load Model\n",
    "# ============================================================================\n",
    "print(f\"\\nüîß Loading model...\")\n",
    "model_path = models_dir / 'fallnet_fold_1.keras'\n",
    "\n",
    "if not model_path.exists():\n",
    "    print(f\"\\n‚ùå ERROR: Model not found at {model_path}\")\n",
    "    print(\"Available models:\")\n",
    "    for f in models_dir.glob(\"*.keras\"):\n",
    "        print(f\"  - {f.name}\")\n",
    "else:\n",
    "    model = keras.models.load_model(model_path)\n",
    "    print(f\"‚úÖ Model loaded: {model_path.name}\")\n",
    "    print(f\"   Input shape: {model.input_shape}\")\n",
    "    print(f\"   Output shape: {model.output_shape}\")\n",
    "    print(f\"   Total params: {model.count_params():,}\")\n",
    "\n",
    "# ============================================================================\n",
    "# Verify Compatibility\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPATIBILITY CHECK\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "n_classes_data = len(np.unique(y_labels))\n",
    "n_classes_model = model.output_shape[-1]\n",
    "\n",
    "print(f\"Data classes: {n_classes_data}\")\n",
    "print(f\"Model outputs: {n_classes_model}\")\n",
    "\n",
    "if n_classes_data == n_classes_model:\n",
    "    print(f\"‚úÖ MATCH! Data and model are compatible!\")\n",
    "else:\n",
    "    print(f\"‚ùå MISMATCH! Cannot evaluate!\")\n",
    "    raise ValueError(f\"Data has {n_classes_data} classes but model expects {n_classes_model}\")\n",
    "\n",
    "# ============================================================================\n",
    "# Make Predictions\n",
    "#      ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MAKING PREDICTIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"Predicting on {len(X_data):,} samples...\")\n",
    "y_pred_probs = model.predict(X_data, verbose=1)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "print(f\"\\n‚úÖ Predictions complete\")\n",
    "print(f\"   Predicted classes: {sorted(np.unique(y_pred))}\")\n",
    "\n",
    "# ============================================================================\n",
    "# Overall Accuracy\n",
    "# ============================================================================\n",
    "overall_acc = (y_pred == y_labels).mean()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"OVERALL PERFORMANCE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Accuracy: {overall_acc:.4f} ({overall_acc*100:.2f}%)\")\n",
    "\n",
    "# ============================================================================\n",
    "# Classification Report\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CLASSIFICATION REPORT\")\n",
    "print(\"=\"*80)\n",
    "print(classification_report(y_labels, y_pred, target_names=class_names, digits=4))\n",
    "\n",
    "# ============================================================================\n",
    "# Confusion Matrix\n",
    "# ============================================================================\n",
    "cm = confusion_matrix(y_labels, y_pred)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CONFUSION MATRIX\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'True \\\\ Pred':<25s}\", end=\"\")\n",
    "for name in class_names:\n",
    "    print(f\"{name[:10]:>10s}\", end=\"\")\n",
    "print()\n",
    "\n",
    "for i, true_name in enumerate(class_names):\n",
    "    print(f\"{true_name[:25]:<25s}\", end=\"\")\n",
    "    for j in range(6):\n",
    "        print(f\"{cm[i,j]:>10d}\", end=\"\")\n",
    "    total = cm[i].sum()\n",
    "    correct = cm[i,i]\n",
    "    acc_row = correct / total if total > 0 else 0\n",
    "    print(f\"  | {correct:>5d}/{total:<5d} ({acc_row*100:>5.1f}%)\")\n",
    "\n",
    "print()\n",
    "\n",
    "# ============================================================================\n",
    "# Per-Class Detailed Metrics\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PER-CLASS DETAILED METRICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n{'Class':<30s} {'Precision':<12s} {'Recall':<12s} {'F1-Score':<12s} {'Support'}\")\n",
    "print(\"-\"*90)\n",
    "\n",
    "for cls_idx in range(6):\n",
    "    precision = precision_score(y_labels == cls_idx, y_pred == cls_idx, zero_division=0)\n",
    "    recall = recall_score(y_labels == cls_idx, y_pred == cls_idx, zero_division=0)\n",
    "    f1 = f1_score(y_labels == cls_idx, y_pred == cls_idx, zero_division=0)\n",
    "    support = (y_labels == cls_idx).sum()\n",
    "    \n",
    "    status = \"‚úÖ\" if recall > 0.90 else \"‚ö†Ô∏è\" if recall > 0.80 else \"‚ùå\"\n",
    "    print(f\"{class_names[cls_idx]:<30s} {precision:<12.4f} {recall:<12.4f} {f1:<12.4f} {support:>7d} {status}\")\n",
    "\n",
    "# ============================================================================\n",
    "# Fall_Initiation Focus (Critical Class)\n",
    "# ============================================================================\n",
    "fall_init_idx = label_map[\"Fall_Initiation\"]\n",
    "fall_init_precision = precision_score(y_labels == fall_init_idx, y_pred == fall_init_idx)\n",
    "fall_init_recall = recall_score(y_labels == fall_init_idx, y_pred == fall_init_idx)\n",
    "fall_init_f1 = f1_score(y_labels == fall_init_idx, y_pred == fall_init_idx)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FALL_INITIATION PERFORMANCE (CRITICAL CLASS)\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Precision: {fall_init_precision:.4f} ({fall_init_precision*100:.2f}%)\")\n",
    "print(f\"Recall:    {fall_init_recall:.4f} ({fall_init_recall*100:.2f}%)\")\n",
    "print(f\"F1-Score:  {fall_init_f1:.4f} ({fall_init_f1*100:.2f}%)\")\n",
    "\n",
    "print(\"\\nüìä Comparison with Paper:\")\n",
    "print(f\"   Paper (8 classes):  99.24% recall\")\n",
    "print(f\"   Yours (6 classes):  {fall_init_recall*100:.2f}% recall\")\n",
    "print(f\"   Difference:         {(fall_init_recall - 0.9924)*100:+.2f}%\")\n",
    "\n",
    "# ============================================================================\n",
    "# Final Summary\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "all_recalls_good = all(recall_score(y_labels == i, y_pred == i, zero_division=0) > 0.85 for i in range(6))\n",
    "\n",
    "print(f\"\\n‚úÖ Overall Accuracy:        {overall_acc:.4f} ({overall_acc*100:.2f}%)\")\n",
    "print(f\"‚úÖ Fall_Initiation Recall:  {fall_init_recall:.4f} ({fall_init_recall*100:.2f}%)\")\n",
    "print(f\"‚úÖ All classes >85% recall: {all_recalls_good}\")\n",
    "\n",
    "if overall_acc > 0.95:\n",
    "    print(\"\\nüéâ EXCELLENT! Model is performing at publication quality!\")\n",
    "    print(\"   Ready for Phase 2: SNN conversion!\")\n",
    "elif overall_acc > 0.85:\n",
    "    print(\"\\n‚úÖ VERY GOOD! Solid baseline for SNN comparison!\")\n",
    "    print(\"   This matches your K-fold CV expectations (87% avg)!\")\n",
    "elif overall_acc > 0.70:\n",
    "    print(\"\\nü§î MODERATE: Acceptable but room for improvement\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  LOWER THAN EXPECTED: May need investigation\")\n",
    "\n",
    "print(f\"\\nüìÅ Model evaluated: {model_path.name}\")\n",
    "print(f\"üìÖ Model saved: Jan 5, 2026 at 18:39\")\n",
    "print(f\"üìä Dataset: 6-class (16,732 samples)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "# Load 6-class data\n",
    "X_data = np.load(processed_dir / \"X_data_6class.npy\")\n",
    "y_labels = np.load(processed_dir / \"y_labels_6class.npy\")\n",
    "\n",
    "# Create categorical labels\n",
    "y_categorical = keras.utils.to_categorical(y_labels, num_classes=6)\n",
    "\n",
    "print(f\"‚úÖ Created y_categorical: {y_categorical.shape}\")\n",
    "print(f\"   From y_labels: {y_labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import legendre\n",
    "\n",
    "# Create a fall signal\n",
    "t = np.linspace(-1, 1, 200)\n",
    "\n",
    "# Simulate: Walking ‚Üí Fall Initiation ‚Üí Impact\n",
    "signal = np.zeros(200)\n",
    "signal[:66] = 0.5 + 0.1*np.sin(10*t[:66])  # Walking (oscillation)\n",
    "signal[66:133] = 0.5 + 2.5*(t[66:133] + 0.33)**2  # Fall initiation (acceleration)\n",
    "signal[133:] = 3.5 + 0.2*np.random.randn(67)  # Impact (high + noisy)\n",
    "\n",
    "# Show what each coefficient captures\n",
    "fig, axes = plt.subplots(4, 2, figsize=(14, 12))\n",
    "\n",
    "# Original signal\n",
    "axes[0, 0].plot(t, signal, 'b-', linewidth=2)\n",
    "axes[0, 0].set_title('Original Fall Signal', fontweight='bold')\n",
    "axes[0, 0].axvline(-0.33, color='r', linestyle='--', alpha=0.5, label='Fall starts')\n",
    "axes[0, 0].axvline(0.33, color='orange', linestyle='--', alpha=0.5, label='Impact')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Show what each polynomial contributes\n",
    "components_to_show = [0, 1, 2, 3, 5, 10, 20]\n",
    "coeffs = np.polyfit(t, signal, deg=20)  # Simplified - use proper Legendre fitting\n",
    "\n",
    "for idx, n in enumerate(components_to_show):\n",
    "    ax = axes[(idx+1)//2, (idx+1)%2]\n",
    "    \n",
    "    # Get the nth Legendre polynomial\n",
    "    P_n = legendre(n)\n",
    "    \n",
    "    # Compute coefficient (project signal onto this polynomial)\n",
    "    c_n = np.trapz(signal * P_n(t), t) * (2*n + 1) / 2\n",
    "    \n",
    "    # Show the contribution of this polynomial\n",
    "    contribution = c_n * P_n(t)\n",
    "    \n",
    "    ax.plot(t, P_n(t), 'gray', alpha=0.3, linewidth=1, label=f'P_{n}(t)')\n",
    "    ax.plot(t, contribution, 'r-', linewidth=2, label=f'c_{n} ¬∑ P_{n}(t)')\n",
    "    ax.axhline(0, color='black', linewidth=0.5, linestyle='--', alpha=0.3)\n",
    "    \n",
    "    ax.set_title(f'Component {n}: c_{n} = {c_n:.3f}', fontweight='bold')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add interpretation\n",
    "    if n == 0:\n",
    "        ax.text(0.5, 0.95, 'Average level', transform=ax.transAxes, \n",
    "                ha='center', va='top', bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.3))\n",
    "    elif n == 1:\n",
    "        ax.text(0.5, 0.95, 'Overall trend', transform=ax.transAxes,\n",
    "                ha='center', va='top', bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.3))\n",
    "    elif n == 2:\n",
    "        ax.text(0.5, 0.95, 'Curvature', transform=ax.transAxes,\n",
    "                ha='center', va='top', bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.3))\n",
    "    elif n == 3:\n",
    "        ax.text(0.5, 0.95, 'S-curve pattern', transform=ax.transAxes,\n",
    "                ha='center', va='top', bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.3))\n",
    "    else:\n",
    "        ax.text(0.5, 0.95, f'Fine detail ({n}th order)', transform=ax.transAxes,\n",
    "                ha='center', va='top', bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.3))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('What Each Legendre Coefficient Captures', fontsize=14, fontweight='bold', y=1.00)\n",
    "plt.show()\n",
    "\n",
    "# Print what each captures\n",
    "print(\"=\"*80)\n",
    "print(\"LEGENDRE COEFFICIENT INTERPRETATION\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nFor a fall detection signal:\")\n",
    "print(f\"\\nc‚ÇÄ = {c_n:.3f}  ‚Üí Average acceleration level\")\n",
    "print(\"            Large positive = high activity\")\n",
    "print(\"            Near zero = stationary\")\n",
    "print(f\"\\nc‚ÇÅ ‚Üí Trend direction\")\n",
    "print(\"            Positive = acceleration increasing over time\")\n",
    "print(\"            Negative = acceleration decreasing\")\n",
    "print(f\"\\nc‚ÇÇ ‚Üí Curvature/acceleration of acceleration\")\n",
    "print(\"            Large value = rapid change (like fall initiation!)\")\n",
    "print(f\"\\nc‚ÇÉ‚Çã‚ÇÅ‚ÇÄ ‚Üí Medium temporal features\")\n",
    "print(\"            Captures rhythmic patterns (walking, stumbling)\")\n",
    "print(f\"\\nc‚ÇÅ‚ÇÅ‚Çä ‚Üí Fine temporal details\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import legendre\n",
    "\n",
    "x = np.linspace(-1, 1, 1000)\n",
    "\n",
    "# Two EVEN polynomials\n",
    "P0 = legendre(0)(x)\n",
    "P2 = legendre(2)(x)\n",
    "product_even = P0 * P2\n",
    "\n",
    "# Two ODD polynomials\n",
    "P1 = legendre(1)(x)\n",
    "P3 = legendre(3)(x)\n",
    "product_odd = P1 * P3\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "\n",
    "# Even example: P‚ÇÄ √ó P‚ÇÇ\n",
    "axes[0, 0].plot(x, P0, 'b-', linewidth=2, label='P‚ÇÄ(x)')\n",
    "axes[0, 0].set_title('P‚ÇÄ(x) - EVEN', fontweight='bold')\n",
    "axes[0, 0].axhline(0, color='black', linewidth=0.5, alpha=0.3)\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "axes[0, 0].legend()\n",
    "\n",
    "axes[0, 1].plot(x, P2, 'r-', linewidth=2, label='P‚ÇÇ(x)')\n",
    "axes[0, 1].set_title('P‚ÇÇ(x) - EVEN', fontweight='bold')\n",
    "axes[0, 1].axhline(0, color='black', linewidth=0.5, alpha=0.3)\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "axes[0, 1].legend()\n",
    "\n",
    "axes[0, 2].plot(x, product_even, 'purple', linewidth=2, label='P‚ÇÄ √ó P‚ÇÇ')\n",
    "axes[0, 2].fill_between(x, 0, product_even, alpha=0.3, color='purple')\n",
    "axes[0, 2].axhline(0, color='black', linewidth=0.5, alpha=0.3)\n",
    "axes[0, 2].set_title('P‚ÇÄ √ó P‚ÇÇ - Product', fontweight='bold')\n",
    "axes[0, 2].grid(True, alpha=0.3)\n",
    "axes[0, 2].legend()\n",
    "\n",
    "# Calculate integral\n",
    "integral_even = np.trapz(product_even, x)\n",
    "axes[0, 2].text(0.5, 0.95, f'‚à´ = {integral_even:.6f} ‚âà 0', \n",
    "                transform=axes[0, 2].transAxes, ha='center', va='top',\n",
    "                bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.7))\n",
    "\n",
    "# Odd example: P‚ÇÅ √ó P‚ÇÉ\n",
    "axes[1, 0].plot(x, P1, 'g-', linewidth=2, label='P‚ÇÅ(x)')\n",
    "axes[1, 0].set_title('P‚ÇÅ(x) - ODD', fontweight='bold')\n",
    "axes[1, 0].axhline(0, color='black', linewidth=0.5, alpha=0.3)\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "axes[1, 0].legend()\n",
    "\n",
    "axes[1, 1].plot(x, P3, 'orange', linewidth=2, label='P‚ÇÉ(x)')\n",
    "axes[1, 1].set_title('P‚ÇÉ(x) - ODD', fontweight='bold')\n",
    "axes[1, 1].axhline(0, color='black', linewidth=0.5, alpha=0.3)\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "axes[1, 1].legend()\n",
    "\n",
    "axes[1, 2].plot(x, product_odd, 'brown', linewidth=2, label='P‚ÇÅ √ó P‚ÇÉ')\n",
    "axes[1, 2].fill_between(x, 0, product_odd, alpha=0.3, color='brown')\n",
    "axes[1, 2].axhline(0, color='black', linewidth=0.5, alpha=0.3)\n",
    "axes[1, 2].set_title('P‚ÇÅ √ó P‚ÇÉ - Product', fontweight='bold')\n",
    "axes[1, 2].grid(True, alpha=0.3)\n",
    "axes[1, 2].legend()\n",
    "\n",
    "# Calculate integral\n",
    "integral_odd = np.trapz(product_odd, x)\n",
    "axes[1, 2].text(0.5, 0.95, f'‚à´ = {integral_odd:.6f} ‚âà 0', \n",
    "                transform=axes[1, 2].transAxes, ha='center', va='top',\n",
    "                bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.7))\n",
    "\n",
    "plt.suptitle('Orthogonality: Same Parity Polynomials', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"KEY OBSERVATION\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nNotice the product P‚ÇÄ √ó P‚ÇÇ (both EVEN):\")\n",
    "print(\"  - Has both positive and negative areas\")\n",
    "print(\"  - Areas cancel out when integrated\")\n",
    "print(\"  - Total integral ‚âà 0\")\n",
    "print(\"\\nSame for P‚ÇÅ √ó P‚ÇÉ (both ODD):\")\n",
    "print(\"  - Product has balanced positive/negative regions\")\n",
    "print(\"  - Integral ‚âà 0\")\n",
    "print(\"\\n ALL pairs are orthogonal, not just odd-even!\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "##  The Mathematical Reason:\n",
    "\n",
    "Legendre polynomials are constructed using the **Gram-Schmidt orthogonalization process**:\n",
    "```\n",
    "Start  monomials: 1, x, x¬≤, x¬≥, x‚Å¥, ...\n",
    "\n",
    "P‚ÇÄ = 1  (already normalized)\n",
    "\n",
    "P‚ÇÅ = x - ‚ü®x, P‚ÇÄ‚ü©¬∑P‚ÇÄ  (make orthogonal to P‚ÇÄ)\n",
    "   = x - 0\n",
    "   = x\n",
    "\n",
    "P‚ÇÇ = x¬≤ - ‚ü®x¬≤, P‚ÇÄ‚ü©¬∑P‚ÇÄ - ‚ü®x¬≤, P‚ÇÅ‚ü©¬∑P‚ÇÅ  (make orthogonal to P‚ÇÄ AND P‚ÇÅ)\n",
    "   = x¬≤ - (1/3)¬∑1 - 0¬∑x\n",
    "   = (3x¬≤ - 1)/2  (after normalization)\n",
    "\n",
    "P‚ÇÉ = x¬≥ - ‚ü®x¬≥, P‚ÇÄ‚ü©¬∑P‚ÇÄ - ‚ü®x¬≥, P‚ÇÅ‚ü©¬∑P‚ÇÅ - ‚ü®x¬≥, P‚ÇÇ‚ü©¬∑P‚ÇÇ\n",
    "   = ... (orthogonal to P‚ÇÄ, P‚ÇÅ, AND P‚ÇÇ!)\n",
    "\n",
    "And so on...\n",
    "```\n",
    "\n",
    "**Each new polynomial is constructed to be orthogonal to ALL previous ones!**\n",
    "\n",
    "---\n",
    "\n",
    "## Complete Orthogonality Table:\n",
    "\n",
    "Here's the mathematical statement:\n",
    "```\n",
    "‚à´‚Çã‚ÇÅ¬π P‚Çô(x)¬∑P‚Çò(x) dx = {  0           if n ‚â† m\n",
    "                        {  2/(2n+1)   if n = m\n",
    "```\n",
    "\n",
    "**Examples:**\n",
    "```\n",
    "‚à´‚Çã‚ÇÅ¬π P‚ÇÄ¬∑P‚ÇÄ dx = 2/(2¬∑0+1) = 2\n",
    "‚à´‚Çã‚ÇÅ¬π P‚ÇÅ¬∑P‚ÇÅ dx = 2/(2¬∑1+1) = 2/3\n",
    "‚à´‚Çã‚ÇÅ¬π P‚ÇÇ¬∑P‚ÇÇ dx = 2/(2¬∑2+1) = 2/5\n",
    "‚à´‚Çã‚ÇÅ¬π P‚ÇÉ¬∑P‚ÇÉ dx = 2/(2¬∑3+1) = 2/7\n",
    "\n",
    "‚à´‚Çã‚ÇÅ¬π P‚ÇÄ¬∑P‚ÇÅ dx = 0  ‚Üê Different!\n",
    "‚à´‚Çã‚ÇÅ¬π P‚ÇÄ¬∑P‚ÇÇ dx = 0  ‚Üê Different!\n",
    "‚à´‚Çã‚ÇÅ¬π P‚ÇÅ¬∑P‚ÇÇ dx = 0  ‚Üê Different!\n",
    "‚à´‚Çã‚ÇÅ¬π P‚ÇÇ¬∑P‚ÇÉ dx = 0  ‚Üê Different!\n",
    "‚à´‚Çã‚ÇÅ¬π P‚ÇÖ¬∑P‚Çá dx = 0  ‚Üê Different!\n",
    "\n",
    "ALL pairs with n‚â†m give 0!\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üí° Why This Matters for LMUs:\n",
    "\n",
    "**Because ALL polynomials are orthogonal to each other:**\n",
    "\n",
    "1. **Each coefficient is independent:**\n",
    "```\n",
    "   c‚ÇÄ affects only P‚ÇÄ contribution\n",
    "   c‚ÇÅ affects only P‚ÇÅ contribution\n",
    "   c‚ÇÇ affects only P‚ÇÇ contribution\n",
    "   ...\n",
    "   They don't interfere!\n",
    "```\n",
    "\n",
    "2. **Easy to extract coefficients:**\n",
    "```\n",
    "   c‚Çô = (2n+1)/2 ¬∑ ‚à´‚Çã‚ÇÅ¬π signal(t)¬∑P‚Çô(t) dt\n",
    "   \n",
    "   No need to worry about other polynomials!\n",
    "```\n",
    "\n",
    "3. **Clean memory updates:**\n",
    "```\n",
    "   Each coefficient evolves independently:\n",
    "   dc‚ÇÄ/dt = a‚ÇÄ¬∑c‚ÇÄ + b‚ÇÄ¬∑x(t)\n",
    "   dc‚ÇÅ/dt = a‚ÇÅ¬∑c‚ÇÅ + b‚ÇÅ¬∑x(t)\n",
    "   dc‚ÇÇ/dt = a‚ÇÇ¬∑c‚ÇÇ + b‚ÇÇ¬∑x(t)\n",
    "   ...\n",
    "```\n",
    "\n",
    "**This independence is KEY to why LMUs are efficient!**\n",
    "\n",
    "---\n",
    "\n",
    "## Summary:\n",
    "\n",
    "**Q: Are only odd-even pairs orthogonal?**\n",
    "\n",
    "**A: NO! ALL pairs are orthogonal:**\n",
    "- ‚úÖ Odd ‚ä• Even (P‚ÇÅ ‚ä• P‚ÇÇ, P‚ÇÉ ‚ä• P‚ÇÑ, ...)\n",
    "- ‚úÖ Even ‚ä• Even (P‚ÇÄ ‚ä• P‚ÇÇ, P‚ÇÇ ‚ä• P‚ÇÑ, ...)\n",
    "- ‚úÖ Odd ‚ä• Odd (P‚ÇÅ ‚ä• P‚ÇÉ, P‚ÇÉ ‚ä• P‚ÇÖ, ...)\n",
    "\n",
    "**Key insight:**\n",
    "```\n",
    "‚à´‚Çã‚ÇÅ¬π P‚Çô(x)¬∑P‚Çò(x) dx = 0  for ANY n ‚â† m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_lmu import LMU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In a notebook cell\n",
    "!uv pip install nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Prevent TensorFlow from allocating all GPU memory at once\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"‚úÖ GPU memory growth enabled\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"\\nGPU devices:\")\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# More detailed info\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(f\"\\n‚úÖ Found {len(gpus)} GPU(s):\")\n",
    "    for gpu in gpus:\n",
    "        print(f\"   {gpu}\")\n",
    "        \n",
    "    # Get GPU details\n",
    "    gpu_details = tf.config.experimental.get_device_details(gpus[0])\n",
    "    print(f\"\\nGPU Details:\")\n",
    "    for key, value in gpu_details.items():\n",
    "        print(f\"   {key}: {value}\")\n",
    "else:\n",
    "    print(\"\\n‚ùå No GPU found - running on CPU\")\n",
    "\n",
    "# Test if TensorFlow is actually using GPU\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Testing GPU usage...\")\n",
    "with tf.device('/GPU:0'):\n",
    "    try:\n",
    "        a = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
    "        b = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
    "        c = tf.matmul(a, b)\n",
    "        print(\"‚úÖ Successfully ran operation on GPU\")\n",
    "        print(f\"   Result device: {c.device}\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"‚ùå Failed to use GPU: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "# Add this BEFORE building any model\n",
    "keras.backend.clear_session()\n",
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "# Also manually delete old models\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # FallNet Training Pipeline\n",
    "# CNN-LMU ensemble for fall detection with 6 classes\n",
    "\n",
    "# %%\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_score, recall_score, f1_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from keras_lmu import LMU\n",
    "fallnet_fold\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU available: {tf.config.list_physical_devices('GPU')}\")\n",
    "\n",
    "# %% [markdown]\n",
    "## 1. FallNet Model Architecture\n",
    "\n",
    "# %%\n",
    "class FallNet:\n",
    "    \"\"\"\n",
    "    FallNet: CNN-LmU Ensemble for Pre-Impact Fall Detection\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_shape=(200, 6), n_classes=6):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_shape: (timesteps, features) = (200, 6)\n",
    "            n_classes: Number of output classes (6)\n",
    "        \"\"\"\n",
    "        self.input_shape = input_shape\n",
    "        self.n_classes = n_classes\n",
    "        self.model = None\n",
    "    \n",
    "    def build_lmu_branch(self, inputs):\n",
    "        \"\"\"LMU Branch\"\"\"\n",
    "        x = LMU(\n",
    "            memory_d=32,      # REDUCED from 64\n",
    "            order=32,          # REDUCED from 64\n",
    "            theta=200.0,\n",
    "            hidden_cell=None,\n",
    "            kernel_regularizer=keras.regularizers.L1L2(l1=5e-4, l2=5e-4),  # INCREASED from 1e-4\n",
    "            recurrent_regularizer=keras.regularizers.L1L2(l1=5e-4, l2=5e-4),\n",
    "            dropout=0.3,       # NEW\n",
    "            recurrent_dropout=0.2,  # NEW\n",
    "            name='lmu'\n",
    "            )(inputs)\n",
    "    \n",
    "        \n",
    "        # Dense layers with stronger regularization\n",
    "        x = layers.Dense(\n",
    "            128,\n",
    "            activation='relu',\n",
    "            kernel_regularizer=keras.regularizers.L1L2(l1=5e-4, l2=5e-4),\n",
    "            name='lmu_dense1'\n",
    "            )(x)\n",
    "        x = layers.Dropout(0.4, name='lmu_dropout1')(x)  # INCREASED\n",
    "    \n",
    "        x = layers.Dense(\n",
    "            64,\n",
    "            activation='relu',\n",
    "            kernel_regularizer=keras.regularizers.L1L2(l1=5e-4, l2=5e-4),\n",
    "            name='lmu_dense2'\n",
    "            )(x)\n",
    "        x = layers.Dropout(0.3, name='lmu_dropout2')(x)  # INCREASED\n",
    "    \n",
    "        x = layers.Dense(\n",
    "            32,\n",
    "            activation='relu',\n",
    "            kernel_regularizer=keras.regularizers.L1L2(l1=5e-4, l2=5e-4),\n",
    "            name='lmu_dense3'\n",
    "            )(x)\n",
    "        x = layers.Dropout(0.2, name='lmu_dropout3')(x)\n",
    "    \n",
    "        lmu_output = layers.Dense(\n",
    "            self.n_classes,\n",
    "            activation='softmax',\n",
    "            name='lmu_output'\n",
    "            )(x)\n",
    "    \n",
    "        return lmu_output\n",
    "        \n",
    "\n",
    "    def build_lstm_branch(self, inputs):\n",
    "        \"\"\"LSTM Branch\"\"\"\n",
    "        x = layers.LSTM(\n",
    "            units=256,\n",
    "            activation='tanh',\n",
    "            return_sequences=False,\n",
    "            name='lstm_layer'\n",
    "        )(inputs)\n",
    "        \n",
    "        x = layers.Dense(128, activation='relu', name='lstm_dense1')(x)\n",
    "        x = layers.Dropout(0.2, name='lstm_dropout1')(x)\n",
    "        \n",
    "        x = layers.Dense(64, activation='relu', name='lstm_dense2')(x)\n",
    "        x = layers.Dropout(0.2, name='lstm_dropout2')(x)\n",
    "        \n",
    "        x = layers.Dense(32, activation='relu', name='lstm_dense3')(x)\n",
    "        x = layers.Dropout(0.2, name='lstm_dropout3')(x)\n",
    "        \n",
    "        lstm_output = layers.Dense(\n",
    "            self.n_classes, \n",
    "            activation='softmax',\n",
    "            name='lstm_output'\n",
    "        )(x)\n",
    "        \n",
    "        return lstm_output\n",
    "    \n",
    "    def build_cnn_branch(self, inputs):\n",
    "        \"\"\"CNN Branch\"\"\"\n",
    "        x = layers.Conv1D(\n",
    "            filters=128,\n",
    "            kernel_size=3,\n",
    "            activation='relu',\n",
    "            padding='same',\n",
    "            name='conv1d_layer'\n",
    "        )(inputs)\n",
    "        \n",
    "        x = layers.MaxPooling1D(pool_size=2, name='maxpool_layer')(x)\n",
    "        x = layers.Flatten(name='flatten_layer')(x)\n",
    "        \n",
    "        x = layers.Dense(1024, activation='relu', name='cnn_dense1')(x)\n",
    "        x = layers.Dropout(0.2, name='cnn_dropout1')(x)\n",
    "        \n",
    "        x = layers.Dense(512, activation='relu', name='cnn_dense2')(x)\n",
    "        x = layers.Dropout(0.2, name='cnn_dropout2')(x)\n",
    "        \n",
    "        cnn_output = layers.Dense(\n",
    "            self.n_classes,\n",
    "            activation='softmax',\n",
    "            name='cnn_output'\n",
    "        )(x)\n",
    "        \n",
    "        return cnn_output\n",
    "\n",
    "    def build_cnn_only(self):\n",
    "        \"\"\"Build CNN-only model (no temporal component)\"\"\"\n",
    "        inputs = layers.Input(shape=self.input_shape, name='input')\n",
    "        cnn_output = self.build_cnn_branch(inputs)\n",
    "        \n",
    "        self.model = models.Model(\n",
    "            inputs=inputs,\n",
    "            outputs=cnn_output,\n",
    "            name='FallNet_CNN_Only'\n",
    "        )\n",
    "        return self.model\n",
    "    \n",
    "    def build_lstm_only(self):\n",
    "        \"\"\"Build LSTM-only model (temporal encoding via gates)\"\"\"\n",
    "        inputs = layers.Input(shape=self.input_shape, name='input')\n",
    "        lstm_output = self.build_lstm_branch(inputs)\n",
    "        \n",
    "        self.model = models.Model(\n",
    "            inputs=inputs,\n",
    "            outputs=lstm_output,\n",
    "            name='FallNet_LSTM_Only'\n",
    "        )\n",
    "        return self.model\n",
    "    \n",
    "    def build_lmu_only(self):\n",
    "        \"\"\"Build LMU-only model (temporal encoding via Legendre polynomials)\"\"\"\n",
    "        inputs = layers.Input(shape=self.input_shape, name='input')\n",
    "        lmu_output = self.build_lmu_branch(inputs)\n",
    "        \n",
    "        self.model = models.Model(\n",
    "            inputs=inputs,\n",
    "            outputs=lmu_output,\n",
    "            name='FallNet_LMU_Only'\n",
    "        )\n",
    "        return self.model\n",
    "    \n",
    "    def build_ensemble(self):\n",
    "        \"\"\"Build the complete ensemble model\"\"\"\n",
    "        inputs = layers.Input(shape=self.input_shape, name='input')\n",
    "        \n",
    "        lmu_output = self.build_lstm_branch(inputs)\n",
    "        cnn_output = self.build_cnn_branch(inputs)\n",
    "        \n",
    "        ensemble_output = layers.Average(name='ensemble_average')([lmu_output, cnn_output])\n",
    "        \n",
    "        self.model = models.Model(\n",
    "            inputs=inputs,\n",
    "            outputs=ensemble_output,\n",
    "            name='FallNet_CNN_LSTM'\n",
    "        )\n",
    "        \n",
    "        return self.model\n",
    "    \n",
    "    def compile_model(self, learning_rate=None):\n",
    "        \"\"\"Compile model\"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Model not built yet. Call build_ensemble() first.\")\n",
    "        \n",
    "        optimizer = keras.optimizers.Adam(learning_rate=learning_rate) if learning_rate else keras.optimizers.Adam()\n",
    "        \n",
    "        self.model.compile(\n",
    "            optimizer=keras.optimizers.Adam(learning_rate=1e-5),  # 100x smaller\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=[\n",
    "                'accuracy', \n",
    "                keras.metrics.Precision(name='precision'),\n",
    "                keras.metrics.Recall(name='recall')fallnet_fold\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        return self.model\n",
    "\n",
    "print(\"‚úÖ FallNet class defined\")\n",
    "\n",
    "# %% [markdown]\n",
    "## 2. Build and Display Model\n",
    "\n",
    "# %%\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BUILDING FALLNET MODEL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create instance with 6 classes\n",
    "fallnet = FallNet(input_shape=(200, 6), n_classes=6)\n",
    "\n",
    "# Build ensemble\n",
    "model = fallnet.build_ensemble()\n",
    "\n",
    "# Compile\n",
    "model = fallnet.compile_model()\n",
    "\n",
    "# Display architecture\n",
    "print(\"\\n\")\n",
    "model.summary()\n",
    "\n",
    "# Count parameters\n",
    "def count_parameters(model):\n",
    "    trainable = np.sum([np.prod(v.shape) for v in model.trainable_weights])\n",
    "    non_trainable = np.sum([np.prod(v.shape) for v in model.non_trainable_weights])\n",
    "    return trainable, non_trainable\n",
    "\n",
    "trainable, non_trainable = count_parameters(model)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL PARAMETERS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Trainable:     {trainable:,}\")\n",
    "print(f\"Non-trainable: {non_trainable:,}\")\n",
    "print(f\"Total:         {trainable + non_trainable:,}\")\n",
    "\n",
    "# %% [markdown]\n",
    "## 3. Training Configuration\n",
    "\n",
    "# %%\n",
    "BATCH_SIZE = 2\n",
    "EPOCHS = 50\n",
    "K_FOLDS = 5\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAINING CONFIGURATION\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "print(f\"Max epochs: {EPOCHS}\")\n",
    "print(f\"K-Folds:    {K_FOLDS}\")\n",
    "print(f\"Using data from previous cell (6 classes, {len(y_labels):,} samples)\")\n",
    "\n",
    "# %% [markdown]\n",
    "## 4. Verify Data Before Training\n",
    "\n",
    "# %%\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PRE-TRAINING VERIFICATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"‚úÖ Data shapes:\")\n",
    "print(f\"   X_data:        {X_data.shape}\")\n",
    "print(f\"   y_labels:      {y_labels.shape}\")\n",
    "print(f\"   y_categorical: {y_categorical.shape}\")\n",
    "print(f\"\\n‚úÖ Classes: {len(np.unique(y_labels))} (should be 6)\")\n",
    "print(f\"‚úÖ Label range: {y_labels.min()}-{y_labels.max()} (should be 0-5)\")\n",
    "print(f\"‚úÖ Model output: {model.output_shape[-1]} (should be 6)\")\n",
    "\n",
    "assert X_data.shape[0] == y_labels.shape[0] == y_categorical.shape[0], \"Shape mismatch!\"\n",
    "assert len(np.unique(y_labels)) == 6, \"Should have 6 classes!\"\n",
    "assert y_labels.max() == 5, \"Max label should be 5!\"\n",
    "assert model.output_shape[-1] == 6, \"Model should output 6 classes!\"\n",
    "\n",
    "print(\"\\n‚úÖ All checks passed - ready to train!\")\n",
    "\n",
    "# %% [markdown]\n",
    "## 5. K-Fold Cross-Validation Training\n",
    "\n",
    "# %%\n",
    "skf = StratifiedKFold(n_splits=K_FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "fold_results = []\n",
    "fold_histories = []\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STARTING K-FOLD CROSS-VALIDATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_data, y_labels), 1):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"FOLD {fold}/{K_FOLDS}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_val = X_data[train_idx], X_data[val_idx]\n",
    "    y_train, y_val = y_categorical[train_idx], y_categorical[val_idx]\n",
    "    \n",
    "    print(f\"Train: {X_train.shape[0]:,} samples | Val: {X_val.shape[0]:,} samples\")\n",
    "    \n",
    "    # Build fresh model for this fold\n",
    "    fallnet_fold = FallNet(input_shape=(200, 6), n_classes=6)\n",
    "    model_fold = fallnet_fold.build_ensemble()\n",
    "    model_fold = fallnet_fold.compile_model()\n",
    "    \n",
    "    # Define callbacks for THIS fold\n",
    "    fold_callbacks = [\n",
    "        EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=20,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=10,\n",
    "            min_lr=1e-7,\n",
    "            verbose=1\n",
    "        ),\n",
    "        ModelCheckpoint(\n",
    "            filepath=str(output_dir / f'fallnet_lstm_fold_{fold}.keras'),\n",
    "            monitor='val_accuracy',\n",
    "            save_best_only=True,\n",
    "            mode='max',\n",
    "            verbose=1\n",
    "        )\n",
    "    ]\n",
    "    # %% [markdown]\n",
    "## 5.5 Calculate Class Weights\n",
    "\n",
    "# %%\n",
    "    from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"CALCULATING CLASS WEIGHTS\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "# Calculate balanced weights\n",
    "    class_weights_array = compute_class_weight(\n",
    "        class_weight='balanced',\n",
    "        classes=np.unique(y_labels),\n",
    "        y=y_labels\n",
    "    )\n",
    "\n",
    "# Cap at 3x to prevent training instability\n",
    "    MAX_WEIGHT = 3.0\n",
    "    class_weights_array_capped = np.clip(class_weights_array, None, MAX_WEIGHT)\n",
    "    class_weights = dict(enumerate(class_weights_array_capped))\n",
    "\n",
    "    print(\"\\nClass Distribution:\")\n",
    "    from collections import Counter\n",
    "    counts = Counter(y_labels)\n",
    "    for cls_idx in range(6):\n",
    "        count = counts[cls_idx]\n",
    "        pct = count / len(y_labels) * 100\n",
    "        weight = class_weights[cls_idx]\n",
    "        print(f\"  {reverse_label_map[cls_idx]:<30s}: {count:>5d} ({pct:>5.2f}%) ‚Üí weight: {weight:.2f}x\")\n",
    "\n",
    "    print(f\"\\n‚úÖ Weight range: {min(class_weights.values()):.2f}x to {max(class_weights.values()):.2f}x\")\n",
    "    print(f\"‚úÖ Max/Min ratio: {max(class_weights.values())/min(class_weights.values()):.2f}x (was 4.0x without capping)\")\n",
    "    # Train WITHOUT class weights\n",
    "    print(f\"\\nTraining fold {fold}...\")\n",
    "    history = model_fold.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epochs=EPOCHS,\n",
    "        class_weight=class_weights,  # ‚Üê ADD THIS LINE!\n",
    "        callbacks=fold_callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Evaluate\n",
    "    val_loss, val_acc, val_precision, val_recall = model_fold.evaluate(X_val, y_val, batch_size=2, verbose=0)\n",
    "    val_f1 = 2 * (val_precision * val_recall) / (val_precision + val_recall) if (val_precision + val_recall) > 0 else 0\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Fold {fold} Results:\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"Loss:      {val_loss:.4f}\")\n",
    "    print(f\"Accuracy:  {val_acc:.4f}\")\n",
    "    print(f\"Precision: {val_precision:.4f}\")\n",
    "    print(f\"Recall:    {val_recall:.4f}\")\n",
    "    print(f\"F1-Score:  {val_f1:.4f}\")\n",
    "    \n",
    "    # Store results\n",
    "    fold_results.append({\n",
    "        'fold': fold,\n",
    "        'val_loss': val_loss,\n",
    "        'val_accuracy': val_acc,\n",
    "        'val_precision': val_precision,\n",
    "        'val_recall': val_recall,\n",
    "        'val_f1': val_f1\n",
    "    })\n",
    "    \n",
    "    fold_histories.append(history.history)\n",
    "    \n",
    "    print(f\"‚úÖ Model saved: fallnet_lstm_fold_{fold}.keras\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"K-FOLD CROSS-VALIDATION COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# %% [markdown]\n",
    "## 6. Aggregate Results\n",
    "\n",
    "# %%\n",
    "results_df = pd.DataFrame(fold_results)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESULTS ACROSS ALL FOLDS\")\n",
    "print(\"=\"*80)\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AVERAGE PERFORMANCE ¬± STD\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "mean_results = results_df.mean(numeric_only=True)\n",
    "std_results = results_df.std(numeric_only=True)\n",
    "\n",
    "metrics_table = []\n",
    "for metric in ['val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_f1']:\n",
    "    metrics_table.append({\n",
    "        'Metric': metric,\n",
    "        'Mean': f\"{mean_results[metric]:.4f}\",\n",
    "        'Std': f\"¬±{std_results[metric]:.4f}\"\n",
    "    })\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics_table)\n",
    "print(metrics_df.to_string(index=False))\n",
    "\n",
    "# %% [markdown]\n",
    "## 7. Visualize Training History\n",
    "\n",
    "# %%\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "metrics = [\n",
    "    ('loss', 'Loss'),\n",
    "    ('accuracy', 'Accuracy'),\n",
    "    ('precision', 'Precision'),\n",
    "    ('recall', 'Recall')\n",
    "]\n",
    "\n",
    "for idx, (metric, title) in enumerate(metrics):\n",
    "    ax = axes[idx // 2, idx % 2]\n",
    "    \n",
    "    for fold, history in enumerate(fold_histories, 1):\n",
    "        epochs = range(1, len(history[metric]) + 1)\n",
    "        ax.plot(epochs, history[metric], label=f'Fold {fold} Train', alpha=0.5, linewidth=1)\n",
    "        ax.plot(epochs, history[f'val_{metric}'], label=f'Fold {fold} Val', \n",
    "                linestyle='--', alpha=0.7, linewidth=1.5)\n",
    "    \n",
    "    ax.set_title(f'{title} Across All Folds', fontsize=13, fontweight='bold')\n",
    "    ax.set_xlabel('Epoch', fontsize=11)\n",
    "    ax.set_ylabel(title, fontsize=11)\n",
    "    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=7)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('FallNet Training History - 5-Fold Cross-Validation', \n",
    "             fontsize=15, fontweight='bold', y=0.995)\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / 'training_history.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"‚úÖ Training history saved to {output_dir / 'training_history.png'}\")\n",
    "\n",
    "# %% [markdown]\n",
    "## 8. Detailed Evaluation on Best Fold\n",
    "\n",
    "# %%\n",
    "best_fold = int(results_df.loc[results_df['val_f1'].idxmax(), 'fold'])\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"DETAILED EVALUATION - BEST FOLD #{best_fold}\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Best fold F1-Score: {results_df.loc[results_df['fold']==best_fold, 'val_f1'].values[0]:.4f}\")\n",
    "\n",
    "# Load best model\n",
    "best_model = keras.models.load_model(output_dir / f'fallnet_fold_lstm_{best_fold}.keras')\n",
    "\n",
    "# Get predictions on ALL data\n",
    "y_pred_probs = best_model.predict(X_data, verbose=0)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "# Classification report\n",
    "class_names = [reverse_label_map[i] for i in range(6)]\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CLASSIFICATION REPORT (Best Fold on All Data)\")\n",
    "print(\"=\"*80)\n",
    "print(classification_report(y_labels, y_pred, target_names=class_names, digits=4))\n",
    "\n",
    "# %% [markdown]\n",
    "## 9. Per-Class Detailed Metrics\n",
    "\n",
    "# %%\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PER-CLASS DETAILED METRICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n{'Class':<40s} {'Precision':<12s} {'Recall':<12s} {'F1-Score':<12s} {'Support'}\")\n",
    "print(\"-\"*90)\n",
    "\n",
    "for cls_idx in range(6):\n",
    "    precision = precision_score(y_labels == cls_idx, y_pred == cls_idx, zero_division=0)\n",
    "    recall = recall_score(y_labels == cls_idx, y_pred == cls_idx, zero_division=0)\n",
    "    f1 = f1_score(y_labels == cls_idx, y_pred == cls_idx, zero_division=0)\n",
    "    support = np.sum(y_labels == cls_idx)\n",
    "    \n",
    "    print(f\"{reverse_label_map[cls_idx]:<40s} {precision:<12.4f} {recall:<12.4f} {f1:<12.4f} {support}\")\n",
    "\n",
    "# %% [markdown]\n",
    "## 10. Confusion Matrix\n",
    "\n",
    "# %%\n",
    "cm = confusion_matrix(y_labels, y_pred)\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(\n",
    "    cm, \n",
    "    annot=True, \n",
    "    fmt='d', \n",
    "    cmap='Blues',\n",
    "    xticklabels=class_names,\n",
    "    yticklabels=class_names,\n",
    "    cbar_kws={'label': 'Count'}\n",
    ")\n",
    "plt.title('Confusion Matrix - Best Fold (6 Classes)', fontsize=15, fontweight='bold', pad=20)\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right', fontsize=10)\n",
    "plt.yticks(rotation=0, fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / 'confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"‚úÖ Confusion matrix saved to {output_dir / 'confusion_matrix.png'}\")\n",
    "\n",
    "# %% [markdown]\n",
    "## 11. Final Summary\n",
    "\n",
    "# %%\n",
    "# Get Fall_Initiation metrics\n",
    "fall_init_idx = label_map[\"Fall_Initiation\"]\n",
    "fall_init_precision = precision_score(y_labels == fall_init_idx, y_pred == fall_init_idx)\n",
    "fall_init_recall = recall_score(y_labels == fall_init_idx, y_pred == fall_init_idx)\n",
    "fall_init_f1 = f1_score(y_labels == fall_init_idx, y_pred == fall_init_idx)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAINING COMPLETE - FINAL SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "summary = f\"\"\"\n",
    "‚úÖ Successfully trained FallNet with 5-fold cross-validation\n",
    "\n",
    "Configuration:\n",
    "  - Model: CNN-LSTM Ensemble (6 classes)\n",
    "  - Total samples: {len(y_labels):,}\n",
    "  - Training samples per fold: ~{len(y_labels)*0.8//K_FOLDS:,.0f}\n",
    "  - Validation samples per fold: ~{len(y_labels)*0.2//K_FOLDS:,.0f}\n",
    "\n",
    "Average Performance (5-fold CV):\n",
    "  - Accuracy:  {mean_results['val_accuracy']:.4f} ¬± {std_results['val_accuracy']:.4f}\n",
    "  - Precision: {mean_results['val_precision']:.4f} ¬± {std_results['val_precision']:.4f}\n",
    "  - Recall:    {mean_results['val_recall']:.4f} ¬± {std_results['val_recall']:.4f}\n",
    "  - F1-Score:  {mean_results['val_f1']:.4f} ¬± {std_results['val_f1']:.4f}\n",
    "\n",
    "Fall_Initiation Performance (Critical Class):\n",
    "  - Recall (Sensitivity): {fall_init_recall:.4f}\n",
    "  - F1-Score:             {fall_init_f1:.4f}\n",
    "\n",
    "Saved Files:\n",
    "  - Training history:    {output_dir / 'training_history.png'}\n",
    "  - Confusion matrix:    {output_dir / 'confusion_matrix.png'}\n",
    "  - Best model:          {output_dir / f'fallnet_fold_{best_fold}.keras'}\n",
    "  - All fold models:     {output_dir / 'fallnet_fold_*.keras'}\n",
    "\"\"\"\n",
    "\n",
    "print(summary)\n",
    "\n",
    "with open(output_dir / 'training_summary.txt', 'w') as f:\n",
    "    f.write(summary)\n",
    "\n",
    "print(f\"‚úÖ Summary saved to {output_dir / 'training_summary.txt'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can LMU overfit a tiny dataset?\n",
    "X_tiny = X_data[:100]\n",
    "y_tiny = y_categorical[:100]\n",
    "\n",
    "# Simple LMU-only model\n",
    "model_test = keras.Sequential([\n",
    "    LMU(memory_d=64, order=64, theta=200.0, hidden_cell=None, input_shape=(200, 6)),\n",
    "    layers.Dense(6, activation='softmax')\n",
    "])\n",
    "\n",
    "model_test.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model_test.fit(X_tiny, y_tiny, epochs=100, batch_size=10, verbose=1)\n",
    "\n",
    "print(f\"\\nFinal accuracy: {history.history['accuracy'][-1]:.4f}\")\n",
    "print(f\"Should be >0.90 if LMU works properly\")\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Built with CUDA:\", tf.test.is_built_with_cuda())\n",
    "print(\"GPUs available:\", tf.config.list_physical_devices('GPU'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can LMU overfit a tiny dataset?\n",
    "X_tiny = X_data[:100]\n",
    "y_tiny = y_categorical[:100]\n",
    "\n",
    "# Simple LMU-only model\n",
    "model_test = keras.Sequential([\n",
    "    LMU(memory_d=64, order=64, theta=200.0, hidden_cell=None, input_shape=(200, 6)),\n",
    "    layers.Dense(6, activation='softmax')\n",
    "])\n",
    "\n",
    "model_test.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model_test.fit(X_tiny, y_tiny, epochs=100, batch_size=10, verbose=1)\n",
    "\n",
    "# Should reach >95% accuracy if LMU works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import gc\n",
    "\n",
    "# Clear session ONCE at start\n",
    "keras.backend.clear_session()\n",
    "gc.collect()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAINING CNN-ONLY MODEL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "BATCH_SIZE = 1  # ‚Üê Reduce to 1 for safety\n",
    "EPOCHS = 50\n",
    "K_FOLDS = 5\n",
    "MODEL_NAME = \"cnn_only\"\n",
    "\n",
    "skf = StratifiedKFold(n_splits=K_FOLDS, shuffle=True, random_state=42)\n",
    "fold_results = []\n",
    "fold_histories = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_data, y_labels), 1):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"FOLD {fold}/{K_FOLDS} - CNN-ONLY\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # ‚≠ê CLEAR MEMORY AT START OF EACH FOLD\n",
    "    keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_val = X_data[train_idx], X_data[val_idx]\n",
    "    y_train, y_val = y_categorical[train_idx], y_categorical[val_idx]\n",
    "    \n",
    "    print(f\"Train: {X_train.shape[0]:,} samples | Val: {X_val.shape[0]:,} samples\")\n",
    "    \n",
    "    # Build CNN-only model\n",
    "    fallnet_fold = FallNet(input_shape=(200, 6), n_classes=6)\n",
    "    model_fold = fallnet_fold.build_cnn_only()\n",
    "    model_fold = fallnet_fold.compile_model()\n",
    "    \n",
    "    # Callbacks\n",
    "    fold_callbacks = [\n",
    "        EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=20,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=10,\n",
    "            min_lr=1e-7,\n",
    "            verbose=1\n",
    "        ),\n",
    "        ModelCheckpoint(\n",
    "            filepath=str(output_dir / f'{MODEL_NAME}_fold_{fold}.keras'),\n",
    "            monitor='val_accuracy',\n",
    "            save_best_only=True,\n",
    "            mode='max',\n",
    "            verbose=1\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # Class weights\n",
    "    from sklearn.utils.class_weight import compute_class_weight\n",
    "    class_weights_array = compute_class_weight(\n",
    "        class_weight='balanced',\n",
    "        classes=np.unique(y_labels),\n",
    "        y=y_labels\n",
    "    )\n",
    "    MAX_WEIGHT = 3.0\n",
    "    class_weights_array_capped = np.clip(class_weights_array, None, MAX_WEIGHT)\n",
    "    class_weights = dict(enumerate(class_weights_array_capped))\n",
    "    \n",
    "    # Train\n",
    "    print(f\"\\nTraining fold {fold}...\")\n",
    "    history = model_fold.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        batch_size=BATCH_SIZE,  # Now 1\n",
    "        epochs=EPOCHS,\n",
    "        class_weight=class_weights,\n",
    "        callbacks=fold_callbacks,\n",
    "        verbose=2  # Less verbose output\n",
    "    )\n",
    "    \n",
    "    # Evaluate\n",
    "    val_loss, val_acc, val_precision, val_recall = model_fold.evaluate(\n",
    "        X_val, y_val, \n",
    "        batch_size=1,  # Match training batch size\n",
    "        verbose=0\n",
    "    )\n",
    "    val_f1 = 2 * (val_precision * val_recall) / (val_precision + val_recall) if (val_precision + val_recall) > 0 else 0\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Fold {fold} Results:\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"Loss:      {val_loss:.4f}\")\n",
    "    print(f\"Accuracy:  {val_acc:.4f}\")\n",
    "    print(f\"Precision: {val_precision:.4f}\")\n",
    "    print(f\"Recall:    {val_recall:.4f}\")\n",
    "    print(f\"F1-Score:  {val_f1:.4f}\")\n",
    "    \n",
    "    fold_results.append({\n",
    "        'fold': fold,\n",
    "        'val_loss': val_loss,\n",
    "        'val_accuracy': val_acc,\n",
    "        'val_precision': val_precision,\n",
    "        'val_recall': val_recall,\n",
    "        'val_f1': val_f1\n",
    "    })\n",
    "    \n",
    "    fold_histories.append(history.history)\n",
    "    \n",
    "    # ‚≠ê CLEAR MEMORY AT END OF EACH FOLD\n",
    "    del model_fold, fallnet_fold\n",
    "    del X_train, X_val, y_train, y_val, history\n",
    "    keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "    \n",
    "    print(f\"\\n‚úì Fold {fold} complete, memory cleared\")\n",
    "\n",
    "# Results summary\n",
    "results_df = pd.DataFrame(fold_results)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CNN-ONLY RESULTS ACROSS ALL FOLDS\")\n",
    "print(\"=\"*80)\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "mean_results = results_df.mean(numeric_only=True)\n",
    "std_results = results_df.std(numeric_only=True)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CNN-ONLY AVERAGE PERFORMANCE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Accuracy:  {mean_results['val_accuracy']:.4f} ¬± {std_results['val_accuracy']:.4f}\")\n",
    "print(f\"Precision: {mean_results['val_precision']:.4f} ¬± {std_results['val_precision']:.4f}\")\n",
    "print(f\"Recall:    {mean_results['val_recall']:.4f} ¬± {std_results['val_recall']:.4f}\")\n",
    "print(f\"F1-Score:  {mean_results['val_f1']:.4f} ¬± {std_results['val_f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## Save CNN-Only Summary\n",
    "\n",
    "# %%\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# CNN-only results\n",
    "cnn_only_summary = {\n",
    "    \"model_type\": \"CNN-Only\",\n",
    "    \"architecture\": {\n",
    "        \"input_shape\": \"(200, 6)\",\n",
    "        \"conv1d\": \"128 filters, kernel=3\",\n",
    "        \"maxpool\": \"pool_size=2\",\n",
    "        \"dense_layers\": [1024, 512],\n",
    "        \"dropout\": 0.2,\n",
    "        \"output\": \"6 classes (softmax)\"\n",
    "    },\n",
    "    \"training_config\": {\n",
    "        \"batch_size\": 2,\n",
    "        \"learning_rate\": 1e-5,\n",
    "        \"epochs\": 50,\n",
    "        \"k_folds\": 5,\n",
    "        \"class_weights\": \"balanced (capped at 3.0x)\"\n",
    "    },\n",
    "    \"results\": {\n",
    "        \"fold_1\": {\"accuracy\": 0.8921, \"precision\": 0.9084, \"recall\": 0.8799, \"f1\": 0.8939},\n",
    "        \"fold_2\": {\"accuracy\": 0.8901, \"precision\": 0.9041, \"recall\": 0.8763, \"f1\": 0.8900},\n",
    "        \"fold_3\": {\"accuracy\": 0.8960, \"precision\": 0.9059, \"recall\": 0.8834, \"f1\": 0.8945},\n",
    "        \"fold_4\": {\"accuracy\": 0.8805, \"precision\": 0.8939, \"recall\": 0.8640, \"f1\": 0.8787},\n",
    "        \"fold_5\": {\"accuracy\": 0.8825, \"precision\": 0.9023, \"recall\": 0.8667, \"f1\": 0.8841}\n",
    "    },\n",
    "    \"average_performance\": {\n",
    "        \"accuracy\": 0.8882,\n",
    "        \"accuracy_std\": 0.0066,\n",
    "        \"precision\": 0.9029,\n",
    "        \"precision_std\": 0.0055,\n",
    "        \"recall\": 0.8741,\n",
    "        \"recall_std\": 0.0084,\n",
    "        \"f1\": 0.8883,\n",
    "        \"f1_std\": 0.0068\n",
    "    },\n",
    "    \"comparison_to_ensemble\": {\n",
    "        \"cnn_lmu_ensemble\": 0.951,\n",
    "        \"cnn_only\": 0.8882,\n",
    "        \"improvement_from_lmu\": 0.063,\n",
    "        \"interpretation\": \"LMU adds 6.3% accuracy by providing temporal encoding\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save to JSON\n",
    "with open(output_dir / 'cnn_only_summary.json', 'w') as f:\n",
    "    json.dump(cnn_only_summary, f, indent=2)\n",
    "\n",
    "# Save to text\n",
    "summary_text = f\"\"\"\n",
    "================================================================================\n",
    "CNN-ONLY MODEL SUMMARY\n",
    "================================================================================\n",
    "\n",
    "Model Architecture:\n",
    "  - Input: (200, 6) - 200 timesteps √ó 6 IMU features\n",
    "  - Conv1D: 128 filters, kernel_size=3, activation=relu\n",
    "  - MaxPooling1D: pool_size=2\n",
    "  - Flatten\n",
    "  - Dense(1024, relu) + Dropout(0.2)\n",
    "  - Dense(512, relu) + Dropout(0.2)\n",
    "  - Dense(6, softmax)\n",
    "\n",
    "Training Configuration:\n",
    "  - Batch size: 2\n",
    "  - Learning rate: 1e-5\n",
    "  - Epochs: 50 (with early stopping)\n",
    "  - K-Folds: 5\n",
    "  - Class weights: Balanced (capped at 3.0x)\n",
    "\n",
    "Results (5-Fold Cross-Validation):\n",
    "  Fold 1: Accuracy = 89.21%, F1 = 89.39%\n",
    "  Fold 2: Accuracy = 89.01%, F1 = 89.00%\n",
    "  Fold 3: Accuracy = 89.60%, F1 = 89.45%\n",
    "  Fold 4: Accuracy = 88.05%, F1 = 87.87%\n",
    "  Fold 5: Accuracy = 88.25%, F1 = 88.41%\n",
    "\n",
    "Average Performance:\n",
    "  Accuracy:  88.82% ¬± 0.66%\n",
    "  Precision: 90.29% ¬± 0.55%\n",
    "  Recall:    87.41% ¬± 0.84%\n",
    "  F1-Score:  88.83% ¬± 0.68%\n",
    "\n",
    "Comparison to Ensemble:\n",
    "  CNN-LMU Ensemble: 95.1%\n",
    "  CNN-Only:         88.8%\n",
    "  Improvement:      +6.3% from adding LMU\n",
    "\n",
    "Interpretation:\n",
    "  The CNN alone achieves 88.8% by capturing spatial correlations between\n",
    "  accelerometer/gyroscope channels. Adding the LMU branch provides temporal\n",
    "  encoding (sequence dynamics over 200 timesteps), boosting performance to\n",
    "  95.1%. This 6.3% improvement demonstrates that temporal information is\n",
    "  critical for fall detection.\n",
    "\n",
    "Model Files:\n",
    "  - cnn_only_fold_1.keras\n",
    "  - cnn_only_fold_2.keras\n",
    "  - cnn_only_fold_3.keras\n",
    "  - cnn_only_fold_4.keras\n",
    "  - cnn_only_fold_5.keras\n",
    "\n",
    "Best Fold: Fold 3 (89.60% accuracy)\n",
    "================================================================================\n",
    "\"\"\"\n",
    "\n",
    "with open(output_dir / 'cnn_only_summary.txt', 'w') as f:\n",
    "    f.write(summary_text)\n",
    "\n",
    "print(\"‚úÖ CNN-only summary saved!\")\n",
    "print(f\"   JSON: {output_dir / 'cnn_only_summary.json'}\")\n",
    "print(f\"   Text: {output_dir / 'cnn_only_summary.txt'}\")\n",
    "print(f\"   Models: {output_dir / 'cnn_only_fold_*.keras'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## Branch Isolation Test 2: LSTM-Only\n",
    "\n",
    "# %%\n",
    "from tensorflow import keras\n",
    "import gc\n",
    "\n",
    "# Clear session\n",
    "keras.backend.clear_session()\n",
    "gc.collect()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAINING LSTM-ONLY MODEL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "BATCH_SIZE = 2\n",
    "EPOCHS = 50\n",
    "K_FOLDS = 5\n",
    "MODEL_NAME = \"lstm_only\"\n",
    "\n",
    "skf = StratifiedKFold(n_splits=K_FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "fold_results = []\n",
    "fold_histories = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_data, y_labels), 1):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"FOLD {fold}/{K_FOLDS} - LSTM-ONLY\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_val = X_data[train_idx], X_data[val_idx]\n",
    "    y_train, y_val = y_categorical[train_idx], y_categorical[val_idx]\n",
    "    \n",
    "    print(f\"Train: {X_train.shape[0]:,} samples | Val: {X_val.shape[0]:,} samples\")\n",
    "    \n",
    "    # Build LSTM-only model\n",
    "    fallnet_fold = FallNet(input_shape=(200, 6), n_classes=6)\n",
    "    model_fold = fallnet_fold.build_lstm_only()  # ‚Üê LSTM-ONLY\n",
    "    model_fold = fallnet_fold.compile_model()\n",
    "    \n",
    "    # Callbacks\n",
    "    fold_callbacks = [\n",
    "        EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=20,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=10,\n",
    "            min_lr=1e-7,\n",
    "            verbose=1\n",
    "        ),\n",
    "        ModelCheckpoint(\n",
    "            filepath=str(output_dir / f'{MODEL_NAME}_fold_{fold}.keras'),\n",
    "            monitor='val_accuracy',\n",
    "            save_best_only=True,\n",
    "            mode='max',\n",
    "            verbose=1\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # Class weights\n",
    "    from sklearn.utils.class_weight import compute_class_weight\n",
    "    class_weights_array = compute_class_weight(\n",
    "        class_weight='balanced',\n",
    "        classes=np.unique(y_labels),\n",
    "        y=y_labels\n",
    "    )\n",
    "    MAX_WEIGHT = 3.0\n",
    "    class_weights_array_capped = np.clip(class_weights_array, None, MAX_WEIGHT)\n",
    "    class_weights = dict(enumerate(class_weights_array_capped))\n",
    "    \n",
    "    # Train\n",
    "    print(f\"\\nTraining fold {fold}...\")\n",
    "    history = model_fold.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epochs=EPOCHS,\n",
    "        class_weight=class_weights,\n",
    "        callbacks=fold_callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Evaluate\n",
    "    val_loss, val_acc, val_precision, val_recall = model_fold.evaluate(X_val, y_val, batch_size=2, verbose=0)\n",
    "    val_f1 = 2 * (val_precision * val_recall) / (val_precision + val_recall) if (val_precision + val_recall) > 0 else 0\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Fold {fold} Results:\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"Loss:      {val_loss:.4f}\")\n",
    "    print(f\"Accuracy:  {val_acc:.4f}\")\n",
    "    print(f\"Precision: {val_precision:.4f}\")\n",
    "    print(f\"Recall:    {val_recall:.4f}\")\n",
    "    print(f\"F1-Score:  {val_f1:.4f}\")\n",
    "    \n",
    "    fold_results.append({\n",
    "        'fold': fold,\n",
    "        'val_loss': val_loss,\n",
    "        'val_accuracy': val_acc,\n",
    "        'val_precision': val_precision,\n",
    "        'val_recall': val_recall,\n",
    "        'val_f1': val_f1\n",
    "    })\n",
    "    \n",
    "    fold_histories.append(history.history)\n",
    "    \n",
    "    # Clear memory\n",
    "    keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "\n",
    "# Results\n",
    "results_df = pd.DataFrame(fold_results)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"LSTM-ONLY RESULTS ACROSS ALL FOLDS\")\n",
    "print(\"=\"*80)\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "mean_results = results_df.mean(numeric_only=True)\n",
    "std_results = results_df.std(numeric_only=True)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"LSTM-ONLY AVERAGE PERFORMANCE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Accuracy:  {mean_results['val_accuracy']:.4f} ¬± {std_results['val_accuracy']:.4f}\")\n",
    "print(f\"Precision: {mean_results['val_precision']:.4f} ¬± {std_results['val_precision']:.4f}\")\n",
    "print(f\"Recall:    {mean_results['val_recall']:.4f} ¬± {std_results['val_recall']:.4f}\")\n",
    "print(f\"F1-Score:  {mean_results['val_f1']:.4f} ¬± {std_results['val_f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## Branch Isolation Test 3: LMU-Only\n",
    "\n",
    "# %%\n",
    "from tensorflow import keras\n",
    "import gc\n",
    "\n",
    "# Clear session\n",
    "keras.backend.clear_session()\n",
    "gc.collect()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAINING LMU-ONLY MODEL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "BATCH_SIZE = 2\n",
    "EPOCHS = 50\n",
    "K_FOLDS = 5\n",
    "MODEL_NAME = \"lmu_only\"\n",
    "\n",
    "skf = StratifiedKFold(n_splits=K_FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "fold_results = []\n",
    "fold_histories = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_data, y_labels), 1):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"FOLD {fold}/{K_FOLDS} - LMU-ONLY\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_val = X_data[train_idx], X_data[val_idx]\n",
    "    y_train, y_val = y_categorical[train_idx], y_categorical[val_idx]\n",
    "    \n",
    "    print(f\"Train: {X_train.shape[0]:,} samples | Val: {X_val.shape[0]:,} samples\")\n",
    "    \n",
    "    # Build LMU-only model\n",
    "    fallnet_fold = FallNet(input_shape=(200, 6), n_classes=6)\n",
    "    model_fold = fallnet_fold.build_lmu_only()  # ‚Üê LMU-ONLY\n",
    "    model_fold = fallnet_fold.compile_model()\n",
    "    \n",
    "    # Callbacks\n",
    "    fold_callbacks = [\n",
    "        EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=2,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=10,\n",
    "            min_lr=1e-7,\n",
    "            verbose=1\n",
    "        ),\n",
    "        ModelCheckpoint(\n",
    "            filepath=str(output_dir / f'{MODEL_NAME}_fold_{fold}.keras'),\n",
    "            monitor='val_accuracy',\n",
    "            save_best_only=True,\n",
    "            mode='max',\n",
    "            verbose=1\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # Class weights\n",
    "    from sklearn.utils.class_weight import compute_class_weight\n",
    "    class_weights_array = compute_class_weight(\n",
    "        class_weight='balanced',\n",
    "        classes=np.unique(y_labels),\n",
    "        y=y_labels\n",
    "    )\n",
    "    MAX_WEIGHT = 3.0\n",
    "    class_weights_array_capped = np.clip(class_weights_array, None, MAX_WEIGHT)\n",
    "    class_weights = dict(enumerate(class_weights_array_capped))\n",
    "    \n",
    "    # Train\n",
    "    print(f\"\\nTraining fold {fold}...\")\n",
    "    history = model_fold.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epochs=EPOCHS,\n",
    "        class_weight=class_weights,\n",
    "        callbacks=fold_callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Evaluate\n",
    "    val_loss, val_acc, val_precision, val_recall = model_fold.evaluate(X_val, y_val, batch_size=2, verbose=0)\n",
    "    val_f1 = 2 * (val_precision * val_recall) / (val_precision + val_recall) if (val_precision + val_recall) > 0 else 0\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Fold {fold} Results:\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"Loss:      {val_loss:.4f}\")\n",
    "    print(f\"Accuracy:  {val_acc:.4f}\")\n",
    "    print(f\"Precision: {val_precision:.4f}\")\n",
    "    print(f\"Recall:    {val_recall:.4f}\")\n",
    "    print(f\"F1-Score:  {val_f1:.4f}\")\n",
    "    \n",
    "    fold_results.append({\n",
    "        'fold': fold,\n",
    "        'val_loss': val_loss,\n",
    "        'val_accuracy': val_acc,\n",
    "        'val_precision': val_precision,\n",
    "        'val_recall': val_recall,\n",
    "        'val_f1': val_f1\n",
    "    })\n",
    "    \n",
    "    fold_histories.append(history.history)\n",
    "    \n",
    "    # Clear memory\n",
    "    keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "\n",
    "# Results\n",
    "results_df = pd.DataFrame(fold_results)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"LMU-ONLY RESULTS ACROSS ALL FOLDS\")\n",
    "print(\"=\"*80)\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "mean_results = results_df.mean(numeric_only=True)\n",
    "std_results = results_df.std(numeric_only=True)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"LMU-ONLY AVERAGE PERFORMANCE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Accuracy:  {mean_results['val_accuracy']:.4f} ¬± {std_results['val_accuracy']:.4f}\")\n",
    "print(f\"Precision: {mean_results['val_precision']:.4f} ¬± {std_results['val_precision']:.4f}\")\n",
    "print(f\"Recall:    {mean_results['val_recall']:.4f} ¬± {std_results['val_recall']:.4f}\")\n",
    "print(f\"F1-Score:  {mean_results['val_f1']:.4f} ¬± {std_results['val_f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Improved LMU-only training with stronger regularization to combat overfitting.\n",
    "\n",
    "Changes from original:\n",
    "1. Increased L1L2 regularization (1e-4 ‚Üí 5e-4)\n",
    "2. Added dropout to LMU layer (0.3)\n",
    "3. Added recurrent dropout (0.2)\n",
    "4. Earlier early stopping (patience 5 ‚Üí 3)\n",
    "5. Reduced LMU capacity (memory_d=32, order=32 instead of 64/64)\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "import json\n",
    "\n",
    "# Import KerasLMU\n",
    "import keras_lmu\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"LMU-ONLY TRAINING - IMPROVED REGULARIZATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "# Paths\n",
    "base_dir = Path.home() / 'repos/summerschool2023/projects/fall-detection/fall_detection_data'\n",
    "processed_dir = base_dir / 'processed'\n",
    "model_dir = base_dir / 'models'\n",
    "\n",
    "# Training hyperparameters\n",
    "BATCH_SIZE = 2\n",
    "LEARNING_RATE = 1e-5\n",
    "EPOCHS = 50\n",
    "K_FOLDS = 5\n",
    "\n",
    "# LMU parameters - REDUCED CAPACITY\n",
    "MEMORY_D = 32      # Was 64 - reduced to prevent overfitting\n",
    "ORDER = 32         # Was 64 - reduced to prevent overfitting\n",
    "THETA = 200.0\n",
    "\n",
    "# Regularization - INCREASED\n",
    "L1_REG = 5e-4      # Was 1e-4 - 5x stronger\n",
    "L2_REG = 5e-4      # Was 1e-4 - 5x stronger\n",
    "DROPOUT = 0.3      # NEW - dropout on LMU output\n",
    "RECURRENT_DROPOUT = 0.2  # NEW - recurrent dropout in LMU\n",
    "\n",
    "# Early stopping - MORE AGGRESSIVE\n",
    "EARLY_STOP_PATIENCE = 3  # Was 10 - stop much earlier\n",
    "REDUCE_LR_PATIENCE = 2   # Was 5 - reduce LR faster\n",
    "\n",
    "CLASS_NAMES = [\n",
    "    'Walking',\n",
    "    'Jogging',\n",
    "    'Walking_stairs_updown',\n",
    "    'Stumble_while_walking',\n",
    "    'Fall_Initiation',\n",
    "    'Impact_Aftermath'\n",
    "]\n",
    "\n",
    "# ============================================================================\n",
    "# LOAD DATA\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nLoading data...\")\n",
    "X = np.load(processed_dir / 'X_data_6class.npy')\n",
    "y = np.load(processed_dir / 'y_labels_6class.npy')\n",
    "\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "\n",
    "# Convert to categorical\n",
    "y_categorical = keras.utils.to_categorical(y, num_classes=6)\n",
    "\n",
    "# Calculate class weights\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "class_weights_array = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y),\n",
    "    y=y\n",
    ")\n",
    "class_weights = {i: weight for i, weight in enumerate(class_weights_array)}\n",
    "\n",
    "print(f\"\\nClass weights:\")\n",
    "for i, weight in class_weights.items():\n",
    "    print(f\"  Class {i} ({CLASS_NAMES[i]:30s}): {weight:.4f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# BUILD MODEL FUNCTION - WITH IMPROVED REGULARIZATION\n",
    "# ============================================================================\n",
    "\n",
    "def build_lmu_model(input_shape, num_classes):\n",
    "    \"\"\"Build LMU-only model with strong regularization\"\"\"\n",
    "    \n",
    "    inputs = keras.Input(shape=input_shape, name='input')\n",
    "    \n",
    "    # LMU layer with dropout and regularization\n",
    "    x = keras_lmu.LMU(\n",
    "        memory_d=MEMORY_D,\n",
    "        order=ORDER,\n",
    "        theta=THETA,\n",
    "        hidden_cell=None,\n",
    "        kernel_regularizer=keras.regularizers.L1L2(l1=L1_REG, l2=L2_REG),\n",
    "        recurrent_regularizer=keras.regularizers.L1L2(l1=L1_REG, l2=L2_REG),\n",
    "        dropout=DROPOUT,\n",
    "        recurrent_dropout=RECURRENT_DROPOUT,\n",
    "        name='lmu'\n",
    "    )(inputs)\n",
    "    \n",
    "    # Dense layers with strong regularization and dropout\n",
    "    x = keras.layers.Dense(\n",
    "        128,\n",
    "        activation='relu',\n",
    "        kernel_regularizer=keras.regularizers.L1L2(l1=L1_REG, l2=L2_REG),\n",
    "        name='dense1'\n",
    "    )(x)\n",
    "    x = keras.layers.Dropout(0.4, name='dropout1')(x)  # Increased from typical 0.3\n",
    "    \n",
    "    x = keras.layers.Dense(\n",
    "        64,\n",
    "        activation='relu',\n",
    "        kernel_regularizer=keras.regularizers.L1L2(l1=L1_REG, l2=L2_REG),\n",
    "        name='dense2'\n",
    "    )(x)\n",
    "    x = keras.layers.Dropout(0.3, name='dropout2')(x)\n",
    "    \n",
    "    x = keras.layers.Dense(\n",
    "        32,\n",
    "        activation='relu',\n",
    "        kernel_regularizer=keras.regularizers.L1L2(l1=L1_REG, l2=L2_REG),\n",
    "        name='dense3'\n",
    "    )(x)\n",
    "    x = keras.layers.Dropout(0.2, name='dropout3')(x)\n",
    "    \n",
    "    outputs = keras.layers.Dense(\n",
    "        num_classes,\n",
    "        activation='softmax',\n",
    "        name='output'\n",
    "    )(x)\n",
    "    \n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name='lmu_regularized')\n",
    "    \n",
    "    return model\n",
    "\n",
    "# ============================================================================\n",
    "# TRAINING LOOP\n",
    "# ============================================================================\n",
    "\n",
    "# Setup k-fold cross-validation\n",
    "skf = StratifiedKFold(n_splits=K_FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "results = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X, y), 1):\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"FOLD {fold}/{K_FOLDS}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_val = X[train_idx], X[val_idx]\n",
    "    y_train, y_val = y_categorical[train_idx], y_categorical[val_idx]\n",
    "    \n",
    "    print(f\"Train size: {len(X_train)}, Val size: {len(X_val)}\")\n",
    "    \n",
    "    # Build model\n",
    "    model = build_lmu_model(input_shape=(200, 6), num_classes=6)\n",
    "    \n",
    "    # Print model summary (only first fold)\n",
    "    if fold == 1:\n",
    "        print(\"\\nModel Architecture:\")\n",
    "        model.summary()\n",
    "        print(f\"\\nRegularization settings:\")\n",
    "        print(f\"  L1/L2: {L1_REG}/{L2_REG}\")\n",
    "        print(f\"  LMU dropout: {DROPOUT}\")\n",
    "        print(f\"  LMU recurrent dropout: {RECURRENT_DROPOUT}\")\n",
    "        print(f\"  Dense dropout: 0.4, 0.3, 0.2\")\n",
    "        print(f\"  LMU capacity: memory_d={MEMORY_D}, order={ORDER} (reduced from 64)\")\n",
    "    \n",
    "    # Compile\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy', keras.metrics.Precision(), keras.metrics.Recall()],\n",
    "        jit_compile=True\n",
    "    )\n",
    "    \n",
    "    # Callbacks - MORE AGGRESSIVE EARLY STOPPING\n",
    "    callbacks = [\n",
    "        keras.callbacks.EarlyStopping(\n",
    "            monitor='val_accuracy',\n",
    "            patience=EARLY_STOP_PATIENCE,  # Reduced to 3\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_accuracy',\n",
    "            factor=0.5,\n",
    "            patience=REDUCE_LR_PATIENCE,  # Reduced to 2\n",
    "            min_lr=1e-7,\n",
    "            verbose=1\n",
    "        ),\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "            filepath=model_dir / f'lmu_regularized_fold_{fold}.keras',\n",
    "            monitor='val_accuracy',\n",
    "            save_best_only=True,\n",
    "            verbose=1\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # Train\n",
    "    print(f\"\\nTraining fold {fold}...\")\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epochs=EPOCHS,\n",
    "        callbacks=callbacks,\n",
    "        class_weight=class_weights,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Evaluate\n",
    "    print(f\"\\nEvaluating fold {fold}...\")\n",
    "    val_loss, val_acc, val_prec, val_rec = model.evaluate(X_val, y_val, verbose=0)\n",
    "    val_f1 = 2 * (val_prec * val_rec) / (val_prec + val_rec + 1e-7)\n",
    "    \n",
    "    # Get predictions for detailed metrics\n",
    "    y_pred_probs = model.predict(X_val, verbose=0)\n",
    "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "    y_true = np.argmax(y_val, axis=1)\n",
    "    \n",
    "    # Per-class metrics\n",
    "    report = classification_report(y_true, y_pred, target_names=CLASS_NAMES, output_dict=True)\n",
    "    \n",
    "    results.append({\n",
    "        'fold': fold,\n",
    "        'val_loss': val_loss,\n",
    "        'val_accuracy': val_acc,\n",
    "        'val_precision': val_prec,\n",
    "        'val_recall': val_rec,\n",
    "        'val_f1': val_f1,\n",
    "        'per_class': report\n",
    "    })\n",
    "    \n",
    "    print(f\"\\nFold {fold} Results:\")\n",
    "    print(f\"  Val Loss:      {val_loss:.6f}\")\n",
    "    print(f\"  Val Accuracy:  {val_acc:.6f}\")\n",
    "    print(f\"  Val Precision: {val_prec:.6f}\")\n",
    "    print(f\"  Val Recall:    {val_rec:.6f}\")\n",
    "    print(f\"  Val F1:        {val_f1:.6f}\")\n",
    "    \n",
    "    # Fall_Initiation specific\n",
    "    fall_metrics = report['Fall_Initiation']\n",
    "    print(f\"\\n  Fall_Initiation:\")\n",
    "    print(f\"    Precision: {fall_metrics['precision']:.4f}\")\n",
    "    print(f\"    Recall:    {fall_metrics['recall']:.4f}\")\n",
    "    print(f\"    F1-Score:  {fall_metrics['f1-score']:.4f}\")\n",
    "    \n",
    "    # Check for overfitting\n",
    "    train_acc = max(history.history['accuracy'])\n",
    "    val_acc_best = max(history.history['val_accuracy'])\n",
    "    gap = train_acc - val_acc_best\n",
    "    print(f\"\\n  Overfitting check:\")\n",
    "    print(f\"    Best train acc: {train_acc:.4f}\")\n",
    "    print(f\"    Best val acc:   {val_acc_best:.4f}\")\n",
    "    print(f\"    Gap:            {gap:.4f} ({gap*100:.1f}%)\")\n",
    "    if gap > 0.10:\n",
    "        print(f\"    ‚ö†Ô∏è  Still overfitting by >10%\")\n",
    "    elif gap > 0.05:\n",
    "        print(f\"    ‚ö†Ô∏è  Moderate overfitting (5-10%)\")\n",
    "    else:\n",
    "        print(f\"    ‚úì Good generalization (<5% gap)\")\n",
    "\n",
    "# ============================================================================\n",
    "# AGGREGATE RESULTS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"LMU-REGULARIZED RESULTS ACROSS ALL FOLDS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(results)\n",
    "print(df[['fold', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_f1']].to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"LMU-REGULARIZED AVERAGE PERFORMANCE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Accuracy:  {df['val_accuracy'].mean():.4f} ¬± {df['val_accuracy'].std():.4f}\")\n",
    "print(f\"Precision: {df['val_precision'].mean():.4f} ¬± {df['val_precision'].std():.4f}\")\n",
    "print(f\"Recall:    {df['val_recall'].mean():.4f} ¬± {df['val_recall'].std():.4f}\")\n",
    "print(f\"F1-Score:  {df['val_f1'].mean():.4f} ¬± {df['val_f1'].std():.4f}\")\n",
    "\n",
    "# Compare to original LMU\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPARISON TO ORIGINAL LMU\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Original LMU:     {0.8072:.4f} ¬± {0.0166:.4f}\")\n",
    "print(f\"Regularized LMU:  {df['val_accuracy'].mean():.4f} ¬± {df['val_accuracy'].std():.4f}\")\n",
    "improvement = df['val_accuracy'].mean() - 0.8072\n",
    "print(f\"Improvement:      {improvement:+.4f} ({improvement*100:+.1f}%)\")\n",
    "\n",
    "# Save results\n",
    "output = {\n",
    "    'config': {\n",
    "        'memory_d': MEMORY_D,\n",
    "        'order': ORDER,\n",
    "        'theta': THETA,\n",
    "        'l1_reg': L1_REG,\n",
    "        'l2_reg': L2_REG,\n",
    "        'dropout': DROPOUT,\n",
    "        'recurrent_dropout': RECURRENT_DROPOUT,\n",
    "        'early_stop_patience': EARLY_STOP_PATIENCE,\n",
    "        'reduce_lr_patience': REDUCE_LR_PATIENCE\n",
    "    },\n",
    "    'results': results,\n",
    "    'summary': {\n",
    "        'mean_accuracy': float(df['val_accuracy'].mean()),\n",
    "        'std_accuracy': float(df['val_accuracy'].std()),\n",
    "        'mean_precision': float(df['val_precision'].mean()),\n",
    "        'std_precision': float(df['val_precision'].std()),\n",
    "        'mean_recall': float(df['val_recall'].mean()),\n",
    "        'std_recall': float(df['val_recall'].std()),\n",
    "        'mean_f1': float(df['val_f1'].mean()),\n",
    "        'std_f1': float(df['val_f1'].std())\n",
    "    }\n",
    "}\n",
    "\n",
    "output_file = model_dir / 'lmu_regularized_summary.json'\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(output, f, indent=2)\n",
    "\n",
    "print(f\"\\n‚úì Results saved to {output_file}\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úì TRAINING COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Improved LMU-only training with stronger regularization to combat overfitting.\n",
    "\n",
    "Changes from original:\n",
    "1. Increased L1L2 regularization (1e-4 ‚Üí 5e-4)\n",
    "2. Added dropout to LMU layer (0.3)\n",
    "3. Added recurrent dropout (0.2)\n",
    "4. Earlier early stopping (patience 5 ‚Üí 3)\n",
    "5. Reduced LMU capacity (memory_d=32, order=32 instead of 64/64)\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "import json\n",
    "\n",
    "# Import KerasLMU\n",
    "import keras_lmu\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"LMU-ONLY TRAINING - IMPROVED REGULARIZATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "# Paths\n",
    "base_dir = Path.home() / 'repos/summerschool2023/projects/fall-detection/fall_detection_data'\n",
    "processed_dir = base_dir / 'processed'\n",
    "model_dir = base_dir / 'models'\n",
    "\n",
    "# Training hyperparameters\n",
    "BATCH_SIZE = 2\n",
    "LEARNING_RATE = 1e-5\n",
    "EPOCHS = 50\n",
    "K_FOLDS = 5\n",
    "\n",
    "# LMU parameters - MODERATE CAPACITY\n",
    "MEMORY_D = 48      # Moderate - between 32 (too small) and 64 (too big)\n",
    "ORDER = 48         # Moderate - between 32 (too small) and 64 (too big)\n",
    "THETA = 200.0\n",
    "\n",
    "# Regularization - MODERATE (between weak and strong)\n",
    "L1_REG = 2e-4      # Moderate - between 1e-4 (weak) and 5e-4 (strong)\n",
    "L2_REG = 2e-4      # Moderate - between 1e-4 (weak) and 5e-4 (strong)\n",
    "DROPOUT = 0.2      # Moderate - lighter than 0.3\n",
    "RECURRENT_DROPOUT = 0.1  # Light - half of previous\n",
    "\n",
    "# Early stopping - BALANCED\n",
    "EARLY_STOP_PATIENCE = 5  # Moderate - between 3 (too aggressive) and 10 (too lenient)\n",
    "REDUCE_LR_PATIENCE = 3   # Moderate - between 2 and 5\n",
    "\n",
    "CLASS_NAMES = [\n",
    "    'Walking',\n",
    "    'Jogging',\n",
    "    'Walking_stairs_updown',\n",
    "    'Stumble_while_walking',\n",
    "    'Fall_Initiation',\n",
    "    'Impact_Aftermath'\n",
    "]\n",
    "\n",
    "# ============================================================================\n",
    "# LOAD DATA\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nLoading data...\")\n",
    "X = np.load(processed_dir / 'X_data_6class.npy')\n",
    "y = np.load(processed_dir / 'y_labels_6class.npy')\n",
    "\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "\n",
    "# Convert to categorical\n",
    "y_categorical = keras.utils.to_categorical(y, num_classes=6)\n",
    "\n",
    "# Calculate class weights\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "class_weights_array = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y),\n",
    "    y=y\n",
    ")\n",
    "class_weights = {i: weight for i, weight in enumerate(class_weights_array)}\n",
    "\n",
    "print(f\"\\nClass weights:\")\n",
    "for i, weight in class_weights.items():\n",
    "    print(f\"  Class {i} ({CLASS_NAMES[i]:30s}): {weight:.4f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# BUILD MODEL FUNCTION - WITH IMPROVED REGULARIZATION\n",
    "# ============================================================================\n",
    "\n",
    "def build_lmu_model(input_shape, num_classes):\n",
    "    \"\"\"Build LMU-only model with strong regularization\"\"\"\n",
    "    \n",
    "    inputs = keras.Input(shape=input_shape, name='input')\n",
    "    \n",
    "    # LMU layer with dropout and regularization\n",
    "    x = keras_lmu.LMU(\n",
    "        memory_d=MEMORY_D,\n",
    "        order=ORDER,\n",
    "        theta=THETA,\n",
    "        hidden_cell=None,\n",
    "        kernel_regularizer=keras.regularizers.L1L2(l1=L1_REG, l2=L2_REG),\n",
    "        recurrent_regularizer=keras.regularizers.L1L2(l1=L1_REG, l2=L2_REG),\n",
    "        dropout=DROPOUT,\n",
    "        recurrent_dropout=RECURRENT_DROPOUT,\n",
    "        name='lmu'\n",
    "    )(inputs)\n",
    "    \n",
    "    # Dense layers with moderate regularization and dropout\n",
    "    x = keras.layers.Dense(\n",
    "        128,\n",
    "        activation='relu',\n",
    "        kernel_regularizer=keras.regularizers.L1L2(l1=L1_REG, l2=L2_REG),\n",
    "        name='dense1'\n",
    "    )(x)\n",
    "    x = keras.layers.Dropout(0.3, name='dropout1')(x)  # Moderate\n",
    "    \n",
    "    x = keras.layers.Dense(\n",
    "        64,\n",
    "        activation='relu',\n",
    "        kernel_regularizer=keras.regularizers.L1L2(l1=L1_REG, l2=L2_REG),\n",
    "        name='dense2'\n",
    "    )(x)\n",
    "    x = keras.layers.Dropout(0.25, name='dropout2')(x)  # Moderate\n",
    "    \n",
    "    x = keras.layers.Dense(\n",
    "        32,\n",
    "        activation='relu',\n",
    "        kernel_regularizer=keras.regularizers.L1L2(l1=L1_REG, l2=L2_REG),\n",
    "        name='dense3'\n",
    "    )(x)\n",
    "    x = keras.layers.Dropout(0.2, name='dropout3')(x)  # Light\n",
    "    \n",
    "    outputs = keras.layers.Dense(\n",
    "        num_classes,\n",
    "        activation='softmax',\n",
    "        name='output'\n",
    "    )(x)\n",
    "    \n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name='lmu_regularized')\n",
    "    \n",
    "    return model\n",
    "\n",
    "# ============================================================================\n",
    "# TRAINING LOOP\n",
    "# ============================================================================\n",
    "\n",
    "# Setup k-fold cross-validation\n",
    "skf = StratifiedKFold(n_splits=K_FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "results = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X, y), 1):\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"FOLD {fold}/{K_FOLDS}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_val = X[train_idx], X[val_idx]\n",
    "    y_train, y_val = y_categorical[train_idx], y_categorical[val_idx]\n",
    "    \n",
    "    print(f\"Train size: {len(X_train)}, Val size: {len(X_val)}\")\n",
    "    \n",
    "    # Build model\n",
    "    model = build_lmu_model(input_shape=(200, 6), num_classes=6)\n",
    "    \n",
    "    # Print model summary (only first fold)\n",
    "    if fold == 1:\n",
    "        print(\"\\nModel Architecture:\")\n",
    "        model.summary()\n",
    "        print(f\"\\nRegularization settings:\")\n",
    "        print(f\"  L1/L2: {L1_REG}/{L2_REG} (moderate)\")\n",
    "        print(f\"  LMU dropout: {DROPOUT}\")\n",
    "        print(f\"  LMU recurrent dropout: {RECURRENT_DROPOUT}\")\n",
    "        print(f\"  Dense dropout: 0.3, 0.25, 0.2\")\n",
    "        print(f\"  LMU capacity: memory_d={MEMORY_D}, order={ORDER} (moderate)\")\n",
    "        print(f\"  Early stop patience: {EARLY_STOP_PATIENCE}\")\n",
    "    \n",
    "    # Compile\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy', keras.metrics.Precision(), keras.metrics.Recall()],\n",
    "        jit_compile=True\n",
    "    )\n",
    "    \n",
    "    # Callbacks - MORE AGGRESSIVE EARLY STOPPING\n",
    "    callbacks = [\n",
    "        keras.callbacks.EarlyStopping(\n",
    "            monitor='val_accuracy',\n",
    "            patience=EARLY_STOP_PATIENCE,  # Reduced to 3\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_accuracy',\n",
    "            factor=0.5,\n",
    "            patience=REDUCE_LR_PATIENCE,  # Reduced to 2\n",
    "            min_lr=1e-7,\n",
    "            verbose=1\n",
    "        ),\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "            filepath=model_dir / f'lmu_regularized_fold_{fold}.keras',\n",
    "            monitor='val_accuracy',\n",
    "            save_best_only=True,\n",
    "            verbose=1\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # Train\n",
    "    print(f\"\\nTraining fold {fold}...\")\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epochs=EPOCHS,\n",
    "        callbacks=callbacks,\n",
    "        class_weight=class_weights,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Evaluate\n",
    "    print(f\"\\nEvaluating fold {fold}...\")\n",
    "    val_loss, val_acc, val_prec, val_rec = model.evaluate(X_val, y_val, verbose=0)\n",
    "    val_f1 = 2 * (val_prec * val_rec) / (val_prec + val_rec + 1e-7)\n",
    "    \n",
    "    # Get predictions for detailed metrics\n",
    "    y_pred_probs = model.predict(X_val, verbose=0)\n",
    "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "    y_true = np.argmax(y_val, axis=1)\n",
    "    \n",
    "    # Per-class metrics\n",
    "    report = classification_report(y_true, y_pred, target_names=CLASS_NAMES, output_dict=True)\n",
    "    \n",
    "    results.append({\n",
    "        'fold': fold,\n",
    "        'val_loss': val_loss,\n",
    "        'val_accuracy': val_acc,\n",
    "        'val_precision': val_prec,\n",
    "        'val_recall': val_rec,\n",
    "        'val_f1': val_f1,\n",
    "        'per_class': report\n",
    "    })\n",
    "    \n",
    "    print(f\"\\nFold {fold} Results:\")\n",
    "    print(f\"  Val Loss:      {val_loss:.6f}\")\n",
    "    print(f\"  Val Accuracy:  {val_acc:.6f}\")\n",
    "    print(f\"  Val Precision: {val_prec:.6f}\")\n",
    "    print(f\"  Val Recall:    {val_rec:.6f}\")\n",
    "    print(f\"  Val F1:        {val_f1:.6f}\")\n",
    "    \n",
    "    # Fall_Initiation specific\n",
    "    fall_metrics = report['Fall_Initiation']\n",
    "    print(f\"\\n  Fall_Initiation:\")\n",
    "    print(f\"    Precision: {fall_metrics['precision']:.4f}\")\n",
    "    print(f\"    Recall:    {fall_metrics['recall']:.4f}\")\n",
    "    print(f\"    F1-Score:  {fall_metrics['f1-score']:.4f}\")\n",
    "    \n",
    "    # Check for overfitting\n",
    "    train_acc = max(history.history['accuracy'])\n",
    "    val_acc_best = max(history.history['val_accuracy'])\n",
    "    gap = train_acc - val_acc_best\n",
    "    print(f\"\\n  Overfitting check:\")\n",
    "    print(f\"    Best train acc: {train_acc:.4f}\")\n",
    "    print(f\"    Best val acc:   {val_acc_best:.4f}\")\n",
    "    print(f\"    Gap:            {gap:.4f} ({gap*100:.1f}%)\")\n",
    "    if gap > 0.10:\n",
    "        print(f\"    ‚ö†Ô∏è  Still overfitting by >10%\")\n",
    "    elif gap > 0.05:\n",
    "        print(f\"    ‚ö†Ô∏è  Moderate overfitting (5-10%)\")\n",
    "    else:\n",
    "        print(f\"    ‚úì Good generalization (<5% gap)\")\n",
    "\n",
    "# ============================================================================\n",
    "# AGGREGATE RESULTS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"LMU-REGULARIZED RESULTS ACROSS ALL FOLDS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(results)\n",
    "print(df[['fold', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_f1']].to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"LMU-REGULARIZED AVERAGE PERFORMANCE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Accuracy:  {df['val_accuracy'].mean():.4f} ¬± {df['val_accuracy'].std():.4f}\")\n",
    "print(f\"Precision: {df['val_precision'].mean():.4f} ¬± {df['val_precision'].std():.4f}\")\n",
    "print(f\"Recall:    {df['val_recall'].mean():.4f} ¬± {df['val_recall'].std():.4f}\")\n",
    "print(f\"F1-Score:  {df['val_f1'].mean():.4f} ¬± {df['val_f1'].std():.4f}\")\n",
    "\n",
    "# Compare to original LMU\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPARISON TO ORIGINAL LMU\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Original LMU:     {0.8072:.4f} ¬± {0.0166:.4f}\")\n",
    "print(f\"Regularized LMU:  {df['val_accuracy'].mean():.4f} ¬± {df['val_accuracy'].std():.4f}\")\n",
    "improvement = df['val_accuracy'].mean() - 0.8072\n",
    "print(f\"Improvement:      {improvement:+.4f} ({improvement*100:+.1f}%)\")\n",
    "\n",
    "# Save results\n",
    "output = {\n",
    "    'config': {\n",
    "        'memory_d': MEMORY_D,\n",
    "        'order': ORDER,\n",
    "        'theta': THETA,\n",
    "        'l1_reg': L1_REG,\n",
    "        'l2_reg': L2_REG,\n",
    "        'dropout': DROPOUT,\n",
    "        'recurrent_dropout': RECURRENT_DROPOUT,\n",
    "        'early_stop_patience': EARLY_STOP_PATIENCE,\n",
    "        'reduce_lr_patience': REDUCE_LR_PATIENCE\n",
    "    },\n",
    "    'results': results,\n",
    "    'summary': {\n",
    "        'mean_accuracy': float(df['val_accuracy'].mean()),\n",
    "        'std_accuracy': float(df['val_accuracy'].std()),\n",
    "        'mean_precision': float(df['val_precision'].mean()),\n",
    "        'std_precision': float(df['val_precision'].std()),\n",
    "        'mean_recall': float(df['val_recall'].mean()),\n",
    "        'std_recall': float(df['val_recall'].std()),\n",
    "        'mean_f1': float(df['val_f1'].mean()),\n",
    "        'std_f1': float(df['val_f1'].std())\n",
    "    }\n",
    "}\n",
    "\n",
    "output_file = model_dir / 'lmu_regularized_summary.json'\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(output, f, indent=2)\n",
    "\n",
    "print(f\"\\n‚úì Results saved to {output_file}\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úì TRAINING COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, classification_report\n",
    "\n",
    "# Paths\n",
    "base_dir = Path.home() / 'repos/summerschool2023/projects/fall-detection/fall_detection_data'\n",
    "model_dir = base_dir / 'models'\n",
    "processed_dir = base_dir / 'processed'\n",
    "\n",
    "# Load data\n",
    "X = np.load(processed_dir / 'X_data_6class.npy')\n",
    "y = np.load(processed_dir / 'y_labels_6class.npy')\n",
    "\n",
    "# Load models\n",
    "cnn_models = [keras.models.load_model(model_dir / f'cnn_only_fold_{i}.keras') for i in range(1,6)]\n",
    "lmu_models = [keras.models.load_model(model_dir / f'lmu_regularized_fold_{i}.keras') for i in range(1,6)]\n",
    "\n",
    "# Setup k-fold (same as training)\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "results = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X, y), 1):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"FOLD {fold}/5\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    X_val = X[val_idx]\n",
    "    y_val = y[val_idx]\n",
    "    \n",
    "    # Get predictions\n",
    "    cnn_pred = cnn_models[fold-1].predict(X_val, verbose=0)\n",
    "    lmu_pred = lmu_models[fold-1].predict(X_val, verbose=0)\n",
    "    \n",
    "    # Individual performance\n",
    "    cnn_class = np.argmax(cnn_pred, axis=1)\n",
    "    lmu_class = np.argmax(lmu_pred, axis=1)\n",
    "    \n",
    "    # Ensemble (average probabilities)\n",
    "    ensemble_pred = 0.5 * cnn_pred + 0.5 * lmu_pred\n",
    "    ensemble_class = np.argmax(ensemble_pred, axis=1)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    cnn_acc = accuracy_score(y_val, cnn_class)\n",
    "    cnn_rec = recall_score(y_val, cnn_class, average='macro')\n",
    "    cnn_prec = precision_score(y_val, cnn_class, average='macro')\n",
    "    \n",
    "    lmu_acc = accuracy_score(y_val, lmu_class)\n",
    "    lmu_rec = recall_score(y_val, lmu_class, average='macro')\n",
    "    lmu_prec = precision_score(y_val, lmu_class, average='macro')\n",
    "    \n",
    "    ens_acc = accuracy_score(y_val, ensemble_class)\n",
    "    ens_rec = recall_score(y_val, ensemble_class, average='macro')\n",
    "    ens_prec = precision_score(y_val, ensemble_class, average='macro')\n",
    "    \n",
    "    # Error analysis\n",
    "    cnn_errors = (cnn_class != y_val)\n",
    "    lmu_errors = (lmu_class != y_val)\n",
    "    ens_errors = (ensemble_class != y_val)\n",
    "    \n",
    "    both_wrong = cnn_errors & lmu_errors\n",
    "    cnn_rescues_lmu = lmu_errors & ~cnn_errors\n",
    "    lmu_rescues_cnn = cnn_errors & ~lmu_errors\n",
    "    ensemble_rescues = both_wrong & ~ens_errors\n",
    "    \n",
    "    print(f\"\\nCNN-only:      Acc={cnn_acc:.4f}, Prec={cnn_prec:.4f}, Rec={cnn_rec:.4f}\")\n",
    "    print(f\"LMU-only:      Acc={lmu_acc:.4f}, Prec={lmu_prec:.4f}, Rec={lmu_rec:.4f}\")\n",
    "    print(f\"CNN-LMU Ens:   Acc={ens_acc:.4f}, Prec={ens_prec:.4f}, Rec={ens_rec:.4f}\")\n",
    "    \n",
    "    print(f\"\\nError Analysis:\")\n",
    "    print(f\"  CNN rescues LMU: {cnn_rescues_lmu.sum()} cases\")\n",
    "    print(f\"  LMU rescues CNN: {lmu_rescues_cnn.sum()} cases\")\n",
    "    print(f\"  Both wrong:      {both_wrong.sum()} cases\")\n",
    "    print(f\"  Ensemble rescues both: {ensemble_rescues.sum()} cases\")\n",
    "    \n",
    "    # Gain from ensemble\n",
    "    gain_vs_cnn = ens_acc - cnn_acc\n",
    "    gain_vs_lmu = ens_acc - lmu_acc\n",
    "    print(f\"\\nEnsemble gain vs CNN: {gain_vs_cnn:+.4f} ({gain_vs_cnn*100:+.1f}%)\")\n",
    "    print(f\"Ensemble gain vs LMU: {gain_vs_lmu:+.4f} ({gain_vs_lmu*100:+.1f}%)\")\n",
    "    \n",
    "    results.append({\n",
    "        'fold': fold,\n",
    "        'cnn_acc': cnn_acc,\n",
    "        'cnn_rec': cnn_rec,\n",
    "        'lmu_acc': lmu_acc,\n",
    "        'lmu_rec': lmu_rec,\n",
    "        'ens_acc': ens_acc,\n",
    "        'ens_rec': ens_rec,\n",
    "        'cnn_rescues': int(cnn_rescues_lmu.sum()),\n",
    "        'lmu_rescues': int(lmu_rescues_cnn.sum())\n",
    "    })\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"SUMMARY ACROSS ALL FOLDS\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "print(f\"\\nCNN-only:     Acc={df['cnn_acc'].mean():.4f}¬±{df['cnn_acc'].std():.4f}, Rec={df['cnn_rec'].mean():.4f}¬±{df['cnn_rec'].std():.4f}\")\n",
    "print(f\"LMU-only:     Acc={df['lmu_acc'].mean():.4f}¬±{df['lmu_acc'].std():.4f}, Rec={df['lmu_rec'].mean():.4f}¬±{df['lmu_rec'].std():.4f}\")\n",
    "print(f\"CNN-LMU Ens:  Acc={df['ens_acc'].mean():.4f}¬±{df['ens_acc'].std():.4f}, Rec={df['ens_rec'].mean():.4f}¬±{df['ens_rec'].std():.4f}\")\n",
    "\n",
    "print(f\"\\nTotal rescues:\")\n",
    "print(f\"  CNN rescued LMU: {df['cnn_rescues'].sum()} cases\")\n",
    "print(f\"  LMU rescued CNN: {df['lmu_rescues'].sum()} cases\")\n",
    "\n",
    "# Critical question\n",
    "mean_ens_recall = df['ens_rec'].mean()\n",
    "if mean_ens_recall >= 0.80:\n",
    "    print(f\"\\n‚úÖ ENSEMBLE RECALL ‚â• 80% ({mean_ens_recall:.1%}) - VIABLE FOR SNN CONVERSION!\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è  ENSEMBLE RECALL < 80% ({mean_ens_recall:.1%}) - Consider CNN-LSTM instead\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from pathlib import Path\n",
    "\n",
    "model_dir = Path.home() / 'repos/summerschool2023/projects/fall-detection/fall_detection_data/models'\n",
    "\n",
    "# Check what the \"fallnet\" models actually contain\n",
    "print(\"Checking fallnet_fold_1.keras:\")\n",
    "model = keras.models.load_model(model_dir / 'fallnet_fold_1.keras')\n",
    "print(\"\\nModel architecture:\")\n",
    "model.summary()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Layer types:\")\n",
    "for layer in model.layers:\n",
    "    print(f\"  {layer.name}: {type(layer).__name__}\")\n",
    "    \n",
    "# Check if it has LSTM or LMU\n",
    "has_lstm = any('LSTM' in type(layer).__name__ for layer in model.layers)\n",
    "has_lmu = any('LMU' in type(layer).__name__ for layer in model.layers)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"Contains LSTM: {has_lstm}\")\n",
    "print(f\"Contains LMU: {has_lmu}\")\n",
    "\n",
    "if has_lmu:\n",
    "    print(\"\\n‚ö†Ô∏è  WARNING: fallnet models contain LMU (overwritten!)\")\n",
    "    print(\"Original CNN-LSTM ensemble was lost\")\n",
    "elif has_lstm:\n",
    "    print(\"\\n‚úì fallnet models still contain LSTM (original preserved)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Paths\n",
    "base_dir = Path.home() / 'repos/summerschool2023/projects/fall-detection/fall_detection_data'\n",
    "model_dir = base_dir / 'models'\n",
    "processed_dir = base_dir / 'processed'\n",
    "\n",
    "# Load data\n",
    "X = np.load(processed_dir / 'X_data_6class.npy')\n",
    "y = np.load(processed_dir / 'y_labels_6class.npy')\n",
    "\n",
    "# Load models - now we have the ensemble models too!\n",
    "cnn_models = [keras.models.load_model(model_dir / f'cnn_only_fold_{i}.keras') for i in range(1,6)]\n",
    "lmu_models = [keras.models.load_model(model_dir / f'lmu_regularized_fold_{i}.keras') for i in range(1,6)]\n",
    "ensemble_models = [keras.models.load_model(model_dir / f'fallnet_fold_{i}.keras') for i in range(1,6)]\n",
    "\n",
    "# Setup k-fold (same as training)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "results = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X, y), 1):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"FOLD {fold}/5\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    X_val = X[val_idx]\n",
    "    y_val = y[val_idx]\n",
    "    \n",
    "    # Get predictions from all three model types\n",
    "    cnn_pred = cnn_models[fold-1].predict(X_val, verbose=0)\n",
    "    lmu_pred = lmu_models[fold-1].predict(X_val, verbose=0)\n",
    "    ensemble_pred = ensemble_models[fold-1].predict(X_val, verbose=0)\n",
    "    \n",
    "    # Convert to class predictions\n",
    "    cnn_class = np.argmax(cnn_pred, axis=1)\n",
    "    lmu_class = np.argmax(lmu_pred, axis=1)\n",
    "    ensemble_class = np.argmax(ensemble_pred, axis=1)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    cnn_acc = accuracy_score(y_val, cnn_class)\n",
    "    cnn_rec = recall_score(y_val, cnn_class, average='macro')\n",
    "    cnn_prec = precision_score(y_val, cnn_class, average='macro')\n",
    "    \n",
    "    lmu_acc = accuracy_score(y_val, lmu_class)\n",
    "    lmu_rec = recall_score(y_val, lmu_class, average='macro')\n",
    "    lmu_prec = precision_score(y_val, lmu_class, average='macro')\n",
    "    \n",
    "    ens_acc = accuracy_score(y_val, ensemble_class)\n",
    "    ens_rec = recall_score(y_val, ensemble_class, average='macro')\n",
    "    ens_prec = precision_score(y_val, ensemble_class, average='macro')\n",
    "    \n",
    "    # Error analysis\n",
    "    cnn_errors = (cnn_class != y_val)\n",
    "    lmu_errors = (lmu_class != y_val)\n",
    "    ens_errors = (ensemble_class != y_val)\n",
    "    \n",
    "    both_wrong = cnn_errors & lmu_errors\n",
    "    cnn_rescues_lmu = lmu_errors & ~cnn_errors\n",
    "    lmu_rescues_cnn = cnn_errors & ~lmu_errors\n",
    "    ensemble_rescues = both_wrong & ~ens_errors\n",
    "    \n",
    "    print(f\"\\nCNN-only:          Acc={cnn_acc:.4f}, Prec={cnn_prec:.4f}, Rec={cnn_rec:.4f}\")\n",
    "    print(f\"LMU-only:          Acc={lmu_acc:.4f}, Prec={lmu_prec:.4f}, Rec={lmu_rec:.4f}\")\n",
    "    print(f\"CNN-LMU Ensemble:  Acc={ens_acc:.4f}, Prec={ens_prec:.4f}, Rec={ens_rec:.4f}\")\n",
    "    \n",
    "    print(f\"\\nError Analysis:\")\n",
    "    print(f\"  CNN rescues LMU: {cnn_rescues_lmu.sum()} cases\")\n",
    "    print(f\"  LMU rescues CNN: {lmu_rescues_cnn.sum()} cases\")\n",
    "    print(f\"  Both wrong:      {both_wrong.sum()} cases\")\n",
    "    print(f\"  Ensemble rescues both: {ensemble_rescues.sum()} cases\")\n",
    "    \n",
    "    # Gain from ensemble\n",
    "    gain_vs_cnn = ens_acc - cnn_acc\n",
    "    gain_vs_lmu = ens_acc - lmu_acc\n",
    "    print(f\"\\nEnsemble gain vs CNN: {gain_vs_cnn:+.4f} ({gain_vs_cnn*100:+.1f}%)\")\n",
    "    print(f\"Ensemble gain vs LMU: {gain_vs_lmu:+.4f} ({gain_vs_lmu*100:+.1f}%)\")\n",
    "    \n",
    "    results.append({\n",
    "        'fold': fold,\n",
    "        'cnn_acc': cnn_acc,\n",
    "        'cnn_rec': cnn_rec,\n",
    "        'lmu_acc': lmu_acc,\n",
    "        'lmu_rec': lmu_rec,\n",
    "        'ens_acc': ens_acc,\n",
    "        'ens_rec': ens_rec,\n",
    "        'cnn_rescues': int(cnn_rescues_lmu.sum()),\n",
    "        'lmu_rescues': int(lmu_rescues_cnn.sum()),\n",
    "        'ensemble_rescues': int(ensemble_rescues.sum())\n",
    "    })\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"SUMMARY ACROSS ALL FOLDS\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "print(f\"\\nCNN-only:          Acc={df['cnn_acc'].mean():.4f}¬±{df['cnn_acc'].std():.4f}, Rec={df['cnn_rec'].mean():.4f}¬±{df['cnn_rec'].std():.4f}\")\n",
    "print(f\"LMU-only:          Acc={df['lmu_acc'].mean():.4f}¬±{df['lmu_acc'].std():.4f}, Rec={df['lmu_rec'].mean():.4f}¬±{df['lmu_rec'].std():.4f}\")\n",
    "print(f\"CNN-LMU Ensemble:  Acc={df['ens_acc'].mean():.4f}¬±{df['ens_acc'].std():.4f}, Rec={df['ens_rec'].mean():.4f}¬±{df['ens_rec'].std():.4f}\")\n",
    "\n",
    "print(f\"\\nTotal rescues:\")\n",
    "print(f\"  CNN rescued LMU: {df['cnn_rescues'].sum()} cases\")\n",
    "print(f\"  LMU rescued CNN: {df['lmu_rescues'].sum()} cases\")\n",
    "print(f\"  Ensemble rescued both: {df['ensemble_rescues'].sum()} cases\")\n",
    "\n",
    "# Compare to your manual ensemble (averaging predictions)\n",
    "manual_ensemble_acc = 0.9000  # From your previous analysis\n",
    "trained_ensemble_acc = df['ens_acc'].mean()\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"ENSEMBLE COMPARISON\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Manual averaging:  {manual_ensemble_acc:.4f} (averaging CNN + LMU predictions)\")\n",
    "print(f\"Trained ensemble:  {trained_ensemble_acc:.4f} (CNN-LMU model with learned weights)\")\n",
    "print(f\"Difference:        {(trained_ensemble_acc - manual_ensemble_acc):+.4f}\")\n",
    "\n",
    "# Critical question\n",
    "mean_ens_recall = df['ens_rec'].mean()\n",
    "if mean_ens_recall >= 0.80:\n",
    "    print(f\"\\n‚úÖ ENSEMBLE RECALL ‚â• 80% ({mean_ens_recall:.1%}) - VIABLE FOR SNN CONVERSION!\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è  ENSEMBLE RECALL < 80% ({mean_ens_recall:.1%}) - Consider CNN-LSTM instead\")\n",
    "\n",
    "# Detailed table\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"DETAILED RESULTS BY FOLD\")\n",
    "print(f\"{'='*60}\")\n",
    "print(df[['fold', 'cnn_acc', 'lmu_acc', 'ens_acc', 'cnn_rec', 'lmu_rec', 'ens_rec']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
